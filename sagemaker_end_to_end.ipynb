{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330bac2b-9187-47e9-bece-dd4f889a8dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Improves Data Science Productiity Using SageMaker Studio\n",
    "\n",
    "Using Machine Learning Model to predict customer churn for a Music Streaming Service\n",
    "\n",
    "The notebook is organized into the following sections:\n",
    "\n",
    "* Background\n",
    "* Dataset Exploration\n",
    "* Model Training Using SageMaker Studio\n",
    "* Use SageMaker Experiment To organize Data Science experiments\n",
    "* Use Sagemaker Debugger to monitors utilization of system resources such as GPUs, CPUs, network, and memory, and profiles the training jobs to collect detailed ML framework metrics.  \n",
    "* Deploy the trained model into SageMaker Inference to serve churn prediction\n",
    "* Monitor Model quality using SageMaker Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77465a13-c23d-458b-9967-14762479b9e1",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "This particular challenge was originally introduced as a Kaggle competition in 2018. The goal was to build an algorithm that predicts \n",
    "whether a subscription user will churn using a donated dataset from KKBOX. \n",
    "\n",
    "For a subscription business, accurately predicting churn is critical to long-term success. \n",
    "\n",
    "Even slight variations in churn can drastically affect profits.\n",
    "\n",
    "KKBOX is Asia’s leading music streaming service, holding the world’s most comprehensive Asia-Pop music library with over 30 million tracks. They offer a generous, unlimited version of their service to millions of people, supported by advertising and paid subscriptions. This delicate model is dependent on accurately predicting churn of their paid users.\n",
    "\n",
    "In this notebook, we'll explore a machine learning model called XGBoost to predict whether a user will churn after their subscription expires. Currently, the company uses survival analysis techniques to determine the residual membership life time for each subscriber. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81e0fe-811c-4be2-ad20-fc5086f9d101",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We combining multiple datasets, including the subscription, membership and user activity logs to extract the signals for training a machine learning model. We use an EMR cluster to perform the feature engineering work, directly from within SageMaker Studio. For detail about using EMR and Pyspark, please refer to the notebook [here](processing_pyspark.ipynb)\n",
    "\n",
    "In the following section, we'll explore the curated dataset in greater detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac23e0d9-4174-4866-9749-5e1efb0de033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.120.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.129.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting boto3<2.0,>=1.26.28\n",
      "  Using cached boto3-1.26.54-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (22.1.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Collecting botocore<1.30.0,>=1.29.54\n",
      "  Using cached botocore-1.29.54-py3-none-any.whl (10.3 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (4.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.54->boto3<2.0,>=1.26.28->sagemaker) (1.26.13)\n",
      "Installing collected packages: importlib-metadata, botocore, boto3, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Uninstalling importlib-metadata-5.1.0:\n",
      "      Successfully uninstalled importlib-metadata-5.1.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.24\n",
      "    Uninstalling botocore-1.29.24:\n",
      "      Successfully uninstalled botocore-1.29.24\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.24\n",
      "    Uninstalling boto3-1.26.24:\n",
      "      Successfully uninstalled boto3-1.26.24\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.120.0\n",
      "    Uninstalling sagemaker-2.120.0:\n",
      "      Successfully uninstalled sagemaker-2.120.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.29.54 which is incompatible.\n",
      "awscli 1.27.24 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "aiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.54 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.54 botocore-1.29.54 importlib-metadata-4.13.0 sagemaker-2.129.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159afbf-302c-433f-809c-a9a05b936e18",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the Python libraries we'll need for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bac1294-25d2-4d2d-b36e-b7fad3f82cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af3ee61-1580-4ac8-9535-87b1cf53a2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "prefix = \"data/kkbox-customer-churn-model\"\n",
    "experiment_name = \"kkbox-customer-churn-model-experiment\"\n",
    "content_type = \"csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dd436-1dc8-48d0-a375-ee3e3ce0ae85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d69fbb-cab8-4864-b1b9-27e50bf3d67d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.2xlarge.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-01-23-02-14-47-668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-23 02:14:47 Starting - Starting the training job...\n",
      "2023-01-23 02:15:03 Starting - Preparing the instances for training......\n",
      "2023-01-23 02:15:51 Downloading - Downloading input data.....\u001b[34m[2023-01-23 02:16:58.538 ip-10-0-215-214.us-east-2.compute.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:16:58:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=5476 sha256=3ccfe7c8711d19e04b24090f061081f9cba37f268bf11656ee9b35d74e291341\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-ygohlqcs/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:17:00:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-01-23:02:17:00:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.2,\n",
      "        \"gamma\": 4,\n",
      "        \"max_depth\": 5,\n",
      "        \"min_child_weight\": 6,\n",
      "        \"n_estimators\": 50,\n",
      "        \"region\": \"us-east-2\",\n",
      "        \"subsample\": 0.7\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2023-01-23-02-14-47-668\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-869530972998/sagemaker-xgboost-2023-01-23-02-14-47-668/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"n_estimators\":50,\"region\":\"us-east-2\",\"subsample\":0.7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-869530972998/sagemaker-xgboost-2023-01-23-02-14-47-668/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"n_estimators\":50,\"region\":\"us-east-2\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2023-01-23-02-14-47-668\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-869530972998/sagemaker-xgboost-2023-01-23-02-14-47-668/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--n_estimators\",\"50\",\"--region\",\"us-east-2\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=50\u001b[0m\n",
      "\u001b[34mSM_HP_REGION=us-east-2\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --n_estimators 50 --region us-east-2 --subsample 0.7\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.129.0.tar.gz (660 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 660.7/660.7 kB 10.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting attrs<23,>=20.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 11.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.54-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 28.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 16.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 17.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 2.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.30.0,>=1.29.54\n",
      "  Downloading botocore-1.29.54-py3-none-any.whl (10.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 127.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /miniconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 16.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 36.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 20.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.54->boto3<2.0,>=1.26.28->sagemaker) (1.26.5)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.129.0-py2.py3-none-any.whl size=897207 sha256=1dc8d46e3e49aaba9e044bd378c5091e0ea5f33429fff78a3c525ab50a7a98b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/cb/3a/556f9780251839d7f80e44c13870d93ef0ab011682143f5cd6\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=cd1620bdc60ebf7a123d36502d3dadd42670a3dbbbe4b6e5a156671b03e469bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: zipp, smdebug_rulesconfig, protobuf3-to-dict, ppft, pox, google-pasta, dill, contextlib2, attrs, schema, multiprocess, importlib-metadata, botocore, s3transfer, pathos, boto3, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\n",
      "2023-01-23 02:16:57 Training - Training image download completed. Training in progress.\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.26.54 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.29.54 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-22.2.0 boto3-1.26.54 botocore-1.29.54 contextlib2-21.6.0 dill-0.3.6 google-pasta-0.2.0 importlib-metadata-4.13.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 s3transfer-0.6.0 sagemaker-2.129.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 zipp-3.11.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 22.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mtrain_dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mval_dir: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mINFO:sagemaker.experiments.run:The run (sagemaker-run-1674440087-3b58) under experiment (kkbox-customer-churn-model-experiment-2) already exists. Loading it. Note: sagemaker.experiments.load_run is recommended to use when the desired run already exists.\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[02:17:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-logloss:0.58893#011validation_1-logloss:0.59075\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-logloss:0.51954#011validation_1-logloss:0.52552\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-logloss:0.47102#011validation_1-logloss:0.48111\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-logloss:0.43618#011validation_1-logloss:0.45019\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-logloss:0.40993#011validation_1-logloss:0.42713\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-logloss:0.38925#011validation_1-logloss:0.40971\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-logloss:0.37457#011validation_1-logloss:0.39772\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-logloss:0.36287#011validation_1-logloss:0.38830\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-logloss:0.35410#011validation_1-logloss:0.38153\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-logloss:0.34714#011validation_1-logloss:0.37594\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-logloss:0.34155#011validation_1-logloss:0.37110\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-logloss:0.33725#011validation_1-logloss:0.36808\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-logloss:0.33404#011validation_1-logloss:0.36535\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-logloss:0.33098#011validation_1-logloss:0.36325\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-logloss:0.32912#011validation_1-logloss:0.36110\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-logloss:0.32635#011validation_1-logloss:0.35822\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-logloss:0.32427#011validation_1-logloss:0.35595\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-logloss:0.32236#011validation_1-logloss:0.35395\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-logloss:0.32118#011validation_1-logloss:0.35277\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-logloss:0.31955#011validation_1-logloss:0.35083\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-logloss:0.31835#011validation_1-logloss:0.34969\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-logloss:0.31750#011validation_1-logloss:0.34874\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-logloss:0.31690#011validation_1-logloss:0.34810\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-logloss:0.31580#011validation_1-logloss:0.34681\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-logloss:0.31435#011validation_1-logloss:0.34587\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-logloss:0.31351#011validation_1-logloss:0.34472\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-logloss:0.31213#011validation_1-logloss:0.34349\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-logloss:0.31183#011validation_1-logloss:0.34320\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-logloss:0.31011#011validation_1-logloss:0.34185\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-logloss:0.30971#011validation_1-logloss:0.34140\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-logloss:0.30917#011validation_1-logloss:0.34081\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-logloss:0.30876#011validation_1-logloss:0.34043\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-logloss:0.30818#011validation_1-logloss:0.34004\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-logloss:0.30703#011validation_1-logloss:0.33887\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-logloss:0.30628#011validation_1-logloss:0.33819\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-logloss:0.30579#011validation_1-logloss:0.33772\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-logloss:0.30544#011validation_1-logloss:0.33721\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-logloss:0.30509#011validation_1-logloss:0.33687\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-logloss:0.30478#011validation_1-logloss:0.33662\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-logloss:0.30417#011validation_1-logloss:0.33612\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-logloss:0.30399#011validation_1-logloss:0.33601\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-logloss:0.30368#011validation_1-logloss:0.33564\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-logloss:0.30272#011validation_1-logloss:0.33437\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-logloss:0.30180#011validation_1-logloss:0.33311\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-logloss:0.30153#011validation_1-logloss:0.33287\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-logloss:0.30103#011validation_1-logloss:0.33258\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-logloss:0.30090#011validation_1-logloss:0.33238\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-logloss:0.30033#011validation_1-logloss:0.33177\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-logloss:0.29982#011validation_1-logloss:0.33129\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-logloss:0.29974#011validation_1-logloss:0.33128\u001b[0m\n",
      "\u001b[34mtrain idx: 0, loss: 0.588928, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 1, loss: 0.519542, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 2, loss: 0.47102, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 3, loss: 0.436179, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 4, loss: 0.409935, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 5, loss: 0.389246, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 6, loss: 0.374568, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 7, loss: 0.362866, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 8, loss: 0.354098, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 9, loss: 0.347135, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 10, loss: 0.341553, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 11, loss: 0.337246, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 12, loss: 0.334039, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 13, loss: 0.330976, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 14, loss: 0.329121, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 15, loss: 0.326347, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 16, loss: 0.324265, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 17, loss: 0.322357, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 18, loss: 0.321182, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 19, loss: 0.319549, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 20, loss: 0.318349, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 21, loss: 0.317496, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 22, loss: 0.316896, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 23, loss: 0.315804, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 24, loss: 0.314347, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 25, loss: 0.313513, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 26, loss: 0.312126, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 27, loss: 0.311835, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 28, loss: 0.310113, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 29, loss: 0.309713, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 30, loss: 0.309165, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 31, loss: 0.308764, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 32, loss: 0.308182, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 33, loss: 0.307029, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 34, loss: 0.306285, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 35, loss: 0.305789, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 36, loss: 0.305441, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 37, loss: 0.305088, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 38, loss: 0.304778, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 39, loss: 0.304165, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 40, loss: 0.303986, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 41, loss: 0.303685, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 42, loss: 0.30272, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 43, loss: 0.301804, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 44, loss: 0.30153, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 45, loss: 0.301033, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 46, loss: 0.300895, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 47, loss: 0.300325, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 48, loss: 0.299818, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 49, loss: 0.299738, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mval idx: 0, loss: 0.590746\u001b[0m\n",
      "\u001b[34mval idx: 1, loss: 0.525521\u001b[0m\n",
      "\u001b[34mval idx: 2, loss: 0.481113\u001b[0m\n",
      "\u001b[34mval idx: 3, loss: 0.450193\u001b[0m\n",
      "\u001b[34mval idx: 4, loss: 0.427135\u001b[0m\n",
      "\u001b[34mval idx: 5, loss: 0.409713\u001b[0m\n",
      "\u001b[34mval idx: 6, loss: 0.39772\u001b[0m\n",
      "\u001b[34mval idx: 7, loss: 0.3883\u001b[0m\n",
      "\u001b[34mval idx: 8, loss: 0.38153\u001b[0m\n",
      "\u001b[34mval idx: 9, loss: 0.375943\u001b[0m\n",
      "\u001b[34mval idx: 10, loss: 0.371096\u001b[0m\n",
      "\u001b[34mval idx: 11, loss: 0.368084\u001b[0m\n",
      "\u001b[34mval idx: 12, loss: 0.36535\u001b[0m\n",
      "\u001b[34mval idx: 13, loss: 0.363251\u001b[0m\n",
      "\u001b[34mval idx: 14, loss: 0.361096\u001b[0m\n",
      "\u001b[34mval idx: 15, loss: 0.358218\u001b[0m\n",
      "\u001b[34mval idx: 16, loss: 0.355953\u001b[0m\n",
      "\u001b[34mval idx: 17, loss: 0.353947\u001b[0m\n",
      "\u001b[34mval idx: 18, loss: 0.352773\u001b[0m\n",
      "\u001b[34mval idx: 19, loss: 0.350834\u001b[0m\n",
      "\u001b[34mval idx: 20, loss: 0.349685\u001b[0m\n",
      "\u001b[34mval idx: 21, loss: 0.348743\u001b[0m\n",
      "\u001b[34mval idx: 22, loss: 0.348098\u001b[0m\n",
      "\u001b[34mval idx: 23, loss: 0.346809\u001b[0m\n",
      "\u001b[34mval idx: 24, loss: 0.345867\u001b[0m\n",
      "\u001b[34mval idx: 25, loss: 0.344721\u001b[0m\n",
      "\u001b[34mval idx: 26, loss: 0.343495\u001b[0m\n",
      "\u001b[34mval idx: 27, loss: 0.343198\u001b[0m\n",
      "\u001b[34mval idx: 28, loss: 0.341852\u001b[0m\n",
      "\u001b[34mval idx: 29, loss: 0.3414\u001b[0m\n",
      "\n",
      "2023-01-23 02:18:12 Uploading - Uploading generated training model\u001b[34mval idx: 30, loss: 0.340813\u001b[0m\n",
      "\u001b[34mval idx: 31, loss: 0.340427\u001b[0m\n",
      "\u001b[34mval idx: 32, loss: 0.340043\u001b[0m\n",
      "\u001b[34mval idx: 33, loss: 0.338873\u001b[0m\n",
      "\u001b[34mval idx: 34, loss: 0.338194\u001b[0m\n",
      "\u001b[34mval idx: 35, loss: 0.337722\u001b[0m\n",
      "\u001b[34mval idx: 36, loss: 0.337209\u001b[0m\n",
      "\u001b[34mval idx: 37, loss: 0.336874\u001b[0m\n",
      "\u001b[34mval idx: 38, loss: 0.336616\u001b[0m\n",
      "\u001b[34mval idx: 39, loss: 0.336122\u001b[0m\n",
      "\u001b[34mval idx: 40, loss: 0.336007\u001b[0m\n",
      "\u001b[34mval idx: 41, loss: 0.335636\u001b[0m\n",
      "\u001b[34mval idx: 42, loss: 0.334372\u001b[0m\n",
      "\u001b[34mval idx: 43, loss: 0.333109\u001b[0m\n",
      "\u001b[34mval idx: 44, loss: 0.332873\u001b[0m\n",
      "\u001b[34mval idx: 45, loss: 0.332575\u001b[0m\n",
      "\u001b[34mval idx: 46, loss: 0.332377\u001b[0m\n",
      "\u001b[34mval idx: 47, loss: 0.331766\u001b[0m\n",
      "\u001b[34mval idx: 48, loss: 0.331288\u001b[0m\n",
      "\u001b[34mval idx: 49, loss: 0.331281\u001b[0m\n",
      "\u001b[34mevaluation results: {'validation_0': OrderedDict([('logloss', [0.588928, 0.519542, 0.47102, 0.436179, 0.409935, 0.389246, 0.374568, 0.362866, 0.354098, 0.347135, 0.341553, 0.337246, 0.334039, 0.330976, 0.329121, 0.326347, 0.324265, 0.322357, 0.321182, 0.319549, 0.318349, 0.317496, 0.316896, 0.315804, 0.314347, 0.313513, 0.312126, 0.311835, 0.310113, 0.309713, 0.309165, 0.308764, 0.308182, 0.307029, 0.306285, 0.305789, 0.305441, 0.305088, 0.304778, 0.304165, 0.303986, 0.303685, 0.30272, 0.301804, 0.30153, 0.301033, 0.300895, 0.300325, 0.299818, 0.299738])]), 'validation_1': OrderedDict([('logloss', [0.590746, 0.525521, 0.481113, 0.450193, 0.427135, 0.409713, 0.39772, 0.3883, 0.38153, 0.375943, 0.371096, 0.368084, 0.36535, 0.363251, 0.361096, 0.358218, 0.355953, 0.353947, 0.352773, 0.350834, 0.349685, 0.348743, 0.348098, 0.346809, 0.345867, 0.344721, 0.343495, 0.343198, 0.341852, 0.3414, 0.340813, 0.340427, 0.340043, 0.338873, 0.338194, 0.337722, 0.337209, 0.336874, 0.336616, 0.336122, 0.336007, 0.335636, 0.334372, 0.333109, 0.332873, 0.332575, 0.332377, 0.331766, 0.331288, 0.331281])])}\u001b[0m\n",
      "\n",
      "2023-01-23 02:18:50 Completed - Training job completed\n",
      "Training seconds: 178\n",
      "Billable seconds: 178\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\":5,\n",
    "    \"eta\":0.2,\n",
    "    \"gamma\":4,\n",
    "    \"min_child_weight\":6,\n",
    "    \"subsample\":0.7,\n",
    "    \"n_estimators\":50,\n",
    "    \"region\" : region}\n",
    "\n",
    "with Run(experiment_name=experiment_name, sagemaker_session=sagemaker_session) as run: \n",
    "    # initialize hyperparameters\n",
    "    output_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "    # this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "    # specify the repo_version depending on your preference.\n",
    "    # xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.5-1\")\n",
    "    # construct a SageMaker estimator that calls the xgboost-container\n",
    "    # estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "    #                                           hyperparameters=hyperparameters,\n",
    "    #                                           role=sagemaker.get_execution_role(),\n",
    "    #                                           instance_count=1, \n",
    "    #                                           instance_type='ml.m5.2xlarge', \n",
    "    #                                           volume_size=10, # 5 GB \n",
    "    #                                           output_path=output_path)\n",
    "    \n",
    "    estimator = XGBoost(entry_point = \"scripts/train.py\", \n",
    "                    framework_version='1.5-1',\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    volume_size =10,\n",
    "                    output_path=output_path)\n",
    "\n",
    "    train_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'train'))\n",
    "    validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'validation'))\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator.fit({'train': train_input, 'validation': validation_input})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae266643-7663-4be3-93c0-3fabfed01712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-869530972998/data/kkbox-customer-churn-model/output/sagemaker-xgboost-2023-01-23-02-14-47-668/output/model.tar.gz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59154738-b276-4712-83e6-2b7b5847a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
