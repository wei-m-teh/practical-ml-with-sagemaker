{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330bac2b-9187-47e9-bece-dd4f889a8dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Improves Data Science Productiity Using SageMaker Studio\n",
    "\n",
    "Using Machine Learning Model to predict customer churn for a Music Streaming Service\n",
    "\n",
    "The notebook is organized into the following sections:\n",
    "\n",
    "* Background\n",
    "* Dataset Exploration\n",
    "* Centralize the feature set with SageMaker Feature Store\n",
    "* Train a model using a SageMaker Training job.\n",
    "* Track and organize data science projects using SageMaker Experiment\n",
    "* Use Sagemaker Debugger to monitor utilization of system resources such as GPUs, CPUs, network, and memory, and profiles the training jobs to collect detailed ML framework metrics.\n",
    "* Automate Hyperparameter Tuning process to find the best model hyperparameters.\n",
    "* Identify bias in the data and the model. Measure model feature importance using SHAP through SageMaker Clarify\n",
    "* Register the model into SageMaker Model Registry\n",
    "* Deploy model into SageMaker Inference to serve churn predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77465a13-c23d-458b-9967-14762479b9e1",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "This particular challenge was originally introduced as a Kaggle competition in 2018. The goal was to build an algorithm that predicts \n",
    "whether a subscription user will churn using a donated dataset from KKBOX. \n",
    "\n",
    "For a subscription business, accurately predicting churn is critical to long-term success. \n",
    "\n",
    "Even slight variations in churn can drastically affect profits.\n",
    "\n",
    "KKBOX is Asia’s leading music streaming service, holding the world’s most comprehensive Asia-Pop music library with over 30 million tracks. They offer a generous, unlimited version of their service to millions of people, supported by advertising and paid subscriptions. This delicate model is dependent on accurately predicting churn of their paid users.\n",
    "\n",
    "In this notebook, we'll explore a machine learning model called XGBoost to predict whether a user will churn after their subscription expires. Currently, the company uses survival analysis techniques to determine the residual membership life time for each subscriber. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81e0fe-811c-4be2-ad20-fc5086f9d101",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We combining multiple datasets, including the subscription, membership and user activity logs to extract the signals for training a machine learning model. We use an EMR cluster to perform the feature engineering work, directly from within SageMaker Studio. For detail about using EMR and Pyspark, please refer to the notebook [here](processing_pyspark.ipynb)\n",
    "\n",
    "In the following section, we'll explore the curated dataset in greater detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac23e0d9-4174-4866-9749-5e1efb0de033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.120.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.131.0-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.20.3)\n",
      "Collecting boto3<2.0,>=1.26.28\n",
      "  Using cached boto3-1.26.62-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (22.1.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Collecting botocore<1.30.0,>=1.29.62\n",
      "  Using cached botocore-1.29.62-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (4.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.62->boto3<2.0,>=1.26.28->sagemaker) (1.26.13)\n",
      "Installing collected packages: importlib-metadata, botocore, boto3, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Uninstalling importlib-metadata-5.1.0:\n",
      "      Successfully uninstalled importlib-metadata-5.1.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.24\n",
      "    Uninstalling botocore-1.29.24:\n",
      "      Successfully uninstalled botocore-1.29.24\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.24\n",
      "    Uninstalling boto3-1.26.24:\n",
      "      Successfully uninstalled boto3-1.26.24\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.120.0\n",
      "    Uninstalling sagemaker-2.120.0:\n",
      "      Successfully uninstalled sagemaker-2.120.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires botocore==1.29.24, but you have botocore 1.29.62 which is incompatible.\n",
      "awscli 1.27.24 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.27.24 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "aiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.62 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.62 botocore-1.29.62 importlib-metadata-4.13.0 sagemaker-2.131.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159afbf-302c-433f-809c-a9a05b936e18",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the Python libraries we'll need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9bac1294-25d2-4d2d-b36e-b7fad3f82cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    HyperbandStrategyConfig,\n",
    "    StrategyConfig\n",
    ")\n",
    "from sagemaker.experiments import load_run\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics, FileSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3af3ee61-1580-4ac8-9535-87b1cf53a2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "prefix = \"data/kkbox-customer-churn-model\"\n",
    "experiment_name = \"kkbox-customer-churn-model-experiment\"\n",
    "content_type = \"csv\"\n",
    "customer_churn_dataset_s3 = f\"{prefix}/processed/all/customer_churn.csv\"\n",
    "s3_model_evaluation_prefix = \"data/kkbox-customer-churn-model/evaluation\"\n",
    "inference_serving_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edfaac9-5b0c-476f-ab5e-fc509f9c35f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acf174-72d7-44dd-a422-9ae11169e903",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c31ae013-f9d7-41d3-94d2-ec29e89a6ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = ['msno', 'is_churn', 'regist_trans', 'mst_frq_plan_days', \n",
    "            'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', \n",
    "            'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', \n",
    "            'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew']\n",
    "\n",
    "churn_df = pd.read_csv(f\"s3://{bucket}/{customer_churn_dataset_s3}\", names=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad573fd-1104-4677-a751-46acf5d2d5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>regist_trans</th>\n",
       "      <th>mst_frq_plan_days</th>\n",
       "      <th>revenue</th>\n",
       "      <th>regist_cancels</th>\n",
       "      <th>bd</th>\n",
       "      <th>tenure</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>...</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>qtr_trans</th>\n",
       "      <th>mst_frq_pay_met</th>\n",
       "      <th>is_auto_renew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>++4RuqBw0Ss6bQU4oMxaRlbBPoWzoEiIZaxPM04Y4+U=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.230844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.341067</td>\n",
       "      <td>1.292343</td>\n",
       "      <td>0.886311</td>\n",
       "      <td>...</td>\n",
       "      <td>13.603248</td>\n",
       "      <td>21.373550</td>\n",
       "      <td>7.728394</td>\n",
       "      <td>2.715068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+/namlXq+u3izRjHCFJV4MgqcXcLidZYszVsROOq/y4=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.095294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.822034</td>\n",
       "      <td>1.423729</td>\n",
       "      <td>1.186441</td>\n",
       "      <td>...</td>\n",
       "      <td>28.584746</td>\n",
       "      <td>46.016949</td>\n",
       "      <td>8.457757</td>\n",
       "      <td>10.832877</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+0/X9tkmyHyet9X80G6GTrDFHnJqvai8d1ZPhayT0os=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.095294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.432647</td>\n",
       "      <td>1.139461</td>\n",
       "      <td>0.838352</td>\n",
       "      <td>...</td>\n",
       "      <td>31.039620</td>\n",
       "      <td>30.091918</td>\n",
       "      <td>8.623620</td>\n",
       "      <td>13.010959</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+0jTOa6KGPk1vtNTwRDMZc/McUo41AeuwV3ndo54Y+Q=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.048788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.446634</td>\n",
       "      <td>2.706076</td>\n",
       "      <td>1.072250</td>\n",
       "      <td>...</td>\n",
       "      <td>16.692939</td>\n",
       "      <td>21.883415</td>\n",
       "      <td>7.874394</td>\n",
       "      <td>3.032877</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+0l+FDuhyjaZnu0APnrg5L9QqgaRw4RmdQMvqOtKDmU=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.182280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.696237</td>\n",
       "      <td>1.327957</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>...</td>\n",
       "      <td>23.787634</td>\n",
       "      <td>29.215054</td>\n",
       "      <td>8.276365</td>\n",
       "      <td>2.043836</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  regist_trans  \\\n",
       "0  ++4RuqBw0Ss6bQU4oMxaRlbBPoWzoEiIZaxPM04Y4+U=         0      3.295837   \n",
       "1  +/namlXq+u3izRjHCFJV4MgqcXcLidZYszVsROOq/y4=         0      3.135494   \n",
       "2  +0/X9tkmyHyet9X80G6GTrDFHnJqvai8d1ZPhayT0os=         0      3.135494   \n",
       "3  +0jTOa6KGPk1vtNTwRDMZc/McUo41AeuwV3ndo54Y+Q=         0      3.091042   \n",
       "4  +0l+FDuhyjaZnu0APnrg5L9QqgaRw4RmdQMvqOtKDmU=         0      3.218876   \n",
       "\n",
       "   mst_frq_plan_days   revenue  regist_cancels  bd     tenure    num_25  \\\n",
       "0           3.433987  8.230844             0.0   0   7.341067  1.292343   \n",
       "1           3.433987  8.095294             0.0   0  20.822034  1.423729   \n",
       "2           3.433987  8.095294             0.0   0   4.432647  1.139461   \n",
       "3           3.433987  8.048788             0.0   0   5.446634  2.706076   \n",
       "4           3.433987  8.182280             0.0   0   6.696237  1.327957   \n",
       "\n",
       "     num_50  ...    num_985    num_100   num_unq  total_secs  city  gender  \\\n",
       "0  0.886311  ...  13.603248  21.373550  7.728394    2.715068   0.0     0.0   \n",
       "1  1.186441  ...  28.584746  46.016949  8.457757   10.832877   5.0     1.0   \n",
       "2  0.838352  ...  31.039620  30.091918  8.623620   13.010959  10.0     1.0   \n",
       "3  1.072250  ...  16.692939  21.883415  7.874394    3.032877   3.0     2.0   \n",
       "4  0.704301  ...  23.787634  29.215054  8.276365    2.043836   2.0     1.0   \n",
       "\n",
       "   registered_via  qtr_trans  mst_frq_pay_met  is_auto_renew  \n",
       "0             0.0        0.0              0.0            0.0  \n",
       "1             1.0        0.0              6.0            0.0  \n",
       "2             1.0        0.0              6.0            0.0  \n",
       "3             1.0        2.0              7.0            0.0  \n",
       "4             3.0        0.0              5.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7585908b-87d3-4747-b071-0dc23a7292d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows: 1570131, columns: 21\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of rows: {churn_df.shape[0]}, columns: {churn_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793142c0-566d-486f-8931-15c4c50a63db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ingest Features into SageMaker Feature Store\n",
    "\n",
    "Since the data is already preprocessed, we'll simply work on ingesting the data into a SageMaker offline store. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569baa6-bd6d-4aa2-b956-42e254df9154",
   "metadata": {},
   "source": [
    "# Feature Store Overview\n",
    "\n",
    "Amazon SageMaker Feature Store is a fully managed, purpose-built repository to store, share, and manage features for machine learning (ML) models. Features are inputs to ML models used during training and inference. Features are used repeatedly by multiple teams and feature quality is critical to ensure a highly accurate model. Also, when features used to train models offline in batch are made available for real-time inference, it’s hard to keep the two feature stores synchronized. SageMaker Feature Store provides a secured and unified store for feature use across the ML lifecycle.\n",
    "\n",
    "![how feature store works](img/sm_feature_store.png)\n",
    "\n",
    "The following cells demonstrates how to get started with Feature Store, create feature groups, and ingest data into them. \n",
    "These feature groups are stored in your Feature Store.\n",
    "\n",
    "Feature groups are resources that contain metadata for all data stored in your Feature Store. A feature group is a logical grouping of features, defined in the feature store to describe records. A feature group’s definition is composed of a list of feature definitions, a record identifier name, and configurations for its online and offline store.\n",
    "\n",
    "* Creating a feature group\n",
    "* Ingest data into a feature group\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f32a3-dbfe-401b-9756-5432d48b00e7",
   "metadata": {},
   "source": [
    "## Create a Feature Group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95a2dc5-cf77-4200-8889-8d9f0b71d421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "import pandas as pd\n",
    "import botocore\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "customer_churn_feature_group_name = \"kkbox-customer-churn-features\"\n",
    "customer_churn_feature_group_s3_prefix = f\"{prefix}/feature-store\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14505e22-25c7-4755-8143-840279fd0a24",
   "metadata": {},
   "source": [
    "Fist we want to see if the feature store is already created. We can use boto3 client for SageMaker to help us with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8970a4-b083-4eed-b3a2-04b129dc04ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a73bb1-2059-41b3-b21a-8ba916814db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_new_fs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b76c11e-9ad0-4499-a747-c2a0224d7c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = response = sm_client.describe_feature_group(\n",
    "        FeatureGroupName=customer_churn_feature_group_name)\n",
    "except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == \"ResourceNotFound\":\n",
    "            create_new_fs = True\n",
    "        else:\n",
    "            raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ba5831-b413-456d-a92e-1d9a2664f170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_event_timestamp():\n",
    "    # naive datetime representing local time\n",
    "    naive_dt = datetime.now()\n",
    "    # take timezone into account\n",
    "    aware_dt = naive_dt.astimezone()\n",
    "    # time in UTC\n",
    "    utc_dt = aware_dt.astimezone(timezone.utc)\n",
    "    # transform to ISO-8601 format\n",
    "    event_time = utc_dt.isoformat(timespec='milliseconds')\n",
    "    event_time = event_time.replace('+00:00', 'Z')\n",
    "    return event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab461a8-7fa9-4214-941f-5e0226b55a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    print(f'Initial status: {status}')\n",
    "    while status == 'Creating':\n",
    "        logger.info(f'Waiting for feature group: {feature_group.name} to be created ...')\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    if status != 'Created':\n",
    "        raise SystemExit(f'Failed to create feature group {feature_group.name}: {status}')\n",
    "    logger.info(f'FeatureGroup {feature_group.name} was successfully created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8814ab-65ab-4121-8ffe-ae97b1ad81d5",
   "metadata": {},
   "source": [
    "Given we are working a pandas dataframe, we could use Sagemaker Feature Store API to infer the schema from the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c0b431-f57d-422b-93ac-d54b939668ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "if create_new_fs:\n",
    "    customer_churn_feature_group = FeatureGroup(\n",
    "        name=customer_churn_feature_group_name, sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    churn_df['event_time'] = generate_event_timestamp()\n",
    "    customer_churn_feature_group.load_feature_definitions(data_frame=churn_df)\n",
    "    customer_churn_feature_group.create(s3_uri=f's3://{bucket}/{customer_churn_feature_group_s3_prefix}', \n",
    "                               record_identifier_name='msno', \n",
    "                               event_time_feature_name='event_time', \n",
    "                               role_arn=role, \n",
    "                               enable_online_store=True)\n",
    "    wait_for_feature_group_creation_complete(customer_churn_feature_group)\n",
    "else:\n",
    "    customer_churn_feature_group = FeatureGroup(\n",
    "        name=customer_churn_feature_group_name, sagemaker_session=sagemaker_session\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ea110-8be1-4912-90e1-c371439a20d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ingest the data into the newly created feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dcd43-a1ae-4a17-8ac8-b5a900ea3d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f'Ingesting data into feature group: {customer_churn_feature_group.name} ...')\n",
    "customer_churn_feature_group.ingest(data_frame=churn_df, max_processes=16, wait=True)\n",
    "logger.info(f'{len(churn_df)} customer records ingested into feature group: {customer_churn_feature_group.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb652f-aa80-4ab3-87f2-cddc4332beed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using the Amazon SageMaker Python SDK to get your data from your feature groups\n",
    "You can use the Feature Store APIs to create a dataset from your feature groups. Data scientists create ML datasets for training by retrieving ML feature data from one or more feature groups in the offline store. Use the create_dataset() function to create the dataset. You can use the SDK to do the following:\n",
    "\n",
    "Create a dataset from multiple feature groups.\n",
    "Create a dataset from the feature groups and a pandas data frame.\n",
    "By default, Feature Store doesn't include records that you've deleted from the dataset. It also doesn't include duplicated records. A duplicate record has the record ID and timestamp value in the event time column. Before you use the SDK to create a dataset, you must start a SageMaker session. Use the following code to start the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "068fd47a-c602-43b1-aeea-8e8c77405c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_store import FeatureStore\n",
    "\n",
    "featurestore_runtime = boto3.client(service_name=\"sagemaker-featurestore-runtime\",region_name=region)\n",
    "feature_store_output_prefix=f\"{prefix}/feature-store-output\"\n",
    "feature_store_session = sagemaker.Session(\n",
    "    sagemaker_client=sm_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d814a40-e8a8-469f-9206-83f85cca3cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = ['msno', 'is_churn', 'regist_trans', 'mst_frq_plan_days', \n",
    "            'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', \n",
    "            'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', \n",
    "            'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew']\n",
    "feature_store = FeatureStore(feature_store_session)\n",
    "builder = feature_store.create_dataset(\n",
    "    base=customer_churn_feature_group,\n",
    "    output_path=f\"s3://{bucket}/{feature_store_output_prefix}\",\n",
    "    included_feature_names=feature_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a5ca01b-db5c-4941-a271-02584589c990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Query 2cbce736-b6ce-4877-8306-ca897be07fd4 is being executed.\n",
      "INFO:sagemaker:Query 2cbce736-b6ce-4877-8306-ca897be07fd4 is being executed.\n",
      "INFO:sagemaker:Query 2cbce736-b6ce-4877-8306-ca897be07fd4 is being executed.\n",
      "INFO:sagemaker:Query 2cbce736-b6ce-4877-8306-ca897be07fd4 is being executed.\n",
      "INFO:sagemaker:Query 2cbce736-b6ce-4877-8306-ca897be07fd4 successfully executed.\n"
     ]
    }
   ],
   "source": [
    "fs_output = builder.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4623c-a0be-4836-82c6-85dcfb15d344",
   "metadata": {
    "tags": []
   },
   "source": [
    "Because the output from the query above is a tuple (dataframe and the SQL query used in fetching the data from the feature store),\n",
    "we'll reference the dataframe for our use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3602458-510e-48db-bde5-bf75efb9f57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = fs_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa57d6-63b7-4bcd-8654-f3777c2f966a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train an XGBoost model using SageMaker Training\n",
    "In the following section, we'll use the data in the feature store to train a model using the dataset in the feature store. \n",
    "Specifically, we'll use the column named \"is_churn\" as the target label, and train a binary classification model to predict customer churn given the \n",
    "input data.\n",
    "\n",
    "First, we will set some hyperparameters for the model, then evaluate the performance based on these hyperparams. We could either tune this set of parameters \n",
    "based on the performance, or use SageMaker auto parameter tuning feature to help us find the most effective paremeters. \n",
    "We'll need to capture the model performance metrics so that we could review the model and make decision about whether to retrain a model, or to proceed to deploy the model in the downstream process.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b98ba-053a-4d49-87aa-9e3f4cf42d16",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, before we train a model, we'll need to split the data into train and test dataset. To do that,  we'll use sklearn library to achieve this objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7a872ce-edc4-4c11-bfb2-7421cf3b7467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0e9262b-7e9b-45f6-9af7-aa5aa2ace1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.drop([\"event_time\"], axis=1, inplace=True) # dropping event_time from the columns since it was added for feature store\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09aa44a-f0e0-4db7-89eb-0a37d6405997",
   "metadata": {},
   "source": [
    "We'll upload the train and test dataset to S3 for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "902ba3be-8f24-44a6-929a-d69da6cf9d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_s3_prefix = f\"{prefix}/input/train\"\n",
    "test_dataset_s3_prefix = f\"{prefix}/input/test\"\n",
    "val_dataset_s3_prefix = f\"{prefix}/input/val\"\n",
    "\n",
    "train.to_csv(f\"s3://{bucket}/{train_dataset_s3_prefix}/train.csv\", index=False, header=False)\n",
    "test.to_csv(f\"s3://{bucket}/{test_dataset_s3_prefix}/test.csv\", index=False, header=False)\n",
    "val.to_csv(f\"s3://{bucket}/{val_dataset_s3_prefix}/val.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cb8005c-9315-4d87-abd8-e62d96b1915b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>regist_trans</th>\n",
       "      <th>mst_frq_plan_days</th>\n",
       "      <th>revenue</th>\n",
       "      <th>regist_cancels</th>\n",
       "      <th>bd</th>\n",
       "      <th>tenure</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>...</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>qtr_trans</th>\n",
       "      <th>mst_frq_pay_met</th>\n",
       "      <th>is_auto_renew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>496039</th>\n",
       "      <td>HSKFilVIP2kVbGVmzcr3vnBLkZ5Z5VnDMDPNQDb5vFM=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.239593</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "      <td>4.923841</td>\n",
       "      <td>0.534768</td>\n",
       "      <td>0.495033</td>\n",
       "      <td>...</td>\n",
       "      <td>26.849338</td>\n",
       "      <td>28.970199</td>\n",
       "      <td>8.482085</td>\n",
       "      <td>4.098630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267882</th>\n",
       "      <td>+w0pdN48/gWA22LFznPjXuUQnXqLfjrGHQ/ubboZ0Mk=</td>\n",
       "      <td>0</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>7.509883</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "      <td>9.505917</td>\n",
       "      <td>4.677515</td>\n",
       "      <td>3.221893</td>\n",
       "      <td>...</td>\n",
       "      <td>84.772189</td>\n",
       "      <td>60.778107</td>\n",
       "      <td>9.856640</td>\n",
       "      <td>1.010959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220198</th>\n",
       "      <td>JCidxiRvGGq9C+YZD9o9c0vWXEBjDCwlCCsV0trekyM=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.048788</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>6.110368</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.588629</td>\n",
       "      <td>...</td>\n",
       "      <td>117.899666</td>\n",
       "      <td>77.341137</td>\n",
       "      <td>9.540826</td>\n",
       "      <td>10.268493</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646547</th>\n",
       "      <td>FzMY8Z7yxKVh2cQ/QfumjSiGspsjctozK+06wGKadbI=</td>\n",
       "      <td>0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>7.594381</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>5.941994</td>\n",
       "      <td>1.493841</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>...</td>\n",
       "      <td>24.619346</td>\n",
       "      <td>25.098488</td>\n",
       "      <td>7.977952</td>\n",
       "      <td>3.575661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30860</th>\n",
       "      <td>8UqlJXmPq8BwWdK49bCWPIyzxIud1pJlDDe7iUeduys=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>7.591357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.883436</td>\n",
       "      <td>2.297546</td>\n",
       "      <td>0.984663</td>\n",
       "      <td>...</td>\n",
       "      <td>16.880368</td>\n",
       "      <td>23.634969</td>\n",
       "      <td>7.841221</td>\n",
       "      <td>1.715068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                msno  is_churn  regist_trans  \\\n",
       "496039  HSKFilVIP2kVbGVmzcr3vnBLkZ5Z5VnDMDPNQDb5vFM=         0      3.258097   \n",
       "267882  +w0pdN48/gWA22LFznPjXuUQnXqLfjrGHQ/ubboZ0Mk=         0      2.397895   \n",
       "220198  JCidxiRvGGq9C+YZD9o9c0vWXEBjDCwlCCsV0trekyM=         0      3.178054   \n",
       "646547  FzMY8Z7yxKVh2cQ/QfumjSiGspsjctozK+06wGKadbI=         0      2.772589   \n",
       "30860   8UqlJXmPq8BwWdK49bCWPIyzxIud1pJlDDe7iUeduys=         0      3.044522   \n",
       "\n",
       "        mst_frq_plan_days   revenue  regist_cancels  bd    tenure    num_25  \\\n",
       "496039           3.433987  8.239593        1.098612   0  4.923841  0.534768   \n",
       "267882           3.433987  7.509883        1.098612   0  9.505917  4.677515   \n",
       "220198           3.433987  8.048788        0.693147   0  6.110368  2.000000   \n",
       "646547           3.433987  7.594381        0.693147   0  5.941994  1.493841   \n",
       "30860            3.433987  7.591357        0.000000   0  8.883436  2.297546   \n",
       "\n",
       "          num_50  ...     num_985    num_100   num_unq  total_secs  city  \\\n",
       "496039  0.495033  ...   26.849338  28.970199  8.482085    4.098630   2.0   \n",
       "267882  3.221893  ...   84.772189  60.778107  9.856640    1.010959   4.0   \n",
       "220198  1.588629  ...  117.899666  77.341137  9.540826   10.268493  10.0   \n",
       "646547  0.897251  ...   24.619346  25.098488  7.977952    3.575661   1.0   \n",
       "30860   0.984663  ...   16.880368  23.634969  7.841221    1.715068   0.0   \n",
       "\n",
       "        gender  registered_via  qtr_trans  mst_frq_pay_met  is_auto_renew  \n",
       "496039     2.0             1.0        2.0              1.0            0.0  \n",
       "267882     1.0             4.0        2.0              1.0            1.0  \n",
       "220198     1.0             1.0        3.0              1.0            0.0  \n",
       "646547     0.0             2.0        0.0              0.0            0.0  \n",
       "30860      0.0             0.0        2.0              0.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93047b3b-5e4a-4d44-b220-2807713ac2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Experiment\n",
    "Amazon SageMaker Experiments is a capability of Amazon SageMaker that lets you create, manage, analyze, and compare your machine learning experiments.\n",
    "Because machine learning is an iterative process, we need to experiment with multiple combinations of data, algorithms, and parameters, all while observing the impact of incremental changes on model accuracy. Over time, this iterative experimentation can result in thousands of model training runs and model versions. This makes it hard to track the best performing models and their input configurations. It’s also difficult to compare active experiments with past experiments to identify opportunities for further incremental improvements. Use SageMaker Experiments to organize, view, analyze, and compare iterative ML experimentation to gain comparative insights and track your best performing models.\n",
    "\n",
    "SageMaker Experiments automatically tracks the inputs, parameters, configurations, and results of your iterations as runs. You can assign, group, and organize these runs into experiments. SageMaker Experiments is integrated with Amazon SageMaker Studio, providing a visual interface to browse your active and past experiments, compare runs on key performance metrics, and identify the best performing models. SageMaker Experiments tracks all of the steps and artifacts that went into creating a model, and you can quickly revisit the origins of a model when you are troubleshooting issues in production, or auditing your models for compliance verifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a46122-ca79-4d11-9c41-f436eceda15f",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Debugger\n",
    "With Amazon SageMaker Debugger, you can debug models during training. During training, Debugger periodicially saves tensors, which specify the state of the model at that point in time. Debugger saves the tensors to Amazon S3 for analysis and visualization. This allows you to diagnose training issues with Studio.\n",
    "\n",
    "# Specify Debugger rules\n",
    "To enable automated detection of common issues during training, you can attach a list of rules to evaluate the training job against.\n",
    "\n",
    "For our project, we'll configure the following rules:\n",
    "\n",
    "* LossNotDecreasing rule -- triggered if the loss doesn't decrease monotonically at any point during training\n",
    "* Overtraining rule -- Triggered when the model approaches to a minimum of the loss function and does not improve anymore.\n",
    "* Overfit rule -- This rule detects if your model is being overfit to the training data by comparing the validation and training losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67ec1ddb-aa28-4afc-b366-850ffe90a553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import rule_configs, Rule\n",
    "\n",
    "debug_rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.overfit())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53d69fbb-cab8-4864-b1b9-27e50bf3d67d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.2xlarge.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: kkbox-customer-churn-training-2023-02-02-00-44-54-410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 00:44:54 Starting - Starting the training job...\n",
      "2023-02-02 00:45:14 Starting - Preparing the instances for trainingLossNotDecreasing: InProgress\n",
      "Overtraining: InProgress\n",
      "Overfit: InProgress\n",
      "......\n",
      "2023-02-02 00:46:25 Downloading - Downloading input data......\n",
      "2023-02-02 00:47:26 Training - Training image download completed. Training in progress.\u001b[34m[2023-02-02 00:47:11.647 ip-10-0-74-164.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Module train-fs does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:11:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-fs\n",
      "  Building wheel for train-fs (setup.py): started\n",
      "  Building wheel for train-fs (setup.py): finished with status 'done'\n",
      "  Created wheel for train-fs: filename=train_fs-1.0.0-py2.py3-none-any.whl size=7105 sha256=b6b676024e51f6bb88a50effabf73c789a7be43954ff59a4745a1de4487f1949\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-lv4jkrmj/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built train-fs\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-fs\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-fs-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:13:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-02-02:00:47:13:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.2,\n",
      "        \"gamma\": 4,\n",
      "        \"max_depth\": 5,\n",
      "        \"min_child_weight\": 6,\n",
      "        \"n_estimators\": 500,\n",
      "        \"region\": \"us-east-1\",\n",
      "        \"subsample\": 0.7\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"kkbox-customer-churn-training-2023-02-02-00-44-54-410\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-00-44-54-410/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-fs\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-fs.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"n_estimators\":500,\"region\":\"us-east-1\",\"subsample\":0.7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-fs.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-fs\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-00-44-54-410/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"max_depth\":5,\"min_child_weight\":6,\"n_estimators\":500,\"region\":\"us-east-1\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"kkbox-customer-churn-training-2023-02-02-00-44-54-410\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-00-44-54-410/source/sourcedir.tar.gz\",\"module_name\":\"train-fs\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-fs.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--n_estimators\",\"500\",\"--region\",\"us-east-1\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=500\u001b[0m\n",
      "\u001b[34mSM_HP_REGION=us-east-1\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train-fs --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --n_estimators 500 --region us-east-1 --subsample 0.7\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.131.0.tar.gz (665 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 665.5/665.5 kB 23.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug in /miniconda3/lib/python3.8/site-packages (1.0.10)\u001b[0m\n",
      "\u001b[34mCollecting smdebug\n",
      "  Downloading smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 270.1/270.1 kB 6.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting attrs<23,>=20.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 18.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.62-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 5.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 17.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyinstrument==3.4.2\n",
      "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.3/83.3 kB 14.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyinstrument-cext>=0.2.2\n",
      "  Downloading pyinstrument_cext-0.2.4-cp38-cp38-manylinux2010_x86_64.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.30.0,>=1.29.62\n",
      "  Downloading botocore-1.29.62-py3-none-any.whl (10.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.4/10.4 MB 99.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 9.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.12.0-py3-none-any.whl (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /miniconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 11.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 28.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.62->boto3<2.0,>=1.26.28->sagemaker) (1.26.5)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.131.0-py2.py3-none-any.whl size=902760 sha256=dc84a7f150f511a9d6d81cd15d8e02d8671f9e7b4da60b8aeb764ee37e38b5f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/a2/7e/daeaa6ecdd8aa0c3786fabba91ec5f9339f17556a121dfd690\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=6fbf046f6895a9ef218870d17a29f13bd53823b6f4450283fd4da22de55b9f09\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyinstrument-cext, zipp, smdebug_rulesconfig, pyinstrument, protobuf3-to-dict, ppft, pox, google-pasta, dill, contextlib2, attrs, schema, multiprocess, importlib-metadata, botocore, s3transfer, pathos, boto3, smdebug, sagemaker\n",
      "  Attempting uninstall: pyinstrument\n",
      "    Found existing installation: pyinstrument 4.3.0\n",
      "    Uninstalling pyinstrument-4.3.0:\n",
      "      Successfully uninstalled pyinstrument-4.3.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\n",
      "  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.10\n",
      "    Uninstalling smdebug-1.0.10:\n",
      "      Successfully uninstalled smdebug-1.0.10\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.26.62 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.29.62 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires smdebug==1.0.10, but you have smdebug 1.0.12 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-22.2.0 boto3-1.26.62 botocore-1.29.62 contextlib2-21.6.0 dill-0.3.6 google-pasta-0.2.0 importlib-metadata-4.13.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyinstrument-3.4.2 pyinstrument-cext-0.2.4 s3transfer-0.6.0 sagemaker-2.131.0 schema-0.7.5 smdebug-1.0.12 smdebug_rulesconfig-1.0.1 zipp-3.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2023-02-02 00:47:22.152 ip-10-0-74-164.ec2.internal:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-02-02 00:47:22.175 ip-10-0-74-164.ec2.internal:39 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mtrain_dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mval_dir: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mINFO:sagemaker.experiments.run:The run (sagemaker-run-1675298693-c5bd) under experiment (kkbox-customer-churn-model-experiment) already exists. Loading it. Note: sagemaker.experiments.load_run is recommended to use when the desired run already exists.\u001b[0m\n",
      "\u001b[34m[2023-02-02 00:47:43.116 ip-10-0-74-164.ec2.internal:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-02-02 00:47:43.117 ip-10-0-74-164.ec2.internal:39 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-02-02 00:47:43.117 ip-10-0-74-164.ec2.internal:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mERROR:root:0,3.258096538021482,3.4339872044851463,8.239593454305968,1.0986122886681096,0,4.923841059602649,0.5347682119205298,0.4950331125827814,0.5149006622516556,26.84933774834437,28.97019867549669,8.482085415500888,4.098630136986301,2.0,2.0,1.0,2.0,1.0,0.0\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mERROR:root:0,3.295836866004329,3.4339872044851463,8.262300941787448,0.0,0,25.3960396039604,2.915134370579916,1.654879773691655,2.2701555869872703,14.882602545968885,38.844413012729845,8.100366679331,4.69041095890411,0.0,0.0,0.0,0.0,0.0,0.0\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\u001b[0m\n",
      "\u001b[34m[00:47:44] WARNING: ../src/learner.cc:576: \u001b[0m\n",
      "\u001b[34mParameters: { \"callbacks\" } might not be used.\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\u001b[0m\n",
      "\u001b[34m[00:47:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-logloss:0.54344#011validation_1-logloss:0.54366\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-logloss:0.44312#011validation_1-logloss:0.44338\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-logloss:0.37175#011validation_1-logloss:0.37211\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-logloss:0.31907#011validation_1-logloss:0.31951\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-logloss:0.27924#011validation_1-logloss:0.27971\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-logloss:0.24857#011validation_1-logloss:0.24920\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-logloss:0.22480#011validation_1-logloss:0.22553\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-logloss:0.20618#011validation_1-logloss:0.20690\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-logloss:0.19159#011validation_1-logloss:0.19227\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-logloss:0.17989#011validation_1-logloss:0.18074\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-logloss:0.17056#011validation_1-logloss:0.17150\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-logloss:0.16313#011validation_1-logloss:0.16405\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-logloss:0.15687#011validation_1-logloss:0.15779\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-logloss:0.15198#011validation_1-logloss:0.15293\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-logloss:0.14782#011validation_1-logloss:0.14872\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-logloss:0.14464#011validation_1-logloss:0.14562\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-logloss:0.14217#011validation_1-logloss:0.14311\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-logloss:0.13988#011validation_1-logloss:0.14084\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-logloss:0.13786#011validation_1-logloss:0.13889\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-logloss:0.13642#011validation_1-logloss:0.13748\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-logloss:0.13529#011validation_1-logloss:0.13638\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-logloss:0.13431#011validation_1-logloss:0.13544\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-logloss:0.13347#011validation_1-logloss:0.13465\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-logloss:0.13280#011validation_1-logloss:0.13401\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-logloss:0.13167#011validation_1-logloss:0.13276\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-logloss:0.13091#011validation_1-logloss:0.13205\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-logloss:0.13022#011validation_1-logloss:0.13132\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-logloss:0.12976#011validation_1-logloss:0.13085\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-logloss:0.12924#011validation_1-logloss:0.13037\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-logloss:0.12862#011validation_1-logloss:0.12974\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-logloss:0.12827#011validation_1-logloss:0.12941\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-logloss:0.12802#011validation_1-logloss:0.12923\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-logloss:0.12775#011validation_1-logloss:0.12897\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-logloss:0.12742#011validation_1-logloss:0.12865\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-logloss:0.12734#011validation_1-logloss:0.12859\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-logloss:0.12719#011validation_1-logloss:0.12845\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-logloss:0.12698#011validation_1-logloss:0.12827\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-logloss:0.12653#011validation_1-logloss:0.12783\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-logloss:0.12617#011validation_1-logloss:0.12751\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-logloss:0.12594#011validation_1-logloss:0.12728\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-logloss:0.12565#011validation_1-logloss:0.12704\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-logloss:0.12545#011validation_1-logloss:0.12689\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-logloss:0.12503#011validation_1-logloss:0.12649\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-logloss:0.12489#011validation_1-logloss:0.12635\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-logloss:0.12460#011validation_1-logloss:0.12607\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-logloss:0.12436#011validation_1-logloss:0.12585\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-logloss:0.12419#011validation_1-logloss:0.12570\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-logloss:0.12398#011validation_1-logloss:0.12551\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-logloss:0.12394#011validation_1-logloss:0.12547\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-logloss:0.12388#011validation_1-logloss:0.12543\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-logloss:0.12351#011validation_1-logloss:0.12504\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-logloss:0.12339#011validation_1-logloss:0.12495\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-logloss:0.12333#011validation_1-logloss:0.12490\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-logloss:0.12321#011validation_1-logloss:0.12482\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-logloss:0.12314#011validation_1-logloss:0.12477\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-logloss:0.12311#011validation_1-logloss:0.12474\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-logloss:0.12294#011validation_1-logloss:0.12458\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-logloss:0.12276#011validation_1-logloss:0.12444\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-logloss:0.12255#011validation_1-logloss:0.12426\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-logloss:0.12240#011validation_1-logloss:0.12411\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-logloss:0.12213#011validation_1-logloss:0.12383\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-logloss:0.12208#011validation_1-logloss:0.12381\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-logloss:0.12204#011validation_1-logloss:0.12379\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-logloss:0.12199#011validation_1-logloss:0.12376\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-logloss:0.12193#011validation_1-logloss:0.12370\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-logloss:0.12187#011validation_1-logloss:0.12367\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-logloss:0.12168#011validation_1-logloss:0.12350\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-logloss:0.12164#011validation_1-logloss:0.12347\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-logloss:0.12127#011validation_1-logloss:0.12316\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-logloss:0.12099#011validation_1-logloss:0.12287\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-logloss:0.12093#011validation_1-logloss:0.12286\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-logloss:0.12061#011validation_1-logloss:0.12254\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-logloss:0.12058#011validation_1-logloss:0.12254\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-logloss:0.12053#011validation_1-logloss:0.12252\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-logloss:0.12040#011validation_1-logloss:0.12241\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-logloss:0.12029#011validation_1-logloss:0.12231\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-logloss:0.12026#011validation_1-logloss:0.12230\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-logloss:0.12023#011validation_1-logloss:0.12229\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-logloss:0.12010#011validation_1-logloss:0.12220\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-logloss:0.12005#011validation_1-logloss:0.12221\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-logloss:0.12001#011validation_1-logloss:0.12221\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-logloss:0.11995#011validation_1-logloss:0.12221\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-logloss:0.11987#011validation_1-logloss:0.12218\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-logloss:0.11978#011validation_1-logloss:0.12208\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-logloss:0.11959#011validation_1-logloss:0.12190\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-logloss:0.11951#011validation_1-logloss:0.12185\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-logloss:0.11948#011validation_1-logloss:0.12183\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-logloss:0.11942#011validation_1-logloss:0.12182\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-logloss:0.11933#011validation_1-logloss:0.12175\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-logloss:0.11929#011validation_1-logloss:0.12174\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-logloss:0.11901#011validation_1-logloss:0.12145\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-logloss:0.11899#011validation_1-logloss:0.12145\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-logloss:0.11894#011validation_1-logloss:0.12145\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-logloss:0.11871#011validation_1-logloss:0.12120\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-logloss:0.11865#011validation_1-logloss:0.12118\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-logloss:0.11861#011validation_1-logloss:0.12116\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-logloss:0.11858#011validation_1-logloss:0.12115\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-logloss:0.11853#011validation_1-logloss:0.12116\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-logloss:0.11844#011validation_1-logloss:0.12112\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-logloss:0.11842#011validation_1-logloss:0.12112\u001b[0m\n",
      "\u001b[34m[100]#011validation_0-logloss:0.11838#011validation_1-logloss:0.12113\u001b[0m\n",
      "\u001b[34m[101]#011validation_0-logloss:0.11836#011validation_1-logloss:0.12114\u001b[0m\n",
      "\u001b[34m[102]#011validation_0-logloss:0.11830#011validation_1-logloss:0.12112\u001b[0m\n",
      "\u001b[34m[103]#011validation_0-logloss:0.11829#011validation_1-logloss:0.12112\u001b[0m\n",
      "\u001b[34m[104]#011validation_0-logloss:0.11827#011validation_1-logloss:0.12111\u001b[0m\n",
      "\u001b[34m[105]#011validation_0-logloss:0.11824#011validation_1-logloss:0.12110\u001b[0m\n",
      "\u001b[34m[106]#011validation_0-logloss:0.11823#011validation_1-logloss:0.12111\u001b[0m\n",
      "\u001b[34m[107]#011validation_0-logloss:0.11818#011validation_1-logloss:0.12108\u001b[0m\n",
      "\u001b[34m[108]#011validation_0-logloss:0.11795#011validation_1-logloss:0.12091\u001b[0m\n",
      "\u001b[34m[109]#011validation_0-logloss:0.11791#011validation_1-logloss:0.12090\u001b[0m\n",
      "\u001b[34m[110]#011validation_0-logloss:0.11784#011validation_1-logloss:0.12087\u001b[0m\n",
      "\u001b[34m[111]#011validation_0-logloss:0.11775#011validation_1-logloss:0.12081\u001b[0m\n",
      "\u001b[34m[112]#011validation_0-logloss:0.11774#011validation_1-logloss:0.12080\u001b[0m\n",
      "\u001b[34m[113]#011validation_0-logloss:0.11754#011validation_1-logloss:0.12060\u001b[0m\n",
      "\u001b[34m[114]#011validation_0-logloss:0.11750#011validation_1-logloss:0.12059\u001b[0m\n",
      "\u001b[34m[115]#011validation_0-logloss:0.11737#011validation_1-logloss:0.12050\u001b[0m\n",
      "\u001b[34m[116]#011validation_0-logloss:0.11735#011validation_1-logloss:0.12049\u001b[0m\n",
      "\u001b[34m[117]#011validation_0-logloss:0.11733#011validation_1-logloss:0.12050\u001b[0m\n",
      "\u001b[34m[118]#011validation_0-logloss:0.11728#011validation_1-logloss:0.12051\u001b[0m\n",
      "\u001b[34m[119]#011validation_0-logloss:0.11723#011validation_1-logloss:0.12051\u001b[0m\n",
      "\u001b[34m[120]#011validation_0-logloss:0.11722#011validation_1-logloss:0.12051\u001b[0m\n",
      "\u001b[34m[121]#011validation_0-logloss:0.11705#011validation_1-logloss:0.12036\u001b[0m\n",
      "\u001b[34m[122]#011validation_0-logloss:0.11702#011validation_1-logloss:0.12036\u001b[0m\n",
      "\u001b[34m[123]#011validation_0-logloss:0.11697#011validation_1-logloss:0.12035\u001b[0m\n",
      "\u001b[34m[124]#011validation_0-logloss:0.11692#011validation_1-logloss:0.12031\u001b[0m\n",
      "\u001b[34m[125]#011validation_0-logloss:0.11687#011validation_1-logloss:0.12030\u001b[0m\n",
      "\u001b[34m[126]#011validation_0-logloss:0.11685#011validation_1-logloss:0.12030\u001b[0m\n",
      "\u001b[34m[127]#011validation_0-logloss:0.11673#011validation_1-logloss:0.12022\u001b[0m\n",
      "\u001b[34m[128]#011validation_0-logloss:0.11669#011validation_1-logloss:0.12023\u001b[0m\n",
      "\u001b[34m[129]#011validation_0-logloss:0.11660#011validation_1-logloss:0.12015\u001b[0m\n",
      "\u001b[34m[130]#011validation_0-logloss:0.11656#011validation_1-logloss:0.12016\u001b[0m\n",
      "\u001b[34m[131]#011validation_0-logloss:0.11653#011validation_1-logloss:0.12015\u001b[0m\n",
      "\u001b[34m[132]#011validation_0-logloss:0.11646#011validation_1-logloss:0.12014\u001b[0m\n",
      "\u001b[34m[133]#011validation_0-logloss:0.11640#011validation_1-logloss:0.12011\u001b[0m\n",
      "\u001b[34m[134]#011validation_0-logloss:0.11635#011validation_1-logloss:0.12009\u001b[0m\n",
      "\u001b[34m[135]#011validation_0-logloss:0.11634#011validation_1-logloss:0.12010\u001b[0m\n",
      "\u001b[34m[136]#011validation_0-logloss:0.11629#011validation_1-logloss:0.12009\u001b[0m\n",
      "\u001b[34m[137]#011validation_0-logloss:0.11627#011validation_1-logloss:0.12010\u001b[0m\n",
      "\u001b[34m[138]#011validation_0-logloss:0.11619#011validation_1-logloss:0.12004\u001b[0m\n",
      "\u001b[34m[139]#011validation_0-logloss:0.11612#011validation_1-logloss:0.12001\u001b[0m\n",
      "\u001b[34m[140]#011validation_0-logloss:0.11609#011validation_1-logloss:0.12001\u001b[0m\n",
      "\u001b[34m[141]#011validation_0-logloss:0.11606#011validation_1-logloss:0.12001\u001b[0m\n",
      "\u001b[34m[142]#011validation_0-logloss:0.11592#011validation_1-logloss:0.11991\u001b[0m\n",
      "\u001b[34m[143]#011validation_0-logloss:0.11589#011validation_1-logloss:0.11991\u001b[0m\n",
      "\u001b[34m[144]#011validation_0-logloss:0.11578#011validation_1-logloss:0.11983\u001b[0m\n",
      "\u001b[34m[145]#011validation_0-logloss:0.11577#011validation_1-logloss:0.11982\u001b[0m\n",
      "\u001b[34m[146]#011validation_0-logloss:0.11574#011validation_1-logloss:0.11982\u001b[0m\n",
      "\u001b[34m[147]#011validation_0-logloss:0.11568#011validation_1-logloss:0.11983\u001b[0m\n",
      "\u001b[34m[148]#011validation_0-logloss:0.11565#011validation_1-logloss:0.11982\u001b[0m\n",
      "\u001b[34m[149]#011validation_0-logloss:0.11564#011validation_1-logloss:0.11981\u001b[0m\n",
      "\u001b[34m[150]#011validation_0-logloss:0.11555#011validation_1-logloss:0.11973\u001b[0m\n",
      "\u001b[34m[151]#011validation_0-logloss:0.11553#011validation_1-logloss:0.11974\u001b[0m\n",
      "\u001b[34m[152]#011validation_0-logloss:0.11543#011validation_1-logloss:0.11965\u001b[0m\n",
      "\u001b[34m[153]#011validation_0-logloss:0.11540#011validation_1-logloss:0.11965\u001b[0m\n",
      "\u001b[34m[154]#011validation_0-logloss:0.11538#011validation_1-logloss:0.11965\u001b[0m\n",
      "\u001b[34m[155]#011validation_0-logloss:0.11533#011validation_1-logloss:0.11965\u001b[0m\n",
      "\u001b[34m[156]#011validation_0-logloss:0.11523#011validation_1-logloss:0.11955\u001b[0m\n",
      "\u001b[34m[157]#011validation_0-logloss:0.11502#011validation_1-logloss:0.11932\u001b[0m\n",
      "\u001b[34m[158]#011validation_0-logloss:0.11498#011validation_1-logloss:0.11933\u001b[0m\n",
      "\u001b[34m[159]#011validation_0-logloss:0.11497#011validation_1-logloss:0.11933\u001b[0m\n",
      "\u001b[34m[160]#011validation_0-logloss:0.11487#011validation_1-logloss:0.11924\u001b[0m\n",
      "\u001b[34m[161]#011validation_0-logloss:0.11483#011validation_1-logloss:0.11923\u001b[0m\n",
      "\u001b[34m[162]#011validation_0-logloss:0.11475#011validation_1-logloss:0.11918\u001b[0m\n",
      "\u001b[34m[163]#011validation_0-logloss:0.11470#011validation_1-logloss:0.11916\u001b[0m\n",
      "\u001b[34m[164]#011validation_0-logloss:0.11468#011validation_1-logloss:0.11914\u001b[0m\n",
      "\u001b[34m[165]#011validation_0-logloss:0.11464#011validation_1-logloss:0.11912\u001b[0m\n",
      "\u001b[34m[166]#011validation_0-logloss:0.11460#011validation_1-logloss:0.11911\u001b[0m\n",
      "\u001b[34m[167]#011validation_0-logloss:0.11452#011validation_1-logloss:0.11906\u001b[0m\n",
      "\u001b[34m[168]#011validation_0-logloss:0.11442#011validation_1-logloss:0.11899\u001b[0m\n",
      "\u001b[34m[169]#011validation_0-logloss:0.11437#011validation_1-logloss:0.11896\u001b[0m\n",
      "\u001b[34m[170]#011validation_0-logloss:0.11435#011validation_1-logloss:0.11896\u001b[0m\n",
      "\u001b[34m[171]#011validation_0-logloss:0.11425#011validation_1-logloss:0.11889\u001b[0m\n",
      "\u001b[34m[172]#011validation_0-logloss:0.11419#011validation_1-logloss:0.11882\u001b[0m\n",
      "\u001b[34m[173]#011validation_0-logloss:0.11416#011validation_1-logloss:0.11882\u001b[0m\n",
      "\u001b[34m[174]#011validation_0-logloss:0.11412#011validation_1-logloss:0.11882\u001b[0m\n",
      "\u001b[34m[175]#011validation_0-logloss:0.11411#011validation_1-logloss:0.11882\u001b[0m\n",
      "\u001b[34m[176]#011validation_0-logloss:0.11409#011validation_1-logloss:0.11881\u001b[0m\n",
      "\u001b[34m[177]#011validation_0-logloss:0.11407#011validation_1-logloss:0.11881\u001b[0m\n",
      "\u001b[34m[178]#011validation_0-logloss:0.11400#011validation_1-logloss:0.11877\u001b[0m\n",
      "\u001b[34m[179]#011validation_0-logloss:0.11389#011validation_1-logloss:0.11870\u001b[0m\n",
      "\u001b[34m[180]#011validation_0-logloss:0.11386#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[181]#011validation_0-logloss:0.11383#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[182]#011validation_0-logloss:0.11382#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[183]#011validation_0-logloss:0.11376#011validation_1-logloss:0.11866\u001b[0m\n",
      "\u001b[34m[184]#011validation_0-logloss:0.11374#011validation_1-logloss:0.11866\u001b[0m\n",
      "\u001b[34m[185]#011validation_0-logloss:0.11371#011validation_1-logloss:0.11866\u001b[0m\n",
      "\u001b[34m[186]#011validation_0-logloss:0.11367#011validation_1-logloss:0.11867\u001b[0m\n",
      "\u001b[34m[187]#011validation_0-logloss:0.11365#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[188]#011validation_0-logloss:0.11361#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[189]#011validation_0-logloss:0.11360#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[190]#011validation_0-logloss:0.11356#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[191]#011validation_0-logloss:0.11353#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[192]#011validation_0-logloss:0.11352#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[193]#011validation_0-logloss:0.11348#011validation_1-logloss:0.11869\u001b[0m\n",
      "\u001b[34m[194]#011validation_0-logloss:0.11345#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[195]#011validation_0-logloss:0.11345#011validation_1-logloss:0.11868\u001b[0m\n",
      "\u001b[34m[196]#011validation_0-logloss:0.11342#011validation_1-logloss:0.11867\u001b[0m\n",
      "\u001b[34m[197]#011validation_0-logloss:0.11338#011validation_1-logloss:0.11866\u001b[0m\n",
      "\u001b[34m[198]#011validation_0-logloss:0.11335#011validation_1-logloss:0.11867\u001b[0m\n",
      "\u001b[34m[199]#011validation_0-logloss:0.11324#011validation_1-logloss:0.11857\u001b[0m\n",
      "\u001b[34m[200]#011validation_0-logloss:0.11321#011validation_1-logloss:0.11858\u001b[0m\n",
      "\u001b[34m[201]#011validation_0-logloss:0.11317#011validation_1-logloss:0.11859\u001b[0m\n",
      "\u001b[34m[202]#011validation_0-logloss:0.11310#011validation_1-logloss:0.11854\u001b[0m\n",
      "\u001b[34m[203]#011validation_0-logloss:0.11296#011validation_1-logloss:0.11841\u001b[0m\n",
      "\u001b[34m[204]#011validation_0-logloss:0.11295#011validation_1-logloss:0.11841\u001b[0m\n",
      "\u001b[34m[205]#011validation_0-logloss:0.11292#011validation_1-logloss:0.11841\u001b[0m\n",
      "\u001b[34m[206]#011validation_0-logloss:0.11290#011validation_1-logloss:0.11841\u001b[0m\n",
      "\u001b[34m[207]#011validation_0-logloss:0.11289#011validation_1-logloss:0.11842\u001b[0m\n",
      "\u001b[34m[208]#011validation_0-logloss:0.11282#011validation_1-logloss:0.11837\u001b[0m\n",
      "\u001b[34m[209]#011validation_0-logloss:0.11282#011validation_1-logloss:0.11838\u001b[0m\n",
      "\u001b[34m[210]#011validation_0-logloss:0.11280#011validation_1-logloss:0.11839\u001b[0m\n",
      "\u001b[34m[211]#011validation_0-logloss:0.11276#011validation_1-logloss:0.11838\u001b[0m\n",
      "\u001b[34m[212]#011validation_0-logloss:0.11268#011validation_1-logloss:0.11833\u001b[0m\n",
      "\u001b[34m[213]#011validation_0-logloss:0.11263#011validation_1-logloss:0.11836\u001b[0m\n",
      "\u001b[34m[214]#011validation_0-logloss:0.11262#011validation_1-logloss:0.11836\u001b[0m\n",
      "\u001b[34m[215]#011validation_0-logloss:0.11257#011validation_1-logloss:0.11833\u001b[0m\n",
      "\u001b[34m[216]#011validation_0-logloss:0.11253#011validation_1-logloss:0.11834\u001b[0m\n",
      "\u001b[34m[217]#011validation_0-logloss:0.11249#011validation_1-logloss:0.11834\u001b[0m\n",
      "\u001b[34m[218]#011validation_0-logloss:0.11243#011validation_1-logloss:0.11830\u001b[0m\n",
      "\u001b[34m[219]#011validation_0-logloss:0.11231#011validation_1-logloss:0.11818\u001b[0m\n",
      "\u001b[34m[220]#011validation_0-logloss:0.11229#011validation_1-logloss:0.11818\u001b[0m\n",
      "\u001b[34m[221]#011validation_0-logloss:0.11226#011validation_1-logloss:0.11819\u001b[0m\n",
      "\u001b[34m[222]#011validation_0-logloss:0.11223#011validation_1-logloss:0.11819\u001b[0m\n",
      "\u001b[34m[223]#011validation_0-logloss:0.11214#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[224]#011validation_0-logloss:0.11212#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[225]#011validation_0-logloss:0.11210#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[226]#011validation_0-logloss:0.11209#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[227]#011validation_0-logloss:0.11209#011validation_1-logloss:0.11811\u001b[0m\n",
      "\u001b[34m[228]#011validation_0-logloss:0.11207#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[229]#011validation_0-logloss:0.11205#011validation_1-logloss:0.11812\u001b[0m\n",
      "\u001b[34m[230]#011validation_0-logloss:0.11200#011validation_1-logloss:0.11810\u001b[0m\n",
      "\u001b[34m[231]#011validation_0-logloss:0.11195#011validation_1-logloss:0.11809\u001b[0m\n",
      "\u001b[34m[232]#011validation_0-logloss:0.11192#011validation_1-logloss:0.11810\u001b[0m\n",
      "\u001b[34m[233]#011validation_0-logloss:0.11186#011validation_1-logloss:0.11806\u001b[0m\n",
      "\u001b[34m[234]#011validation_0-logloss:0.11183#011validation_1-logloss:0.11807\u001b[0m\n",
      "\u001b[34m[235]#011validation_0-logloss:0.11181#011validation_1-logloss:0.11807\u001b[0m\n",
      "\u001b[34m[236]#011validation_0-logloss:0.11175#011validation_1-logloss:0.11805\u001b[0m\n",
      "\u001b[34m[237]#011validation_0-logloss:0.11166#011validation_1-logloss:0.11800\u001b[0m\n",
      "\u001b[34m[238]#011validation_0-logloss:0.11162#011validation_1-logloss:0.11800\u001b[0m\n",
      "\u001b[34m[239]#011validation_0-logloss:0.11157#011validation_1-logloss:0.11799\u001b[0m\n",
      "\u001b[34m[240]#011validation_0-logloss:0.11155#011validation_1-logloss:0.11799\u001b[0m\n",
      "\u001b[34m[241]#011validation_0-logloss:0.11153#011validation_1-logloss:0.11799\u001b[0m\n",
      "\u001b[34m[242]#011validation_0-logloss:0.11152#011validation_1-logloss:0.11799\u001b[0m\n",
      "\u001b[34m[243]#011validation_0-logloss:0.11149#011validation_1-logloss:0.11800\u001b[0m\n",
      "\u001b[34m[244]#011validation_0-logloss:0.11144#011validation_1-logloss:0.11799\u001b[0m\n",
      "\u001b[34m[245]#011validation_0-logloss:0.11142#011validation_1-logloss:0.11798\u001b[0m\n",
      "\u001b[34m[246]#011validation_0-logloss:0.11141#011validation_1-logloss:0.11798\u001b[0m\n",
      "\u001b[34m[247]#011validation_0-logloss:0.11136#011validation_1-logloss:0.11796\u001b[0m\n",
      "\u001b[34m[248]#011validation_0-logloss:0.11128#011validation_1-logloss:0.11790\u001b[0m\n",
      "\u001b[34m[249]#011validation_0-logloss:0.11119#011validation_1-logloss:0.11783\u001b[0m\n",
      "\u001b[34m[250]#011validation_0-logloss:0.11110#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[251]#011validation_0-logloss:0.11106#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[252]#011validation_0-logloss:0.11104#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[253]#011validation_0-logloss:0.11103#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[254]#011validation_0-logloss:0.11099#011validation_1-logloss:0.11773\u001b[0m\n",
      "\u001b[34m[255]#011validation_0-logloss:0.11096#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[256]#011validation_0-logloss:0.11091#011validation_1-logloss:0.11772\u001b[0m\n",
      "\u001b[34m[257]#011validation_0-logloss:0.11090#011validation_1-logloss:0.11773\u001b[0m\n",
      "\u001b[34m[258]#011validation_0-logloss:0.11087#011validation_1-logloss:0.11773\u001b[0m\n",
      "\u001b[34m[259]#011validation_0-logloss:0.11084#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[260]#011validation_0-logloss:0.11081#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[261]#011validation_0-logloss:0.11079#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[262]#011validation_0-logloss:0.11079#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[263]#011validation_0-logloss:0.11076#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[264]#011validation_0-logloss:0.11075#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[265]#011validation_0-logloss:0.11070#011validation_1-logloss:0.11772\u001b[0m\n",
      "\u001b[34m[266]#011validation_0-logloss:0.11069#011validation_1-logloss:0.11773\u001b[0m\n",
      "\u001b[34m[267]#011validation_0-logloss:0.11067#011validation_1-logloss:0.11773\u001b[0m\n",
      "\u001b[34m[268]#011validation_0-logloss:0.11065#011validation_1-logloss:0.11774\u001b[0m\n",
      "\u001b[34m[269]#011validation_0-logloss:0.11063#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[270]#011validation_0-logloss:0.11060#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[271]#011validation_0-logloss:0.11055#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[272]#011validation_0-logloss:0.11053#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[273]#011validation_0-logloss:0.11051#011validation_1-logloss:0.11775\u001b[0m\n",
      "\u001b[34m[274]#011validation_0-logloss:0.11048#011validation_1-logloss:0.11776\u001b[0m\n",
      "\u001b[34m[275]#011validation_0-logloss:0.11043#011validation_1-logloss:0.11777\u001b[0m\n",
      "\u001b[34m[276]#011validation_0-logloss:0.11035#011validation_1-logloss:0.11772\u001b[0m\n",
      "\u001b[34m[277]#011validation_0-logloss:0.11031#011validation_1-logloss:0.11771\u001b[0m\n",
      "\u001b[34m[278]#011validation_0-logloss:0.11025#011validation_1-logloss:0.11766\u001b[0m\n",
      "\u001b[34m[279]#011validation_0-logloss:0.11022#011validation_1-logloss:0.11766\u001b[0m\n",
      "\u001b[34m[280]#011validation_0-logloss:0.11020#011validation_1-logloss:0.11763\u001b[0m\n",
      "\u001b[34m[281]#011validation_0-logloss:0.11017#011validation_1-logloss:0.11764\u001b[0m\n",
      "\u001b[34m[282]#011validation_0-logloss:0.11013#011validation_1-logloss:0.11764\u001b[0m\n",
      "\u001b[34m[283]#011validation_0-logloss:0.11011#011validation_1-logloss:0.11763\u001b[0m\n",
      "\u001b[34m[284]#011validation_0-logloss:0.11009#011validation_1-logloss:0.11764\u001b[0m\n",
      "\u001b[34m[285]#011validation_0-logloss:0.10997#011validation_1-logloss:0.11751\u001b[0m\n",
      "\u001b[34m[286]#011validation_0-logloss:0.10993#011validation_1-logloss:0.11751\u001b[0m\n",
      "\u001b[34m[287]#011validation_0-logloss:0.10989#011validation_1-logloss:0.11749\u001b[0m\n",
      "\u001b[34m[288]#011validation_0-logloss:0.10986#011validation_1-logloss:0.11749\u001b[0m\n",
      "\u001b[34m[289]#011validation_0-logloss:0.10972#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[290]#011validation_0-logloss:0.10970#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[291]#011validation_0-logloss:0.10968#011validation_1-logloss:0.11737\u001b[0m\n",
      "\u001b[34m[292]#011validation_0-logloss:0.10963#011validation_1-logloss:0.11735\u001b[0m\n",
      "\u001b[34m[293]#011validation_0-logloss:0.10961#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[294]#011validation_0-logloss:0.10960#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[295]#011validation_0-logloss:0.10959#011validation_1-logloss:0.11737\u001b[0m\n",
      "\u001b[34m[296]#011validation_0-logloss:0.10957#011validation_1-logloss:0.11737\u001b[0m\n",
      "\u001b[34m[297]#011validation_0-logloss:0.10951#011validation_1-logloss:0.11735\u001b[0m\n",
      "\u001b[34m[298]#011validation_0-logloss:0.10948#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[299]#011validation_0-logloss:0.10945#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[300]#011validation_0-logloss:0.10944#011validation_1-logloss:0.11735\u001b[0m\n",
      "\u001b[34m[301]#011validation_0-logloss:0.10942#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[302]#011validation_0-logloss:0.10940#011validation_1-logloss:0.11735\u001b[0m\n",
      "\u001b[34m[303]#011validation_0-logloss:0.10938#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[304]#011validation_0-logloss:0.10937#011validation_1-logloss:0.11736\u001b[0m\n",
      "\u001b[34m[305]#011validation_0-logloss:0.10935#011validation_1-logloss:0.11737\u001b[0m\n",
      "\u001b[34m[306]#011validation_0-logloss:0.10927#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[307]#011validation_0-logloss:0.10925#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[308]#011validation_0-logloss:0.10922#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[309]#011validation_0-logloss:0.10921#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[310]#011validation_0-logloss:0.10915#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[311]#011validation_0-logloss:0.10913#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[312]#011validation_0-logloss:0.10910#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[313]#011validation_0-logloss:0.10909#011validation_1-logloss:0.11726\u001b[0m\n",
      "\u001b[34m[314]#011validation_0-logloss:0.10906#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[315]#011validation_0-logloss:0.10904#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[316]#011validation_0-logloss:0.10901#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[317]#011validation_0-logloss:0.10897#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[318]#011validation_0-logloss:0.10894#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[319]#011validation_0-logloss:0.10893#011validation_1-logloss:0.11731\u001b[0m\n",
      "\u001b[34m[320]#011validation_0-logloss:0.10888#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[321]#011validation_0-logloss:0.10887#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[322]#011validation_0-logloss:0.10883#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[323]#011validation_0-logloss:0.10881#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[324]#011validation_0-logloss:0.10878#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[325]#011validation_0-logloss:0.10876#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[326]#011validation_0-logloss:0.10873#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[327]#011validation_0-logloss:0.10871#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[328]#011validation_0-logloss:0.10866#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[329]#011validation_0-logloss:0.10863#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[330]#011validation_0-logloss:0.10860#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[331]#011validation_0-logloss:0.10858#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[332]#011validation_0-logloss:0.10855#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[333]#011validation_0-logloss:0.10854#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[334]#011validation_0-logloss:0.10851#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[335]#011validation_0-logloss:0.10849#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[336]#011validation_0-logloss:0.10847#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[337]#011validation_0-logloss:0.10845#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[338]#011validation_0-logloss:0.10844#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[339]#011validation_0-logloss:0.10840#011validation_1-logloss:0.11731\u001b[0m\n",
      "\u001b[34m[340]#011validation_0-logloss:0.10837#011validation_1-logloss:0.11730\u001b[0m\n",
      "\u001b[34m[341]#011validation_0-logloss:0.10834#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[342]#011validation_0-logloss:0.10831#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[343]#011validation_0-logloss:0.10829#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[344]#011validation_0-logloss:0.10827#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[345]#011validation_0-logloss:0.10824#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[346]#011validation_0-logloss:0.10820#011validation_1-logloss:0.11726\u001b[0m\n",
      "\u001b[34m[347]#011validation_0-logloss:0.10818#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[348]#011validation_0-logloss:0.10817#011validation_1-logloss:0.11727\u001b[0m\n",
      "\u001b[34m[349]#011validation_0-logloss:0.10816#011validation_1-logloss:0.11728\u001b[0m\n",
      "\u001b[34m[350]#011validation_0-logloss:0.10814#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[351]#011validation_0-logloss:0.10812#011validation_1-logloss:0.11729\u001b[0m\n",
      "\u001b[34m[352]#011validation_0-logloss:0.10806#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[353]#011validation_0-logloss:0.10799#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[354]#011validation_0-logloss:0.10796#011validation_1-logloss:0.11719\u001b[0m\n",
      "\u001b[34m[355]#011validation_0-logloss:0.10794#011validation_1-logloss:0.11720\u001b[0m\n",
      "\u001b[34m[356]#011validation_0-logloss:0.10792#011validation_1-logloss:0.11719\u001b[0m\n",
      "\u001b[34m[357]#011validation_0-logloss:0.10791#011validation_1-logloss:0.11719\u001b[0m\n",
      "\u001b[34m[358]#011validation_0-logloss:0.10790#011validation_1-logloss:0.11720\u001b[0m\n",
      "\u001b[34m[359]#011validation_0-logloss:0.10788#011validation_1-logloss:0.11718\u001b[0m\n",
      "\u001b[34m[360]#011validation_0-logloss:0.10787#011validation_1-logloss:0.11719\u001b[0m\n",
      "\u001b[34m[361]#011validation_0-logloss:0.10784#011validation_1-logloss:0.11719\u001b[0m\n",
      "\u001b[34m[362]#011validation_0-logloss:0.10782#011validation_1-logloss:0.11720\u001b[0m\n",
      "\u001b[34m[363]#011validation_0-logloss:0.10780#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[364]#011validation_0-logloss:0.10778#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[365]#011validation_0-logloss:0.10775#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[366]#011validation_0-logloss:0.10774#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[367]#011validation_0-logloss:0.10773#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[368]#011validation_0-logloss:0.10770#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[369]#011validation_0-logloss:0.10769#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[370]#011validation_0-logloss:0.10766#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[371]#011validation_0-logloss:0.10765#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[372]#011validation_0-logloss:0.10760#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[373]#011validation_0-logloss:0.10757#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[374]#011validation_0-logloss:0.10754#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[375]#011validation_0-logloss:0.10753#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[376]#011validation_0-logloss:0.10751#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[377]#011validation_0-logloss:0.10748#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[378]#011validation_0-logloss:0.10748#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[379]#011validation_0-logloss:0.10745#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[380]#011validation_0-logloss:0.10741#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[381]#011validation_0-logloss:0.10739#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[382]#011validation_0-logloss:0.10739#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[383]#011validation_0-logloss:0.10736#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[384]#011validation_0-logloss:0.10733#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[385]#011validation_0-logloss:0.10730#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[386]#011validation_0-logloss:0.10727#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[387]#011validation_0-logloss:0.10725#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[388]#011validation_0-logloss:0.10724#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[389]#011validation_0-logloss:0.10721#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[390]#011validation_0-logloss:0.10717#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[391]#011validation_0-logloss:0.10714#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[392]#011validation_0-logloss:0.10712#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[393]#011validation_0-logloss:0.10711#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[394]#011validation_0-logloss:0.10709#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[395]#011validation_0-logloss:0.10709#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[396]#011validation_0-logloss:0.10707#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[397]#011validation_0-logloss:0.10704#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[398]#011validation_0-logloss:0.10700#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[399]#011validation_0-logloss:0.10696#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[400]#011validation_0-logloss:0.10695#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[401]#011validation_0-logloss:0.10694#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[402]#011validation_0-logloss:0.10694#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[403]#011validation_0-logloss:0.10692#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[404]#011validation_0-logloss:0.10689#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[405]#011validation_0-logloss:0.10687#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[406]#011validation_0-logloss:0.10685#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[407]#011validation_0-logloss:0.10683#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[408]#011validation_0-logloss:0.10680#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[409]#011validation_0-logloss:0.10679#011validation_1-logloss:0.11721\u001b[0m\n",
      "\u001b[34m[410]#011validation_0-logloss:0.10676#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[411]#011validation_0-logloss:0.10675#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[412]#011validation_0-logloss:0.10671#011validation_1-logloss:0.11723\u001b[0m\n",
      "\u001b[34m[413]#011validation_0-logloss:0.10670#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[414]#011validation_0-logloss:0.10667#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[415]#011validation_0-logloss:0.10665#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[416]#011validation_0-logloss:0.10662#011validation_1-logloss:0.11724\u001b[0m\n",
      "\u001b[34m[417]#011validation_0-logloss:0.10661#011validation_1-logloss:0.11725\u001b[0m\n",
      "\u001b[34m[418]#011validation_0-logloss:0.10657#011validation_1-logloss:0.11722\u001b[0m\n",
      "\u001b[34m[419]#011validation_0-logloss:0.10654#011validation_1-logloss:0.11720\u001b[0m\n",
      "\u001b[34m[420]#011validation_0-logloss:0.10650#011validation_1-logloss:0.11718\u001b[0m\n",
      "\u001b[34m[421]#011validation_0-logloss:0.10648#011validation_1-logloss:0.11718\u001b[0m\n",
      "\u001b[34m[422]#011validation_0-logloss:0.10643#011validation_1-logloss:0.11716\u001b[0m\n",
      "\u001b[34m[423]#011validation_0-logloss:0.10638#011validation_1-logloss:0.11713\u001b[0m\n",
      "\u001b[34m[424]#011validation_0-logloss:0.10637#011validation_1-logloss:0.11713\u001b[0m\n",
      "\u001b[34m[425]#011validation_0-logloss:0.10630#011validation_1-logloss:0.11707\u001b[0m\n",
      "\u001b[34m[426]#011validation_0-logloss:0.10628#011validation_1-logloss:0.11707\u001b[0m\n",
      "\u001b[34m[427]#011validation_0-logloss:0.10627#011validation_1-logloss:0.11707\u001b[0m\n",
      "\u001b[34m[428]#011validation_0-logloss:0.10626#011validation_1-logloss:0.11708\u001b[0m\n",
      "\u001b[34m[429]#011validation_0-logloss:0.10623#011validation_1-logloss:0.11708\u001b[0m\n",
      "\u001b[34m[430]#011validation_0-logloss:0.10622#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[431]#011validation_0-logloss:0.10622#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[432]#011validation_0-logloss:0.10621#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[433]#011validation_0-logloss:0.10619#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[434]#011validation_0-logloss:0.10618#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[435]#011validation_0-logloss:0.10615#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[436]#011validation_0-logloss:0.10612#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[437]#011validation_0-logloss:0.10611#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[438]#011validation_0-logloss:0.10608#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[439]#011validation_0-logloss:0.10606#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[440]#011validation_0-logloss:0.10605#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[441]#011validation_0-logloss:0.10603#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[442]#011validation_0-logloss:0.10601#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[443]#011validation_0-logloss:0.10600#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[444]#011validation_0-logloss:0.10598#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[445]#011validation_0-logloss:0.10594#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[446]#011validation_0-logloss:0.10592#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[447]#011validation_0-logloss:0.10591#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[448]#011validation_0-logloss:0.10590#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[449]#011validation_0-logloss:0.10588#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[450]#011validation_0-logloss:0.10582#011validation_1-logloss:0.11707\u001b[0m\n",
      "\u001b[34m[451]#011validation_0-logloss:0.10578#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[452]#011validation_0-logloss:0.10577#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[453]#011validation_0-logloss:0.10574#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[454]#011validation_0-logloss:0.10572#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[455]#011validation_0-logloss:0.10569#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[456]#011validation_0-logloss:0.10568#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[457]#011validation_0-logloss:0.10566#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[458]#011validation_0-logloss:0.10563#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[459]#011validation_0-logloss:0.10561#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[460]#011validation_0-logloss:0.10558#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[461]#011validation_0-logloss:0.10557#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[462]#011validation_0-logloss:0.10555#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[463]#011validation_0-logloss:0.10554#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[464]#011validation_0-logloss:0.10552#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[465]#011validation_0-logloss:0.10551#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[466]#011validation_0-logloss:0.10549#011validation_1-logloss:0.11711\u001b[0m\n",
      "\u001b[34m[467]#011validation_0-logloss:0.10547#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[468]#011validation_0-logloss:0.10545#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[469]#011validation_0-logloss:0.10543#011validation_1-logloss:0.11712\u001b[0m\n",
      "\u001b[34m[470]#011validation_0-logloss:0.10539#011validation_1-logloss:0.11715\u001b[0m\n",
      "\u001b[34m[471]#011validation_0-logloss:0.10536#011validation_1-logloss:0.11714\u001b[0m\n",
      "\u001b[34m[472]#011validation_0-logloss:0.10534#011validation_1-logloss:0.11713\u001b[0m\n",
      "\u001b[34m[473]#011validation_0-logloss:0.10529#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[474]#011validation_0-logloss:0.10528#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[475]#011validation_0-logloss:0.10527#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[476]#011validation_0-logloss:0.10525#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[477]#011validation_0-logloss:0.10523#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[478]#011validation_0-logloss:0.10519#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[479]#011validation_0-logloss:0.10518#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[480]#011validation_0-logloss:0.10516#011validation_1-logloss:0.11710\u001b[0m\n",
      "\u001b[34m[481]#011validation_0-logloss:0.10515#011validation_1-logloss:0.11709\u001b[0m\n",
      "\u001b[34m[482]#011validation_0-logloss:0.10509#011validation_1-logloss:0.11706\u001b[0m\n",
      "\u001b[34m[483]#011validation_0-logloss:0.10507#011validation_1-logloss:0.11705\u001b[0m\n",
      "\u001b[34m[484]#011validation_0-logloss:0.10506#011validation_1-logloss:0.11706\u001b[0m\n",
      "\u001b[34m[485]#011validation_0-logloss:0.10505#011validation_1-logloss:0.11706\u001b[0m\n",
      "\u001b[34m[486]#011validation_0-logloss:0.10503#011validation_1-logloss:0.11707\u001b[0m\n",
      "\u001b[34m[487]#011validation_0-logloss:0.10502#011validation_1-logloss:0.11706\u001b[0m\n",
      "\u001b[34m[488]#011validation_0-logloss:0.10497#011validation_1-logloss:0.11703\u001b[0m\n",
      "\u001b[34m[489]#011validation_0-logloss:0.10494#011validation_1-logloss:0.11702\u001b[0m\n",
      "\u001b[34m[490]#011validation_0-logloss:0.10491#011validation_1-logloss:0.11700\u001b[0m\n",
      "\u001b[34m[491]#011validation_0-logloss:0.10489#011validation_1-logloss:0.11700\u001b[0m\n",
      "\u001b[34m[492]#011validation_0-logloss:0.10487#011validation_1-logloss:0.11699\u001b[0m\n",
      "\u001b[34m[493]#011validation_0-logloss:0.10485#011validation_1-logloss:0.11699\u001b[0m\n",
      "\u001b[34m[494]#011validation_0-logloss:0.10482#011validation_1-logloss:0.11701\u001b[0m\n",
      "\u001b[34m[495]#011validation_0-logloss:0.10480#011validation_1-logloss:0.11701\u001b[0m\n",
      "\u001b[34m[496]#011validation_0-logloss:0.10480#011validation_1-logloss:0.11701\u001b[0m\n",
      "\u001b[34m[497]#011validation_0-logloss:0.10477#011validation_1-logloss:0.11703\u001b[0m\n",
      "\u001b[34m[498]#011validation_0-logloss:0.10475#011validation_1-logloss:0.11702\u001b[0m\n",
      "\u001b[34m[499]#011validation_0-logloss:0.10474#011validation_1-logloss:0.11703\u001b[0m\n",
      "\u001b[34mtrain idx: 0, loss: 0.543435, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 1, loss: 0.443121, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 2, loss: 0.371748, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 3, loss: 0.319072, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 4, loss: 0.27924, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 5, loss: 0.248566, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 6, loss: 0.224797, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 7, loss: 0.206181, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 8, loss: 0.191591, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 9, loss: 0.179886, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 10, loss: 0.170557, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 11, loss: 0.163133, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 12, loss: 0.156868, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 13, loss: 0.151977, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 14, loss: 0.147822, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 15, loss: 0.144635, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 16, loss: 0.142171, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 17, loss: 0.139884, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 18, loss: 0.137859, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 19, loss: 0.136423, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 20, loss: 0.135295, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 21, loss: 0.13431, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 22, loss: 0.13347, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 23, loss: 0.132802, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 24, loss: 0.131669, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 25, loss: 0.130914, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 26, loss: 0.130216, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 27, loss: 0.129761, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 28, loss: 0.129243, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 29, loss: 0.128624, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 30, loss: 0.128274, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 31, loss: 0.128025, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 32, loss: 0.127752, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 33, loss: 0.127422, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 34, loss: 0.127339, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 35, loss: 0.127194, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 36, loss: 0.126976, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 37, loss: 0.126527, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 38, loss: 0.126173, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 39, loss: 0.12594, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 40, loss: 0.125654, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 41, loss: 0.125447, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 42, loss: 0.125026, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 43, loss: 0.124887, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 44, loss: 0.124596, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 45, loss: 0.124357, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 46, loss: 0.124187, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 47, loss: 0.123982, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 48, loss: 0.123939, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 49, loss: 0.123883, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 50, loss: 0.123514, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 51, loss: 0.123392, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 52, loss: 0.12333, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 53, loss: 0.12321, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 54, loss: 0.123144, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 55, loss: 0.123108, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 56, loss: 0.122937, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 57, loss: 0.122756, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 58, loss: 0.122553, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 59, loss: 0.122399, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 60, loss: 0.122133, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 61, loss: 0.122085, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 62, loss: 0.122035, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 63, loss: 0.121994, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 64, loss: 0.121928, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 65, loss: 0.121872, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 66, loss: 0.121679, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 67, loss: 0.121639, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 68, loss: 0.121272, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 69, loss: 0.120987, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 70, loss: 0.120932, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 71, loss: 0.12061, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 72, loss: 0.120585, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 73, loss: 0.120534, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 74, loss: 0.120399, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 75, loss: 0.120289, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 76, loss: 0.120262, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 77, loss: 0.120228, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 78, loss: 0.120097, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 79, loss: 0.120046, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 80, loss: 0.120015, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 81, loss: 0.119951, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 82, loss: 0.119875, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 83, loss: 0.119776, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 84, loss: 0.119589, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 85, loss: 0.119506, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 86, loss: 0.119485, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 87, loss: 0.119424, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 88, loss: 0.11933, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 89, loss: 0.119293, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 90, loss: 0.119013, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 91, loss: 0.118994, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 92, loss: 0.118945, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 93, loss: 0.118712, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 94, loss: 0.118652, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 95, loss: 0.11861, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 96, loss: 0.118579, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 97, loss: 0.118529, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 98, loss: 0.11844, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 99, loss: 0.118418, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 100, loss: 0.11838, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 101, loss: 0.11836, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 102, loss: 0.118305, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 103, loss: 0.118287, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 104, loss: 0.118269, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 105, loss: 0.118241, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 106, loss: 0.118229, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 107, loss: 0.118177, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 108, loss: 0.117954, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 109, loss: 0.117907, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 110, loss: 0.117844, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 111, loss: 0.117751, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 112, loss: 0.11774, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 113, loss: 0.117545, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 114, loss: 0.117502, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 115, loss: 0.117374, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 116, loss: 0.117353, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 117, loss: 0.117326, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 118, loss: 0.117281, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 119, loss: 0.117228, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 120, loss: 0.117216, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 121, loss: 0.117051, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 122, loss: 0.117019, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 123, loss: 0.116975, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 124, loss: 0.116915, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 125, loss: 0.116867, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 126, loss: 0.116848, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 127, loss: 0.116734, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 128, loss: 0.116694, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 129, loss: 0.116597, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 130, loss: 0.116556, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 131, loss: 0.116525, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 132, loss: 0.116462, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 133, loss: 0.116403, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 134, loss: 0.116348, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 135, loss: 0.116339, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 136, loss: 0.116293, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 137, loss: 0.116274, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 138, loss: 0.116187, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 139, loss: 0.116124, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 140, loss: 0.116089, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 141, loss: 0.116058, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 142, loss: 0.115923, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 143, loss: 0.115891, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 144, loss: 0.115777, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 145, loss: 0.11577, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 146, loss: 0.115738, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 147, loss: 0.115679, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 148, loss: 0.115654, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 149, loss: 0.115642, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 150, loss: 0.115546, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 151, loss: 0.115534, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 152, loss: 0.115435, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 153, loss: 0.115402, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 154, loss: 0.115377, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 155, loss: 0.115328, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 156, loss: 0.115229, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 157, loss: 0.115015, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 158, loss: 0.114981, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 159, loss: 0.114966, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 160, loss: 0.114871, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 161, loss: 0.114827, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 162, loss: 0.114755, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 163, loss: 0.114704, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 164, loss: 0.114676, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 165, loss: 0.114636, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 166, loss: 0.114602, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 167, loss: 0.114523, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 168, loss: 0.114424, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 169, loss: 0.114366, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 170, loss: 0.114351, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 171, loss: 0.114255, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 172, loss: 0.114191, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 173, loss: 0.114164, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 174, loss: 0.114116, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 175, loss: 0.114111, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 176, loss: 0.114088, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 177, loss: 0.114071, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 178, loss: 0.113999, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 179, loss: 0.113892, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 180, loss: 0.113861, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 181, loss: 0.113831, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 182, loss: 0.113817, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 183, loss: 0.113761, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 184, loss: 0.113741, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 185, loss: 0.113712, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 186, loss: 0.113673, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 187, loss: 0.113651, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 188, loss: 0.113615, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 189, loss: 0.113599, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 190, loss: 0.11356, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 191, loss: 0.11353, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 192, loss: 0.113519, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 193, loss: 0.113484, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 194, loss: 0.113453, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 195, loss: 0.113445, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 196, loss: 0.113417, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 197, loss: 0.113376, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 198, loss: 0.113354, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 199, loss: 0.11324, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 200, loss: 0.113211, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 201, loss: 0.113168, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 202, loss: 0.113101, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 203, loss: 0.112957, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 204, loss: 0.11295, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 205, loss: 0.112919, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 206, loss: 0.112899, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 207, loss: 0.112886, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 208, loss: 0.112824, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 209, loss: 0.112816, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 210, loss: 0.112801, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 211, loss: 0.112758, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 212, loss: 0.112677, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 213, loss: 0.11263, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 214, loss: 0.112622, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 215, loss: 0.112566, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 216, loss: 0.112535, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 217, loss: 0.112495, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 218, loss: 0.112434, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 219, loss: 0.112305, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 220, loss: 0.112289, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 221, loss: 0.11226, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 222, loss: 0.112234, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 223, loss: 0.112139, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 224, loss: 0.112115, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 225, loss: 0.112103, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 226, loss: 0.112093, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 227, loss: 0.112087, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 228, loss: 0.112072, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 229, loss: 0.112052, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 230, loss: 0.111996, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 231, loss: 0.11195, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 232, loss: 0.111924, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 233, loss: 0.111863, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 234, loss: 0.111826, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 235, loss: 0.111808, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 236, loss: 0.111747, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 237, loss: 0.111664, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 238, loss: 0.111622, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 239, loss: 0.111575, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 240, loss: 0.111549, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 241, loss: 0.111528, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 242, loss: 0.111518, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 243, loss: 0.111486, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 244, loss: 0.11144, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 245, loss: 0.111417, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 246, loss: 0.111408, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 247, loss: 0.111361, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 248, loss: 0.111278, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 249, loss: 0.111193, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 250, loss: 0.111103, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 251, loss: 0.111061, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 252, loss: 0.111041, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 253, loss: 0.111033, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 254, loss: 0.110992, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 255, loss: 0.110959, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 256, loss: 0.110914, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 257, loss: 0.110903, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 258, loss: 0.110867, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 259, loss: 0.110837, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 260, loss: 0.110812, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 261, loss: 0.110791, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 262, loss: 0.110787, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 263, loss: 0.110755, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 264, loss: 0.110748, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 265, loss: 0.110703, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 266, loss: 0.110685, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 267, loss: 0.110669, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 268, loss: 0.110648, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 269, loss: 0.110631, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 270, loss: 0.110599, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 271, loss: 0.110545, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 272, loss: 0.110527, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 273, loss: 0.110505, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 274, loss: 0.110478, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 275, loss: 0.110434, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 276, loss: 0.110351, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 277, loss: 0.110306, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 278, loss: 0.110247, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 279, loss: 0.110222, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 280, loss: 0.110195, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 281, loss: 0.110168, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 282, loss: 0.110135, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 283, loss: 0.110111, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 284, loss: 0.110094, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 285, loss: 0.109967, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 286, loss: 0.10993, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 287, loss: 0.109892, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 288, loss: 0.109862, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 289, loss: 0.109721, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 290, loss: 0.109705, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 291, loss: 0.109678, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 292, loss: 0.109634, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 293, loss: 0.109608, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 294, loss: 0.109597, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 295, loss: 0.109589, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 296, loss: 0.109568, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 297, loss: 0.10951, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 298, loss: 0.109483, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 299, loss: 0.109453, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 300, loss: 0.109439, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 301, loss: 0.109418, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 302, loss: 0.109397, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 303, loss: 0.109375, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 304, loss: 0.10937, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 305, loss: 0.109349, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 306, loss: 0.109271, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 307, loss: 0.10925, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 308, loss: 0.109221, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 309, loss: 0.109213, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 310, loss: 0.109154, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 311, loss: 0.109126, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 312, loss: 0.109104, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 313, loss: 0.109086, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 314, loss: 0.109061, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 315, loss: 0.109036, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 316, loss: 0.109007, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 317, loss: 0.108971, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 318, loss: 0.108942, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 319, loss: 0.108927, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 320, loss: 0.108879, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 321, loss: 0.108866, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 322, loss: 0.108832, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 323, loss: 0.108812, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 324, loss: 0.108781, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 325, loss: 0.108758, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 326, loss: 0.108733, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 327, loss: 0.108711, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 328, loss: 0.108658, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 329, loss: 0.108629, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 330, loss: 0.108599, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 331, loss: 0.108576, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 332, loss: 0.108555, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 333, loss: 0.108536, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 334, loss: 0.108506, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 335, loss: 0.108489, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 336, loss: 0.108471, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 337, loss: 0.108452, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 338, loss: 0.108441, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 339, loss: 0.108398, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 340, loss: 0.108366, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 341, loss: 0.108337, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 342, loss: 0.108307, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 343, loss: 0.108291, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 344, loss: 0.108271, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 345, loss: 0.108237, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 346, loss: 0.108199, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 347, loss: 0.10818, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 348, loss: 0.10817, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 349, loss: 0.108164, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 350, loss: 0.108141, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 351, loss: 0.108123, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 352, loss: 0.108063, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 353, loss: 0.107993, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 354, loss: 0.107962, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 355, loss: 0.10794, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 356, loss: 0.107923, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 357, loss: 0.107915, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 358, loss: 0.107904, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 359, loss: 0.107876, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 360, loss: 0.107867, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 361, loss: 0.10784, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 362, loss: 0.107821, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 363, loss: 0.107799, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 364, loss: 0.107776, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 365, loss: 0.10775, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 366, loss: 0.107741, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 367, loss: 0.10773, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 368, loss: 0.107704, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 369, loss: 0.107691, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 370, loss: 0.107664, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 371, loss: 0.107651, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 372, loss: 0.107604, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 373, loss: 0.107573, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 374, loss: 0.10754, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 375, loss: 0.107534, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 376, loss: 0.107514, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 377, loss: 0.10748, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 378, loss: 0.107475, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 379, loss: 0.107448, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 380, loss: 0.107406, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 381, loss: 0.107394, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 382, loss: 0.107386, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 383, loss: 0.107358, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 384, loss: 0.107327, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 385, loss: 0.107295, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 386, loss: 0.107266, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 387, loss: 0.107252, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 388, loss: 0.10724, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 389, loss: 0.107212, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 390, loss: 0.107172, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 391, loss: 0.107137, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 392, loss: 0.107117, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 393, loss: 0.107111, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 394, loss: 0.107094, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 395, loss: 0.107087, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 396, loss: 0.10707, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 397, loss: 0.107035, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 398, loss: 0.107004, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 399, loss: 0.106957, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 400, loss: 0.106955, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 401, loss: 0.106944, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 402, loss: 0.106936, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 403, loss: 0.106919, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 404, loss: 0.106893, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 405, loss: 0.106869, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 406, loss: 0.10685, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 407, loss: 0.106825, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 408, loss: 0.106803, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 409, loss: 0.106789, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 410, loss: 0.106763, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 411, loss: 0.106746, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 412, loss: 0.106714, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 413, loss: 0.106696, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 414, loss: 0.106672, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 415, loss: 0.106646, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 416, loss: 0.106622, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 417, loss: 0.106609, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 418, loss: 0.106567, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 419, loss: 0.106535, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 420, loss: 0.106496, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 421, loss: 0.106485, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 422, loss: 0.106433, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 423, loss: 0.106377, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 424, loss: 0.106369, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 425, loss: 0.106301, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 426, loss: 0.106281, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 427, loss: 0.106269, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 428, loss: 0.106261, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 429, loss: 0.106234, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 430, loss: 0.106215, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 431, loss: 0.106215, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 432, loss: 0.106208, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 433, loss: 0.106192, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 434, loss: 0.106181, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 435, loss: 0.106151, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 436, loss: 0.106124, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 437, loss: 0.106113, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 438, loss: 0.106085, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 439, loss: 0.106063, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 440, loss: 0.106046, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 441, loss: 0.106027, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 442, loss: 0.106006, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 443, loss: 0.105998, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 444, loss: 0.105976, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 445, loss: 0.105942, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 446, loss: 0.105923, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 447, loss: 0.105912, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 448, loss: 0.105901, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 449, loss: 0.10588, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 450, loss: 0.105821, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 451, loss: 0.105784, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 452, loss: 0.105768, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 453, loss: 0.105743, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 454, loss: 0.105722, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 455, loss: 0.105695, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 456, loss: 0.105683, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 457, loss: 0.10566, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 458, loss: 0.105626, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 459, loss: 0.105606, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 460, loss: 0.105583, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 461, loss: 0.105567, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 462, loss: 0.105555, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 463, loss: 0.105543, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 464, loss: 0.10552, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 465, loss: 0.105506, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 466, loss: 0.105488, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 467, loss: 0.105465, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 468, loss: 0.105446, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 469, loss: 0.105429, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 470, loss: 0.105393, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 471, loss: 0.10536, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 472, loss: 0.10534, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 473, loss: 0.105291, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 474, loss: 0.105279, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 475, loss: 0.105266, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 476, loss: 0.105251, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 477, loss: 0.105231, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 478, loss: 0.105195, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 479, loss: 0.105176, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 480, loss: 0.105163, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 481, loss: 0.105146, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 482, loss: 0.105094, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 483, loss: 0.105072, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 484, loss: 0.105062, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 485, loss: 0.10505, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 486, loss: 0.10503, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 487, loss: 0.105017, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 488, loss: 0.104967, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 489, loss: 0.104941, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 490, loss: 0.104911, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 491, loss: 0.104888, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 492, loss: 0.104872, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 493, loss: 0.104846, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 494, loss: 0.104816, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 495, loss: 0.104804, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 496, loss: 0.104799, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 497, loss: 0.10477, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 498, loss: 0.10475, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mtrain idx: 499, loss: 0.104739, type: <class 'float'>\u001b[0m\n",
      "\u001b[34mval idx: 0, loss: 0.543659\u001b[0m\n",
      "\u001b[34mval idx: 1, loss: 0.443381\u001b[0m\n",
      "\u001b[34mval idx: 2, loss: 0.372115\u001b[0m\n",
      "\u001b[34mval idx: 3, loss: 0.319515\u001b[0m\n",
      "\u001b[34mval idx: 4, loss: 0.279714\u001b[0m\n",
      "\u001b[34mval idx: 5, loss: 0.249201\u001b[0m\n",
      "\u001b[34mval idx: 6, loss: 0.225526\u001b[0m\n",
      "\u001b[34mval idx: 7, loss: 0.206898\u001b[0m\n",
      "\u001b[34mval idx: 8, loss: 0.192272\u001b[0m\n",
      "\u001b[34mval idx: 9, loss: 0.180736\u001b[0m\n",
      "\u001b[34mval idx: 10, loss: 0.171497\u001b[0m\n",
      "\u001b[34mval idx: 11, loss: 0.164053\u001b[0m\n",
      "\u001b[34mval idx: 12, loss: 0.157792\u001b[0m\n",
      "\u001b[34mval idx: 13, loss: 0.15293\u001b[0m\n",
      "\u001b[34mval idx: 14, loss: 0.148722\u001b[0m\n",
      "\u001b[34mval idx: 15, loss: 0.145616\u001b[0m\n",
      "\u001b[34mval idx: 16, loss: 0.143106\u001b[0m\n",
      "\u001b[34mval idx: 17, loss: 0.140845\u001b[0m\n",
      "\u001b[34mval idx: 18, loss: 0.138886\u001b[0m\n",
      "\u001b[34mval idx: 19, loss: 0.137479\u001b[0m\n",
      "\u001b[34mval idx: 20, loss: 0.136384\u001b[0m\n",
      "\u001b[34mval idx: 21, loss: 0.135444\u001b[0m\n",
      "\u001b[34mval idx: 22, loss: 0.134653\u001b[0m\n",
      "\u001b[34mval idx: 23, loss: 0.134005\u001b[0m\n",
      "\u001b[34mval idx: 24, loss: 0.132763\u001b[0m\n",
      "\u001b[34mval idx: 25, loss: 0.132049\u001b[0m\n",
      "\u001b[34mval idx: 26, loss: 0.131324\u001b[0m\n",
      "\u001b[34mval idx: 27, loss: 0.130848\u001b[0m\n",
      "\u001b[34mval idx: 28, loss: 0.130368\u001b[0m\n",
      "\u001b[34mval idx: 29, loss: 0.129744\u001b[0m\n",
      "\u001b[34mval idx: 30, loss: 0.129413\u001b[0m\n",
      "\u001b[34mval idx: 31, loss: 0.129228\u001b[0m\n",
      "\u001b[34mval idx: 32, loss: 0.128973\u001b[0m\n",
      "\u001b[34mval idx: 33, loss: 0.12865\u001b[0m\n",
      "\u001b[34mval idx: 34, loss: 0.128588\u001b[0m\n",
      "\u001b[34mval idx: 35, loss: 0.128453\u001b[0m\n",
      "\u001b[34mval idx: 36, loss: 0.128274\u001b[0m\n",
      "\u001b[34mval idx: 37, loss: 0.127826\u001b[0m\n",
      "\u001b[34mval idx: 38, loss: 0.127505\u001b[0m\n",
      "\u001b[34mval idx: 39, loss: 0.127284\u001b[0m\n",
      "\u001b[34mval idx: 40, loss: 0.127044\u001b[0m\n",
      "\u001b[34mval idx: 41, loss: 0.126891\u001b[0m\n",
      "\u001b[34mval idx: 42, loss: 0.126492\u001b[0m\n",
      "\u001b[34mval idx: 43, loss: 0.126352\u001b[0m\n",
      "\u001b[34mval idx: 44, loss: 0.126072\u001b[0m\n",
      "\u001b[34mval idx: 45, loss: 0.125845\u001b[0m\n",
      "\u001b[34mval idx: 46, loss: 0.125695\u001b[0m\n",
      "\u001b[34mval idx: 47, loss: 0.125513\u001b[0m\n",
      "\u001b[34mval idx: 48, loss: 0.125466\u001b[0m\n",
      "\u001b[34mval idx: 49, loss: 0.125428\u001b[0m\n",
      "\u001b[34mval idx: 50, loss: 0.125041\u001b[0m\n",
      "\u001b[34mval idx: 51, loss: 0.124951\u001b[0m\n",
      "\u001b[34mval idx: 52, loss: 0.124898\u001b[0m\n",
      "\u001b[34mval idx: 53, loss: 0.124819\u001b[0m\n",
      "\u001b[34mval idx: 54, loss: 0.124771\u001b[0m\n",
      "\u001b[34mval idx: 55, loss: 0.12474\u001b[0m\n",
      "\u001b[34mval idx: 56, loss: 0.124582\u001b[0m\n",
      "\u001b[34mval idx: 57, loss: 0.12444\u001b[0m\n",
      "\u001b[34mval idx: 58, loss: 0.124256\u001b[0m\n",
      "\u001b[34mval idx: 59, loss: 0.12411\u001b[0m\n",
      "\u001b[34mval idx: 60, loss: 0.123827\u001b[0m\n",
      "\u001b[34mval idx: 61, loss: 0.123811\u001b[0m\n",
      "\u001b[34mval idx: 62, loss: 0.123788\u001b[0m\n",
      "\u001b[34mval idx: 63, loss: 0.123763\u001b[0m\n",
      "\u001b[34mval idx: 64, loss: 0.123702\u001b[0m\n",
      "\u001b[34mval idx: 65, loss: 0.123667\u001b[0m\n",
      "\u001b[34mval idx: 66, loss: 0.123501\u001b[0m\n",
      "\u001b[34mval idx: 67, loss: 0.123474\u001b[0m\n",
      "\u001b[34mval idx: 68, loss: 0.123163\u001b[0m\n",
      "\u001b[34mval idx: 69, loss: 0.122867\u001b[0m\n",
      "\u001b[34mval idx: 70, loss: 0.122858\u001b[0m\n",
      "\u001b[34mval idx: 71, loss: 0.122536\u001b[0m\n",
      "\u001b[34mval idx: 72, loss: 0.122541\u001b[0m\n",
      "\u001b[34mval idx: 73, loss: 0.122525\u001b[0m\n",
      "\u001b[34mval idx: 74, loss: 0.122411\u001b[0m\n",
      "\u001b[34mval idx: 75, loss: 0.122309\u001b[0m\n",
      "\u001b[34mval idx: 76, loss: 0.122299\u001b[0m\n",
      "\u001b[34mval idx: 77, loss: 0.122291\u001b[0m\n",
      "\u001b[34mval idx: 78, loss: 0.1222\u001b[0m\n",
      "\u001b[34mval idx: 79, loss: 0.122208\u001b[0m\n",
      "\u001b[34mval idx: 80, loss: 0.122211\u001b[0m\n",
      "\u001b[34mval idx: 81, loss: 0.122208\u001b[0m\n",
      "\u001b[34mval idx: 82, loss: 0.122179\u001b[0m\n",
      "\u001b[34mval idx: 83, loss: 0.122076\u001b[0m\n",
      "\u001b[34mval idx: 84, loss: 0.121898\u001b[0m\n",
      "\u001b[34mval idx: 85, loss: 0.121848\u001b[0m\n",
      "\u001b[34mval idx: 86, loss: 0.121833\u001b[0m\n",
      "\u001b[34mval idx: 87, loss: 0.121817\u001b[0m\n",
      "\u001b[34mval idx: 88, loss: 0.12175\u001b[0m\n",
      "\u001b[34mval idx: 89, loss: 0.121743\u001b[0m\n",
      "\u001b[34mval idx: 90, loss: 0.121452\u001b[0m\n",
      "\u001b[34mval idx: 91, loss: 0.121453\u001b[0m\n",
      "\u001b[34mval idx: 92, loss: 0.12145\u001b[0m\n",
      "\u001b[34mval idx: 93, loss: 0.1212\u001b[0m\n",
      "\u001b[34mval idx: 94, loss: 0.121183\u001b[0m\n",
      "\u001b[34mval idx: 95, loss: 0.121158\u001b[0m\n",
      "\u001b[34mval idx: 96, loss: 0.121149\u001b[0m\n",
      "\u001b[34mval idx: 97, loss: 0.121161\u001b[0m\n",
      "\u001b[34mval idx: 98, loss: 0.121121\u001b[0m\n",
      "\u001b[34mval idx: 99, loss: 0.121121\u001b[0m\n",
      "\u001b[34mval idx: 100, loss: 0.121132\u001b[0m\n",
      "\u001b[34mval idx: 101, loss: 0.121137\u001b[0m\n",
      "\u001b[34mval idx: 102, loss: 0.121116\u001b[0m\n",
      "\u001b[34mval idx: 103, loss: 0.12112\u001b[0m\n",
      "\u001b[34mval idx: 104, loss: 0.121109\u001b[0m\n",
      "\u001b[34mval idx: 105, loss: 0.121103\u001b[0m\n",
      "\u001b[34mval idx: 106, loss: 0.12111\u001b[0m\n",
      "\u001b[34mval idx: 107, loss: 0.121082\u001b[0m\n",
      "\u001b[34mval idx: 108, loss: 0.120908\u001b[0m\n",
      "\u001b[34mval idx: 109, loss: 0.120902\u001b[0m\n",
      "\u001b[34mval idx: 110, loss: 0.120865\u001b[0m\n",
      "\u001b[34mval idx: 111, loss: 0.12081\u001b[0m\n",
      "\u001b[34mval idx: 112, loss: 0.120799\u001b[0m\n",
      "\u001b[34mval idx: 113, loss: 0.120599\u001b[0m\n",
      "\u001b[34mval idx: 114, loss: 0.120591\u001b[0m\n",
      "\u001b[34mval idx: 115, loss: 0.120495\u001b[0m\n",
      "\u001b[34mval idx: 116, loss: 0.120493\u001b[0m\n",
      "\u001b[34mval idx: 117, loss: 0.120495\u001b[0m\n",
      "\u001b[34mval idx: 118, loss: 0.120515\u001b[0m\n",
      "\u001b[34mval idx: 119, loss: 0.120506\u001b[0m\n",
      "\u001b[34mval idx: 120, loss: 0.120509\u001b[0m\n",
      "\u001b[34mval idx: 121, loss: 0.120362\u001b[0m\n",
      "\u001b[34mval idx: 122, loss: 0.120358\u001b[0m\n",
      "\u001b[34mval idx: 123, loss: 0.120346\u001b[0m\n",
      "\u001b[34mval idx: 124, loss: 0.120311\u001b[0m\n",
      "\u001b[34mval idx: 125, loss: 0.120296\u001b[0m\n",
      "\u001b[34mval idx: 126, loss: 0.120298\u001b[0m\n",
      "\u001b[34mval idx: 127, loss: 0.120223\u001b[0m\n",
      "\u001b[34mval idx: 128, loss: 0.120228\u001b[0m\n",
      "\u001b[34mval idx: 129, loss: 0.120145\u001b[0m\n",
      "\u001b[34mval idx: 130, loss: 0.120157\u001b[0m\n",
      "\u001b[34mval idx: 131, loss: 0.120151\u001b[0m\n",
      "\u001b[34mval idx: 132, loss: 0.120143\u001b[0m\n",
      "\u001b[34mval idx: 133, loss: 0.120108\u001b[0m\n",
      "\u001b[34mval idx: 134, loss: 0.12009\u001b[0m\n",
      "\u001b[34mval idx: 135, loss: 0.120098\u001b[0m\n",
      "\u001b[34mval idx: 136, loss: 0.12009\u001b[0m\n",
      "\u001b[34mval idx: 137, loss: 0.120099\u001b[0m\n",
      "\u001b[34mval idx: 138, loss: 0.120036\u001b[0m\n",
      "\u001b[34mval idx: 139, loss: 0.12001\u001b[0m\n",
      "\u001b[34mval idx: 140, loss: 0.120006\u001b[0m\n",
      "\u001b[34mval idx: 141, loss: 0.120012\u001b[0m\n",
      "\u001b[34mval idx: 142, loss: 0.119907\u001b[0m\n",
      "\u001b[34mval idx: 143, loss: 0.119909\u001b[0m\n",
      "\u001b[34mval idx: 144, loss: 0.119825\u001b[0m\n",
      "\u001b[34mval idx: 145, loss: 0.119823\u001b[0m\n",
      "\u001b[34mval idx: 146, loss: 0.119815\u001b[0m\n",
      "\u001b[34mval idx: 147, loss: 0.119827\u001b[0m\n",
      "\u001b[34mval idx: 148, loss: 0.119815\u001b[0m\n",
      "\u001b[34mval idx: 149, loss: 0.119813\u001b[0m\n",
      "\u001b[34mval idx: 150, loss: 0.119734\u001b[0m\n",
      "\u001b[34mval idx: 151, loss: 0.119736\u001b[0m\n",
      "\u001b[34mval idx: 152, loss: 0.119651\u001b[0m\n",
      "\u001b[34mval idx: 153, loss: 0.119649\u001b[0m\n",
      "\u001b[34mval idx: 154, loss: 0.119652\u001b[0m\n",
      "\u001b[34mval idx: 155, loss: 0.11965\u001b[0m\n",
      "\u001b[34mval idx: 156, loss: 0.119552\u001b[0m\n",
      "\u001b[34mval idx: 157, loss: 0.119324\u001b[0m\n",
      "\u001b[34mval idx: 158, loss: 0.119328\u001b[0m\n",
      "\u001b[34mval idx: 159, loss: 0.119328\u001b[0m\n",
      "\u001b[34mval idx: 160, loss: 0.119241\u001b[0m\n",
      "\u001b[34mval idx: 161, loss: 0.119227\u001b[0m\n",
      "\u001b[34mval idx: 162, loss: 0.119184\u001b[0m\n",
      "\u001b[34mval idx: 163, loss: 0.119158\u001b[0m\n",
      "\u001b[34mval idx: 164, loss: 0.11914\u001b[0m\n",
      "\u001b[34mval idx: 165, loss: 0.119122\u001b[0m\n",
      "\u001b[34mval idx: 166, loss: 0.119114\u001b[0m\n",
      "\u001b[34mval idx: 167, loss: 0.119056\u001b[0m\n",
      "\u001b[34mval idx: 168, loss: 0.118987\u001b[0m\n",
      "\u001b[34mval idx: 169, loss: 0.118959\u001b[0m\n",
      "\u001b[34mval idx: 170, loss: 0.118958\u001b[0m\n",
      "\u001b[34mval idx: 171, loss: 0.118893\u001b[0m\n",
      "\u001b[34mval idx: 172, loss: 0.11882\u001b[0m\n",
      "\u001b[34mval idx: 173, loss: 0.118816\u001b[0m\n",
      "\u001b[34mval idx: 174, loss: 0.118815\u001b[0m\n",
      "\u001b[34mval idx: 175, loss: 0.118815\u001b[0m\n",
      "\u001b[34mval idx: 176, loss: 0.118811\u001b[0m\n",
      "\u001b[34mval idx: 177, loss: 0.118808\u001b[0m\n",
      "\u001b[34mval idx: 178, loss: 0.118774\u001b[0m\n",
      "\u001b[34mval idx: 179, loss: 0.118697\u001b[0m\n",
      "\u001b[34mval idx: 180, loss: 0.118676\u001b[0m\n",
      "\u001b[34mval idx: 181, loss: 0.118685\u001b[0m\n",
      "\u001b[34mval idx: 182, loss: 0.118684\u001b[0m\n",
      "\u001b[34mval idx: 183, loss: 0.118663\u001b[0m\n",
      "\u001b[34mval idx: 184, loss: 0.118664\u001b[0m\n",
      "\u001b[34mval idx: 185, loss: 0.118663\u001b[0m\n",
      "\u001b[34mval idx: 186, loss: 0.118668\u001b[0m\n",
      "\u001b[34mval idx: 187, loss: 0.118677\u001b[0m\n",
      "\u001b[34mval idx: 188, loss: 0.118678\u001b[0m\n",
      "\u001b[34mval idx: 189, loss: 0.118677\u001b[0m\n",
      "\u001b[34mval idx: 190, loss: 0.118681\u001b[0m\n",
      "\u001b[34mval idx: 191, loss: 0.118683\u001b[0m\n",
      "\u001b[34mval idx: 192, loss: 0.11868\u001b[0m\n",
      "\u001b[34mval idx: 193, loss: 0.118688\u001b[0m\n",
      "\u001b[34mval idx: 194, loss: 0.118682\u001b[0m\n",
      "\u001b[34mval idx: 195, loss: 0.11868\u001b[0m\n",
      "\u001b[34mval idx: 196, loss: 0.118667\u001b[0m\n",
      "\u001b[34mval idx: 197, loss: 0.118663\u001b[0m\n",
      "\u001b[34mval idx: 198, loss: 0.118668\u001b[0m\n",
      "\u001b[34mval idx: 199, loss: 0.118568\u001b[0m\n",
      "\u001b[34mval idx: 200, loss: 0.118579\u001b[0m\n",
      "\u001b[34mval idx: 201, loss: 0.118591\u001b[0m\n",
      "\u001b[34mval idx: 202, loss: 0.118538\u001b[0m\n",
      "\u001b[34mval idx: 203, loss: 0.118406\u001b[0m\n",
      "\u001b[34mval idx: 204, loss: 0.118407\u001b[0m\n",
      "\u001b[34mval idx: 205, loss: 0.118408\u001b[0m\n",
      "\u001b[34mval idx: 206, loss: 0.118412\u001b[0m\n",
      "\u001b[34mval idx: 207, loss: 0.118418\u001b[0m\n",
      "\u001b[34mval idx: 208, loss: 0.118368\u001b[0m\n",
      "\u001b[34mval idx: 209, loss: 0.118376\u001b[0m\n",
      "\u001b[34mval idx: 210, loss: 0.118385\u001b[0m\n",
      "\u001b[34mval idx: 211, loss: 0.118384\u001b[0m\n",
      "\u001b[34mval idx: 212, loss: 0.11833\u001b[0m\n",
      "\u001b[34mval idx: 213, loss: 0.118355\u001b[0m\n",
      "\u001b[34mval idx: 214, loss: 0.118359\u001b[0m\n",
      "\u001b[34mval idx: 215, loss: 0.11833\u001b[0m\n",
      "\u001b[34mval idx: 216, loss: 0.118341\u001b[0m\n",
      "\u001b[34mval idx: 217, loss: 0.118337\u001b[0m\n",
      "\u001b[34mval idx: 218, loss: 0.118299\u001b[0m\n",
      "\u001b[34mval idx: 219, loss: 0.118185\u001b[0m\n",
      "\u001b[34mval idx: 220, loss: 0.11818\u001b[0m\n",
      "\u001b[34mval idx: 221, loss: 0.118192\u001b[0m\n",
      "\u001b[34mval idx: 222, loss: 0.118186\u001b[0m\n",
      "\u001b[34mval idx: 223, loss: 0.118117\u001b[0m\n",
      "\u001b[34mval idx: 224, loss: 0.118123\u001b[0m\n",
      "\u001b[34mval idx: 225, loss: 0.118124\u001b[0m\n",
      "\u001b[34mval idx: 226, loss: 0.118117\u001b[0m\n",
      "\u001b[34mval idx: 227, loss: 0.118115\u001b[0m\n",
      "\u001b[34mval idx: 228, loss: 0.118119\u001b[0m\n",
      "\u001b[34mval idx: 229, loss: 0.118125\u001b[0m\n",
      "\u001b[34mval idx: 230, loss: 0.118099\u001b[0m\n",
      "\u001b[34mval idx: 231, loss: 0.11809\u001b[0m\n",
      "\u001b[34mval idx: 232, loss: 0.118098\u001b[0m\n",
      "\u001b[34mval idx: 233, loss: 0.118062\u001b[0m\n",
      "\u001b[34mval idx: 234, loss: 0.118069\u001b[0m\n",
      "\u001b[34mval idx: 235, loss: 0.118071\u001b[0m\n",
      "\u001b[34mval idx: 236, loss: 0.118048\u001b[0m\n",
      "\u001b[34mval idx: 237, loss: 0.118003\u001b[0m\n",
      "\u001b[34mval idx: 238, loss: 0.118003\u001b[0m\n",
      "\u001b[34mval idx: 239, loss: 0.117993\u001b[0m\n",
      "\u001b[34mval idx: 240, loss: 0.117987\u001b[0m\n",
      "\u001b[34mval idx: 241, loss: 0.117987\u001b[0m\n",
      "\u001b[34mval idx: 242, loss: 0.117994\u001b[0m\n",
      "\u001b[34mval idx: 243, loss: 0.117999\u001b[0m\n",
      "\u001b[34mval idx: 244, loss: 0.117985\u001b[0m\n",
      "\u001b[34mval idx: 245, loss: 0.117979\u001b[0m\n",
      "\u001b[34mval idx: 246, loss: 0.117983\u001b[0m\n",
      "\u001b[34mval idx: 247, loss: 0.117963\u001b[0m\n",
      "\u001b[34mval idx: 248, loss: 0.117896\u001b[0m\n",
      "\u001b[34mval idx: 249, loss: 0.117828\u001b[0m\n",
      "\u001b[34mval idx: 250, loss: 0.117739\u001b[0m\n",
      "\u001b[34mval idx: 251, loss: 0.117737\u001b[0m\n",
      "\u001b[34mval idx: 252, loss: 0.117744\u001b[0m\n",
      "\u001b[34mval idx: 253, loss: 0.11774\u001b[0m\n",
      "\u001b[34mval idx: 254, loss: 0.117732\u001b[0m\n",
      "\u001b[34mval idx: 255, loss: 0.117735\u001b[0m\n",
      "\u001b[34mval idx: 256, loss: 0.117723\u001b[0m\n",
      "\u001b[34mval idx: 257, loss: 0.117726\u001b[0m\n",
      "\u001b[34mval idx: 258, loss: 0.117732\u001b[0m\n",
      "\u001b[34mval idx: 259, loss: 0.117743\u001b[0m\n",
      "\u001b[34mval idx: 260, loss: 0.117742\u001b[0m\n",
      "\u001b[34mval idx: 261, loss: 0.117745\u001b[0m\n",
      "\u001b[34mval idx: 262, loss: 0.117743\u001b[0m\n",
      "\u001b[34mval idx: 263, loss: 0.117749\u001b[0m\n",
      "\u001b[34mval idx: 264, loss: 0.117751\u001b[0m\n",
      "\u001b[34mval idx: 265, loss: 0.117725\u001b[0m\n",
      "\u001b[34mval idx: 266, loss: 0.117731\u001b[0m\n",
      "\u001b[34mval idx: 267, loss: 0.11773\u001b[0m\n",
      "\u001b[34mval idx: 268, loss: 0.117735\u001b[0m\n",
      "\u001b[34mval idx: 269, loss: 0.117747\u001b[0m\n",
      "\u001b[34mval idx: 270, loss: 0.117752\u001b[0m\n",
      "\u001b[34mval idx: 271, loss: 0.117748\u001b[0m\n",
      "\u001b[34mval idx: 272, loss: 0.117745\u001b[0m\n",
      "\u001b[34mval idx: 273, loss: 0.117748\u001b[0m\n",
      "\u001b[34mval idx: 274, loss: 0.117762\u001b[0m\n",
      "\u001b[34mval idx: 275, loss: 0.117774\u001b[0m\n",
      "\u001b[34mval idx: 276, loss: 0.117717\u001b[0m\n",
      "\u001b[34mval idx: 277, loss: 0.117707\u001b[0m\n",
      "\u001b[34mval idx: 278, loss: 0.117664\u001b[0m\n",
      "\u001b[34mval idx: 279, loss: 0.117662\u001b[0m\n",
      "\u001b[34mval idx: 280, loss: 0.117633\u001b[0m\n",
      "\u001b[34mval idx: 281, loss: 0.117635\u001b[0m\n",
      "\u001b[34mval idx: 282, loss: 0.117643\u001b[0m\n",
      "\u001b[34mval idx: 283, loss: 0.11763\u001b[0m\n",
      "\u001b[34mval idx: 284, loss: 0.117635\u001b[0m\n",
      "\u001b[34mval idx: 285, loss: 0.117511\u001b[0m\n",
      "\u001b[34mval idx: 286, loss: 0.117512\u001b[0m\n",
      "\u001b[34mval idx: 287, loss: 0.117494\u001b[0m\n",
      "\u001b[34mval idx: 288, loss: 0.11749\u001b[0m\n",
      "\u001b[34mval idx: 289, loss: 0.117362\u001b[0m\n",
      "\u001b[34mval idx: 290, loss: 0.117359\u001b[0m\n",
      "\u001b[34mval idx: 291, loss: 0.117372\u001b[0m\n",
      "\u001b[34mval idx: 292, loss: 0.11735\u001b[0m\n",
      "\u001b[34mval idx: 293, loss: 0.117356\u001b[0m\n",
      "\u001b[34mval idx: 294, loss: 0.117361\u001b[0m\n",
      "\u001b[34mval idx: 295, loss: 0.117369\u001b[0m\n",
      "\u001b[34mval idx: 296, loss: 0.117375\u001b[0m\n",
      "\u001b[34mval idx: 297, loss: 0.117353\u001b[0m\n",
      "\u001b[34mval idx: 298, loss: 0.117356\u001b[0m\n",
      "\u001b[34mval idx: 299, loss: 0.117363\u001b[0m\n",
      "\u001b[34mval idx: 300, loss: 0.117354\u001b[0m\n",
      "\u001b[34mval idx: 301, loss: 0.117356\u001b[0m\n",
      "\u001b[34mval idx: 302, loss: 0.117352\u001b[0m\n",
      "\u001b[34mval idx: 303, loss: 0.117358\u001b[0m\n",
      "\u001b[34mval idx: 304, loss: 0.117364\u001b[0m\n",
      "\u001b[34mval idx: 305, loss: 0.117372\u001b[0m\n",
      "\u001b[34mval idx: 306, loss: 0.1173\u001b[0m\n",
      "\u001b[34mval idx: 307, loss: 0.117291\u001b[0m\n",
      "\u001b[34mval idx: 308, loss: 0.117298\u001b[0m\n",
      "\u001b[34mval idx: 309, loss: 0.1173\u001b[0m\n",
      "\u001b[34mval idx: 310, loss: 0.117247\u001b[0m\n",
      "\u001b[34mval idx: 311, loss: 0.117245\u001b[0m\n",
      "\u001b[34mval idx: 312, loss: 0.117251\u001b[0m\n",
      "\u001b[34mval idx: 313, loss: 0.11726\u001b[0m\n",
      "\u001b[34mval idx: 314, loss: 0.11727\u001b[0m\n",
      "\u001b[34mval idx: 315, loss: 0.117276\u001b[0m\n",
      "\u001b[34mval idx: 316, loss: 0.117285\u001b[0m\n",
      "\u001b[34mval idx: 317, loss: 0.117303\u001b[0m\n",
      "\u001b[34mval idx: 318, loss: 0.117304\u001b[0m\n",
      "\u001b[34mval idx: 319, loss: 0.117307\u001b[0m\n",
      "\u001b[34mval idx: 320, loss: 0.117273\u001b[0m\n",
      "\u001b[34mval idx: 321, loss: 0.117282\u001b[0m\n",
      "\u001b[34mval idx: 322, loss: 0.117276\u001b[0m\n",
      "\u001b[34mval idx: 323, loss: 0.117284\u001b[0m\n",
      "\u001b[34mval idx: 324, loss: 0.117286\u001b[0m\n",
      "\u001b[34mval idx: 325, loss: 0.117282\u001b[0m\n",
      "\u001b[34mval idx: 326, loss: 0.117289\u001b[0m\n",
      "\u001b[34mval idx: 327, loss: 0.117286\u001b[0m\n",
      "\u001b[34mval idx: 328, loss: 0.117269\u001b[0m\n",
      "\u001b[34mval idx: 329, loss: 0.117267\u001b[0m\n",
      "\u001b[34mval idx: 330, loss: 0.117275\u001b[0m\n",
      "\u001b[34mval idx: 331, loss: 0.117288\u001b[0m\n",
      "\u001b[34mval idx: 332, loss: 0.117289\u001b[0m\n",
      "\u001b[34mval idx: 333, loss: 0.11729\u001b[0m\n",
      "\u001b[34mval idx: 334, loss: 0.117289\u001b[0m\n",
      "\u001b[34mval idx: 335, loss: 0.117284\u001b[0m\n",
      "\u001b[34mval idx: 336, loss: 0.117286\u001b[0m\n",
      "\u001b[34mval idx: 337, loss: 0.117295\u001b[0m\n",
      "\u001b[34mval idx: 338, loss: 0.117292\u001b[0m\n",
      "\u001b[34mval idx: 339, loss: 0.117307\u001b[0m\n",
      "\u001b[34mval idx: 340, loss: 0.117304\u001b[0m\n",
      "\u001b[34mval idx: 341, loss: 0.117284\u001b[0m\n",
      "\u001b[34mval idx: 342, loss: 0.117273\u001b[0m\n",
      "\u001b[34mval idx: 343, loss: 0.117271\u001b[0m\n",
      "\u001b[34mval idx: 344, loss: 0.117273\u001b[0m\n",
      "\u001b[34mval idx: 345, loss: 0.117278\u001b[0m\n",
      "\u001b[34mval idx: 346, loss: 0.117265\u001b[0m\n",
      "\u001b[34mval idx: 347, loss: 0.11727\u001b[0m\n",
      "\u001b[34mval idx: 348, loss: 0.117274\u001b[0m\n",
      "\u001b[34mval idx: 349, loss: 0.117276\u001b[0m\n",
      "\u001b[34mval idx: 350, loss: 0.11729\u001b[0m\n",
      "\u001b[34mval idx: 351, loss: 0.117291\u001b[0m\n",
      "\u001b[34mval idx: 352, loss: 0.117247\u001b[0m\n",
      "\u001b[34mval idx: 353, loss: 0.117208\u001b[0m\n",
      "\u001b[34mval idx: 354, loss: 0.117195\u001b[0m\n",
      "\u001b[34mval idx: 355, loss: 0.117198\u001b[0m\n",
      "\u001b[34mval idx: 356, loss: 0.117192\u001b[0m\n",
      "\u001b[34mval idx: 357, loss: 0.117192\u001b[0m\n",
      "\u001b[34mval idx: 358, loss: 0.117196\u001b[0m\n",
      "\u001b[34mval idx: 359, loss: 0.117184\u001b[0m\n",
      "\u001b[34mval idx: 360, loss: 0.117186\u001b[0m\n",
      "\u001b[34mval idx: 361, loss: 0.117186\u001b[0m\n",
      "\u001b[34mval idx: 362, loss: 0.117202\u001b[0m\n",
      "\u001b[34mval idx: 363, loss: 0.117207\u001b[0m\n",
      "\u001b[34mval idx: 364, loss: 0.117222\u001b[0m\n",
      "\u001b[34mval idx: 365, loss: 0.117224\u001b[0m\n",
      "\u001b[34mval idx: 366, loss: 0.117228\u001b[0m\n",
      "\u001b[34mval idx: 367, loss: 0.117226\u001b[0m\n",
      "\u001b[34mval idx: 368, loss: 0.117229\u001b[0m\n",
      "\u001b[34mval idx: 369, loss: 0.117235\u001b[0m\n",
      "\u001b[34mval idx: 370, loss: 0.117243\u001b[0m\n",
      "\u001b[34mval idx: 371, loss: 0.11725\u001b[0m\n",
      "\u001b[34mval idx: 372, loss: 0.11724\u001b[0m\n",
      "\u001b[34mval idx: 373, loss: 0.117251\u001b[0m\n",
      "\u001b[34mval idx: 374, loss: 0.117237\u001b[0m\n",
      "\u001b[34mval idx: 375, loss: 0.117242\u001b[0m\n",
      "\u001b[34mval idx: 376, loss: 0.117244\u001b[0m\n",
      "\u001b[34mval idx: 377, loss: 0.117236\u001b[0m\n",
      "\u001b[34mval idx: 378, loss: 0.117238\u001b[0m\n",
      "\u001b[34mval idx: 379, loss: 0.117253\u001b[0m\n",
      "\u001b[34mval idx: 380, loss: 0.117219\u001b[0m\n",
      "\u001b[34mval idx: 381, loss: 0.117216\u001b[0m\n",
      "\u001b[34mval idx: 382, loss: 0.117218\u001b[0m\n",
      "\u001b[34mval idx: 383, loss: 0.117219\u001b[0m\n",
      "\u001b[34mval idx: 384, loss: 0.117226\u001b[0m\n",
      "\u001b[34mval idx: 385, loss: 0.11723\u001b[0m\n",
      "\u001b[34mval idx: 386, loss: 0.117229\u001b[0m\n",
      "\u001b[34mval idx: 387, loss: 0.117235\u001b[0m\n",
      "\u001b[34mval idx: 388, loss: 0.117235\u001b[0m\n",
      "\u001b[34mval idx: 389, loss: 0.117221\u001b[0m\n",
      "\u001b[34mval idx: 390, loss: 0.117213\u001b[0m\n",
      "\u001b[34mval idx: 391, loss: 0.117211\u001b[0m\n",
      "\u001b[34mval idx: 392, loss: 0.117212\u001b[0m\n",
      "\u001b[34mval idx: 393, loss: 0.117219\u001b[0m\n",
      "\u001b[34mval idx: 394, loss: 0.117228\u001b[0m\n",
      "\u001b[34mval idx: 395, loss: 0.117234\u001b[0m\n",
      "\u001b[34mval idx: 396, loss: 0.117232\u001b[0m\n",
      "\u001b[34mval idx: 397, loss: 0.117231\u001b[0m\n",
      "\u001b[34mval idx: 398, loss: 0.117232\u001b[0m\n",
      "\u001b[34mval idx: 399, loss: 0.117211\u001b[0m\n",
      "\u001b[34mval idx: 400, loss: 0.117208\u001b[0m\n",
      "\u001b[34mval idx: 401, loss: 0.11721\u001b[0m\n",
      "\u001b[34mval idx: 402, loss: 0.117209\u001b[0m\n",
      "\u001b[34mval idx: 403, loss: 0.117212\u001b[0m\n",
      "\u001b[34mval idx: 404, loss: 0.117214\u001b[0m\n",
      "\u001b[34mval idx: 405, loss: 0.117211\u001b[0m\n",
      "\u001b[34mval idx: 406, loss: 0.117219\u001b[0m\n",
      "\u001b[34mval idx: 407, loss: 0.117205\u001b[0m\n",
      "\u001b[34mval idx: 408, loss: 0.117213\u001b[0m\n",
      "\u001b[34mval idx: 409, loss: 0.117213\u001b[0m\n",
      "\u001b[34mval idx: 410, loss: 0.117221\u001b[0m\n",
      "\u001b[34mval idx: 411, loss: 0.117223\u001b[0m\n",
      "\u001b[34mval idx: 412, loss: 0.117226\u001b[0m\n",
      "\u001b[34mval idx: 413, loss: 0.117235\u001b[0m\n",
      "\u001b[34mval idx: 414, loss: 0.11724\u001b[0m\n",
      "\u001b[34mval idx: 415, loss: 0.117246\u001b[0m\n",
      "\u001b[34mval idx: 416, loss: 0.117241\u001b[0m\n",
      "\u001b[34mval idx: 417, loss: 0.117246\u001b[0m\n",
      "\u001b[34mval idx: 418, loss: 0.117224\u001b[0m\n",
      "\u001b[34mval idx: 419, loss: 0.1172\u001b[0m\n",
      "\u001b[34mval idx: 420, loss: 0.117176\u001b[0m\n",
      "\u001b[34mval idx: 421, loss: 0.117184\u001b[0m\n",
      "\u001b[34mval idx: 422, loss: 0.117158\u001b[0m\n",
      "\u001b[34mval idx: 423, loss: 0.117128\u001b[0m\n",
      "\u001b[34mval idx: 424, loss: 0.117131\u001b[0m\n",
      "\u001b[34mval idx: 425, loss: 0.117074\u001b[0m\n",
      "\u001b[34mval idx: 426, loss: 0.117073\u001b[0m\n",
      "\u001b[34mval idx: 427, loss: 0.117075\u001b[0m\n",
      "\u001b[34mval idx: 428, loss: 0.117079\u001b[0m\n",
      "\u001b[34mval idx: 429, loss: 0.117085\u001b[0m\n",
      "\u001b[34mval idx: 430, loss: 0.117086\u001b[0m\n",
      "\u001b[34mval idx: 431, loss: 0.117086\u001b[0m\n",
      "\u001b[34mval idx: 432, loss: 0.117086\u001b[0m\n",
      "\u001b[34mval idx: 433, loss: 0.11709\u001b[0m\n",
      "\u001b[34mval idx: 434, loss: 0.117088\u001b[0m\n",
      "\u001b[34mval idx: 435, loss: 0.117107\u001b[0m\n",
      "\u001b[34mval idx: 436, loss: 0.117108\u001b[0m\n",
      "\u001b[34mval idx: 437, loss: 0.117107\u001b[0m\n",
      "\u001b[34mval idx: 438, loss: 0.1171\u001b[0m\n",
      "\u001b[34mval idx: 439, loss: 0.117102\u001b[0m\n",
      "\u001b[34mval idx: 440, loss: 0.1171\u001b[0m\n",
      "\u001b[34mval idx: 441, loss: 0.117113\u001b[0m\n",
      "\u001b[34mval idx: 442, loss: 0.117119\u001b[0m\n",
      "\u001b[34mval idx: 443, loss: 0.117119\u001b[0m\n",
      "\u001b[34mval idx: 444, loss: 0.1171\u001b[0m\n",
      "\u001b[34mval idx: 445, loss: 0.117102\u001b[0m\n",
      "\u001b[34mval idx: 446, loss: 0.117096\u001b[0m\n",
      "\u001b[34mval idx: 447, loss: 0.117095\u001b[0m\n",
      "\u001b[34mval idx: 448, loss: 0.117101\u001b[0m\n",
      "\u001b[34mval idx: 449, loss: 0.117106\u001b[0m\n",
      "\u001b[34mval idx: 450, loss: 0.117075\u001b[0m\n",
      "\u001b[34mval idx: 451, loss: 0.117094\u001b[0m\n",
      "\u001b[34mval idx: 452, loss: 0.117099\u001b[0m\n",
      "\u001b[34mval idx: 453, loss: 0.117106\u001b[0m\n",
      "\u001b[34mval idx: 454, loss: 0.117107\u001b[0m\n",
      "\u001b[34mval idx: 455, loss: 0.117104\u001b[0m\n",
      "\u001b[34mval idx: 456, loss: 0.117112\u001b[0m\n",
      "\u001b[34mval idx: 457, loss: 0.117111\u001b[0m\n",
      "\u001b[34mval idx: 458, loss: 0.11709\u001b[0m\n",
      "\u001b[34mval idx: 459, loss: 0.117094\u001b[0m\n",
      "\u001b[34mval idx: 460, loss: 0.117103\u001b[0m\n",
      "\u001b[34mval idx: 461, loss: 0.117107\u001b[0m\n",
      "\u001b[34mval idx: 462, loss: 0.117106\u001b[0m\n",
      "\u001b[34mval idx: 463, loss: 0.117109\u001b[0m\n",
      "\u001b[34mval idx: 464, loss: 0.117113\u001b[0m\n",
      "\u001b[34mval idx: 465, loss: 0.117116\u001b[0m\n",
      "\u001b[34mval idx: 466, loss: 0.117111\u001b[0m\n",
      "\u001b[34mval idx: 467, loss: 0.117116\u001b[0m\n",
      "\u001b[34mval idx: 468, loss: 0.117119\u001b[0m\n",
      "\u001b[34mval idx: 469, loss: 0.117118\u001b[0m\n",
      "\u001b[34mval idx: 470, loss: 0.117149\u001b[0m\n",
      "\u001b[34mval idx: 471, loss: 0.117141\u001b[0m\n",
      "\u001b[34mval idx: 472, loss: 0.11713\u001b[0m\n",
      "\u001b[34mval idx: 473, loss: 0.117095\u001b[0m\n",
      "\u001b[34mval idx: 474, loss: 0.117098\u001b[0m\n",
      "\u001b[34mval idx: 475, loss: 0.117097\u001b[0m\n",
      "\u001b[34mval idx: 476, loss: 0.117098\u001b[0m\n",
      "\u001b[34mval idx: 477, loss: 0.117104\u001b[0m\n",
      "\u001b[34mval idx: 478, loss: 0.117097\u001b[0m\n",
      "\u001b[34mval idx: 479, loss: 0.117099\u001b[0m\n",
      "\u001b[34mval idx: 480, loss: 0.117098\u001b[0m\n",
      "\u001b[34mval idx: 481, loss: 0.117091\u001b[0m\n",
      "\u001b[34mval idx: 482, loss: 0.117062\u001b[0m\n",
      "\u001b[34mval idx: 483, loss: 0.117053\u001b[0m\n",
      "\u001b[34mval idx: 484, loss: 0.117059\u001b[0m\n",
      "\u001b[34mval idx: 485, loss: 0.11706\u001b[0m\n",
      "\u001b[34mval idx: 486, loss: 0.117069\u001b[0m\n",
      "\u001b[34mval idx: 487, loss: 0.117064\u001b[0m\n",
      "\u001b[34mval idx: 488, loss: 0.117031\u001b[0m\n",
      "\u001b[34mval idx: 489, loss: 0.117023\u001b[0m\n",
      "\u001b[34mval idx: 490, loss: 0.117005\u001b[0m\n",
      "\u001b[34mval idx: 491, loss: 0.116995\u001b[0m\n",
      "\u001b[34mval idx: 492, loss: 0.116988\u001b[0m\n",
      "\u001b[34mval idx: 493, loss: 0.11699\u001b[0m\n",
      "\u001b[34mval idx: 494, loss: 0.117006\u001b[0m\n",
      "\u001b[34mval idx: 495, loss: 0.117012\u001b[0m\n",
      "\u001b[34mval idx: 496, loss: 0.117014\u001b[0m\n",
      "\u001b[34mval idx: 497, loss: 0.117025\u001b[0m\n",
      "\u001b[34mval idx: 498, loss: 0.117024\u001b[0m\n",
      "\u001b[34mval idx: 499, loss: 0.117026\u001b[0m\n",
      "\u001b[34mevaluation results: {'validation_0': OrderedDict([('logloss', [0.543435, 0.443121, 0.371748, 0.319072, 0.27924, 0.248566, 0.224797, 0.206181, 0.191591, 0.179886, 0.170557, 0.163133, 0.156868, 0.151977, 0.147822, 0.144635, 0.142171, 0.139884, 0.137859, 0.136423, 0.135295, 0.13431, 0.13347, 0.132802, 0.131669, 0.130914, 0.130216, 0.129761, 0.129243, 0.128624, 0.128274, 0.128025, 0.127752, 0.127422, 0.127339, 0.127194, 0.126976, 0.126527, 0.126173, 0.12594, 0.125654, 0.125447, 0.125026, 0.124887, 0.124596, 0.124357, 0.124187, 0.123982, 0.123939, 0.123883, 0.123514, 0.123392, 0.12333, 0.12321, 0.123144, 0.123108, 0.122937, 0.122756, 0.122553, 0.122399, 0.122133, 0.122085, 0.122035, 0.121994, 0.121928, 0.121872, 0.121679, 0.121639, 0.121272, 0.120987, 0.120932, 0.12061, 0.120585, 0.120534, 0.120399, 0.120289, 0.120262, 0.120228, 0.120097, 0.120046, 0.120015, 0.119951, 0.119875, 0.119776, 0.119589, 0.119506, 0.119485, 0.119424, 0.11933, 0.119293, 0.119013, 0.118994, 0.118945, 0.118712, 0.118652, 0.11861, 0.118579, 0.118529, 0.11844, 0.118418, 0.11838, 0.11836, 0.118305, 0.118287, 0.118269, 0.118241, 0.118229, 0.118177, 0.117954, 0.117907, 0.117844, 0.117751, 0.11774, 0.117545, 0.117502, 0.117374, 0.117353, 0.117326, 0.117281, 0.117228, 0.117216, 0.117051, 0.117019, 0.116975, 0.116915, 0.116867, 0.116848, 0.116734, 0.116694, 0.116597, 0.116556, 0.116525, 0.116462, 0.116403, 0.116348, 0.116339, 0.116293, 0.116274, 0.116187, 0.116124, 0.116089, 0.116058, 0.115923, 0.115891, 0.115777, 0.11577, 0.115738, 0.115679, 0.115654, 0.115642, 0.115546, 0.115534, 0.115435, 0.115402, 0.115377, 0.115328, 0.115229, 0.115015, 0.114981, 0.114966, 0.114871, 0.114827, 0.114755, 0.114704, 0.114676, 0.114636, 0.114602, 0.114523, 0.114424, 0.114366, 0.114351, 0.114255, 0.114191, 0.114164, 0.114116, 0.114111, 0.114088, 0.114071, 0.113999, 0.113892, 0.113861, 0.113831, 0.113817, 0.113761, 0.113741, 0.113712, 0.113673, 0.113651, 0.113615, 0.113599, 0.11356, 0.11353, 0.113519, 0.113484, 0.113453, 0.113445, 0.113417, 0.113376, 0.113354, 0.11324, 0.113211, 0.113168, 0.113101, 0.112957, 0.11295, 0.112919, 0.112899, 0.112886, 0.112824, 0.112816, 0.112801, 0.112758, 0.112677, 0.11263, 0.112622, 0.112566, 0.112535, 0.112495, 0.112434, 0.112305, 0.112289, 0.11226, 0.112234, 0.112139, 0.112115, 0.112103, 0.112093, 0.112087, 0.112072, 0.112052, 0.111996, 0.11195, 0.111924, 0.111863, 0.111826, 0.111808, 0.111747, 0.111664, 0.111622, 0.111575, 0.111549, 0.111528, 0.111518, 0.111486, 0.11144, 0.111417, 0.111408, 0.111361, 0.111278, 0.111193, 0.111103, 0.111061, 0.111041, 0.111033, 0.110992, 0.110959, 0.110914, 0.110903, 0.110867, 0.110837, 0.110812, 0.110791, 0.110787, 0.110755, 0.110748, 0.110703, 0.110685, 0.110669, 0.110648, 0.110631, 0.110599, 0.110545, 0.110527, 0.110505, 0.110478, 0.110434, 0.110351, 0.110306, 0.110247, 0.110222, 0.110195, 0.110168, 0.110135, 0.110111, 0.110094, 0.109967, 0.10993, 0.109892, 0.109862, 0.109721, 0.109705, 0.109678, 0.109634, 0.109608, 0.109597, 0.109589, 0.109568, 0.10951, 0.109483, 0.109453, 0.109439, 0.109418, 0.109397, 0.109375, 0.10937, 0.109349, 0.109271, 0.10925, 0.109221, 0.109213, 0.109154, 0.109126, 0.109104, 0.109086, 0.109061, 0.109036, 0.109007, 0.108971, 0.108942, 0.108927, 0.108879, 0.108866, 0.108832, 0.108812, 0.108781, 0.108758, 0.108733, 0.108711, 0.108658, 0.108629, 0.108599, 0.108576, 0.108555, 0.108536, 0.108506, 0.108489, 0.108471, 0.108452, 0.108441, 0.108398, 0.108366, 0.108337, 0.108307, 0.108291, 0.108271, 0.108237, 0.108199, 0.10818, 0.10817, 0.108164, 0.108141, 0.108123, 0.108063, 0.107993, 0.107962, 0.10794, 0.107923, 0.107915, 0.107904, 0.107876, 0.107867, 0.10784, 0.107821, 0.107799, 0.107776, 0.10775, 0.107741, 0.10773, 0.107704, 0.107691, 0.107664, 0.107651, 0.107604, 0.107573, 0.10754, 0.107534, 0.107514, 0.10748, 0.107475, 0.107448, 0.107406, 0.107394, 0.107386, 0.107358, 0.107327, 0.107295, 0.107266, 0.107252, 0.10724, 0.107212, 0.107172, 0.107137, 0.107117, 0.107111, 0.107094, 0.107087, 0.10707, 0.107035, 0.107004, 0.106957, 0.106955, 0.106944, 0.106936, 0.106919, 0.106893, 0.106869, 0.10685, 0.106825, 0.106803, 0.106789, 0.106763, 0.106746, 0.106714, 0.106696, 0.106672, 0.106646, 0.106622, 0.106609, 0.106567, 0.106535, 0.106496, 0.106485, 0.106433, 0.106377, 0.106369, 0.106301, 0.106281, 0.106269, 0.106261, 0.106234, 0.106215, 0.106215, 0.106208, 0.106192, 0.106181, 0.106151, 0.106124, 0.106113, 0.106085, 0.106063, 0.106046, 0.106027, 0.106006, 0.105998, 0.105976, 0.105942, 0.105923, 0.105912, 0.105901, 0.10588, 0.105821, 0.105784, 0.105768, 0.105743, 0.105722, 0.105695, 0.105683, 0.10566, 0.105626, 0.105606, 0.105583, 0.105567, 0.105555, 0.105543, 0.10552, 0.105506, 0.105488, 0.105465, 0.105446, 0.105429, 0.105393, 0.10536, 0.10534, 0.105291, 0.105279, 0.105266, 0.105251, 0.105231, 0.105195, 0.105176, 0.105163, 0.105146, 0.105094, 0.105072, 0.105062, 0.10505, 0.10503, 0.105017, 0.104967, 0.104941, 0.104911, 0.104888, 0.104872, 0.104846, 0.104816, 0.104804, 0.104799, 0.10477, 0.10475, 0.104739])]), 'validation_1': OrderedDict([('logloss', [0.543659, 0.443381, 0.372115, 0.319515, 0.279714, 0.249201, 0.225526, 0.206898, 0.192272, 0.180736, 0.171497, 0.164053, 0.157792, 0.15293, 0.148722, 0.145616, 0.143106, 0.140845, 0.138886, 0.137479, 0.136384, 0.135444, 0.134653, 0.134005, 0.132763, 0.132049, 0.131324, 0.130848, 0.130368, 0.129744, 0.129413, 0.129228, 0.128973, 0.12865, 0.128588, 0.128453, 0.128274, 0.127826, 0.127505, 0.127284, 0.127044, 0.126891, 0.126492, 0.126352, 0.126072, 0.125845, 0.125695, 0.125513, 0.125466, 0.125428, 0.125041, 0.124951, 0.124898, 0.124819, 0.124771, 0.12474, 0.124582, 0.12444, 0.124256, 0.12411, 0.123827, 0.123811, 0.123788, 0.123763, 0.123702, 0.123667, 0.123501, 0.123474, 0.123163, 0.122867, 0.122858, 0.122536, 0.122541, 0.122525, 0.122411, 0.122309, 0.122299, 0.122291, 0.1222, 0.122208, 0.122211, 0.122208, 0.122179, 0.122076, 0.121898, 0.121848, 0.121833, 0.121817, 0.12175, 0.121743, 0.121452, 0.121453, 0.12145, 0.1212, 0.121183, 0.121158, 0.121149, 0.121161, 0.121121, 0.121121, 0.121132, 0.121137, 0.121116, 0.12112, 0.121109, 0.121103, 0.12111, 0.121082, 0.120908, 0.120902, 0.120865, 0.12081, 0.120799, 0.120599, 0.120591, 0.120495, 0.120493, 0.120495, 0.120515, 0.120506, 0.120509, 0.120362, 0.120358, 0.120346, 0.120311, 0.120296, 0.120298, 0.120223, 0.120228, 0.120145, 0.120157, 0.120151, 0.120143, 0.120108, 0.12009, 0.120098, 0.12009, 0.120099, 0.120036, 0.12001, 0.120006, 0.120012, 0.119907, 0.119909, 0.119825, 0.119823, 0.119815, 0.119827, 0.119815, 0.119813, 0.119734, 0.119736, 0.119651, 0.119649, 0.119652, 0.11965, 0.119552, 0.119324, 0.119328, 0.119328, 0.119241, 0.119227, 0.119184, 0.119158, 0.11914, 0.119122, 0.119114, 0.119056, 0.118987, 0.118959, 0.118958, 0.118893, 0.11882, 0.118816, 0.118815, 0.118815, 0.118811, 0.118808, 0.118774, 0.118697, 0.118676, 0.118685, 0.118684, 0.118663, 0.118664, 0.118663, 0.118668, 0.118677, 0.118678, 0.118677, 0.118681, 0.118683, 0.11868, 0.118688, 0.118682, 0.11868, 0.118667, 0.118663, 0.118668, 0.118568, 0.118579, 0.118591, 0.118538, 0.118406, 0.118407, 0.118408, 0.118412, 0.118418, 0.118368, 0.118376, 0.118385, 0.118384, 0.11833, 0.118355, 0.118359, 0.11833, 0.118341, 0.118337, 0.118299, 0.118185, 0.11818, 0.118192, 0.118186, 0.118117, 0.118123, 0.118124, 0.118117, 0.118115, 0.118119, 0.118125, 0.118099, 0.11809, 0.118098, 0.118062, 0.118069, 0.118071, 0.118048, 0.118003, 0.118003, 0.117993, 0.117987, 0.117987, 0.117994, 0.117999, 0.117985, 0.117979, 0.117983, 0.117963, 0.117896, 0.117828, 0.117739, 0.117737, 0.117744, 0.11774, 0.117732, 0.117735, 0.117723, 0.117726, 0.117732, 0.117743, 0.117742, 0.117745, 0.117743, 0.117749, 0.117751, 0.117725, 0.117731, 0.11773, 0.117735, 0.117747, 0.117752, 0.117748, 0.117745, 0.117748, 0.117762, 0.117774, 0.117717, 0.117707, 0.117664, 0.117662, 0.117633, 0.117635, 0.117643, 0.11763, 0.117635, 0.117511, 0.117512, 0.117494, 0.11749, 0.117362, 0.117359, 0.117372, 0.11735, 0.117356, 0.117361, 0.117369, 0.117375, 0.117353, 0.117356, 0.117363, 0.117354, 0.117356, 0.117352, 0.117358, 0.117364, 0.117372, 0.1173, 0.117291, 0.117298, 0.1173, 0.117247, 0.117245, 0.117251, 0.11726, 0.11727, 0.117276, 0.117285, 0.117303, 0.117304, 0.117307, 0.117273, 0.117282, 0.117276, 0.117284, 0.117286, 0.117282, 0.117289, 0.117286, 0.117269, 0.117267, 0.117275, 0.117288, 0.117289, 0.11729, 0.117289, 0.117284, 0.117286, 0.117295, 0.117292, 0.117307, 0.117304, 0.117284, 0.117273, 0.117271, 0.117273, 0.117278, 0.117265, 0.11727, 0.117274, 0.117276, 0.11729, 0.117291, 0.117247, 0.117208, 0.117195, 0.117198, 0.117192, 0.117192, 0.117196, 0.117184, 0.117186, 0.117186, 0.117202, 0.117207, 0.117222, 0.117224, 0.117228, 0.117226, 0.117229, 0.117235, 0.117243, 0.11725, 0.11724, 0.117251, 0.117237, 0.117242, 0.117244, 0.117236, 0.117238, 0.117253, 0.117219, 0.117216, 0.117218, 0.117219, 0.117226, 0.11723, 0.117229, 0.117235, 0.117235, 0.117221, 0.117213, 0.117211, 0.117212, 0.117219, 0.117228, 0.117234, 0.117232, 0.117231, 0.117232, 0.117211, 0.117208, 0.11721, 0.117209, 0.117212, 0.117214, 0.117211, 0.117219, 0.117205, 0.117213, 0.117213, 0.117221, 0.117223, 0.117226, 0.117235, 0.11724, 0.117246, 0.117241, 0.117246, 0.117224, 0.1172, 0.117176, 0.117184, 0.117158, 0.117128, 0.117131, 0.117074, 0.117073, 0.117075, 0.117079, 0.117085, 0.117086, 0.117086, 0.117086, 0.11709, 0.117088, 0.117107, 0.117108, 0.117107, 0.1171, 0.117102, 0.1171, 0.117113, 0.117119, 0.117119, 0.1171, 0.117102, 0.117096, 0.117095, 0.117101, 0.117106, 0.117075, 0.117094, 0.117099, 0.117106, 0.117107, 0.117104, 0.117112, 0.117111, 0.11709, 0.117094, 0.117103, 0.117107, 0.117106, 0.117109, 0.117113, 0.117116, 0.117111, 0.117116, 0.117119, 0.117118, 0.117149, 0.117141, 0.11713, 0.117095, 0.117098, 0.117097, 0.117098, 0.117104, 0.117097, 0.117099, 0.117098, 0.117091, 0.117062, 0.117053, 0.117059, 0.11706, 0.117069, 0.117064, 0.117031, 0.117023, 0.117005, 0.116995, 0.116988, 0.11699, 0.117006, 0.117012, 0.117014, 0.117025, 0.117024, 0.117026])])}\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:585: UserWarning: kwargs is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\u001b[0m\n",
      "\n",
      "2023-02-02 00:51:07 Uploading - Uploading generated training model\n",
      "2023-02-02 00:51:07 Completed - Training job completed\n",
      "Training seconds: 293\n",
      "Billable seconds: 293\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\":5,\n",
    "    \"eta\":0.2,\n",
    "    \"gamma\":4,\n",
    "    \"min_child_weight\":6,\n",
    "    \"subsample\":0.7,\n",
    "    \"n_estimators\":500,\n",
    "    \"region\" : region\n",
    "}\n",
    "\n",
    "with Run(experiment_name=experiment_name, sagemaker_session=sagemaker_session) as run: \n",
    "    # initialize hyperparameters\n",
    "    output_path = 's3://{}/{}/output'.format(bucket, prefix)    \n",
    "    estimator = XGBoost(entry_point = \"pipelines/cust_churn_prediction/train-fs.py\", \n",
    "                    framework_version='1.5-1',\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    volume_size =10,\n",
    "                    output_path=output_path, \n",
    "                    base_job_name=\"kkbox-customer-churn-training\",\n",
    "                    rules=debug_rules)\n",
    "\n",
    "    train_input = TrainingInput(f\"s3://{bucket}/{train_dataset_s3_prefix}\")\n",
    "    test_input = TrainingInput(f\"s3://{bucket}/{test_dataset_s3_prefix}\")\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator.fit({'train': train_input, 'test': test_input})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f3a52-481c-467c-9424-9d6df30bedde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize Training performance using SageMaker Experiment\n",
    "\n",
    "From the training run, we captured a few performance matrics, including the training and testing loss, confusion matrix and precision recall and ROC Curve.\n",
    "Additionally, we can use SageMaker Experiment to visualize these metrics as charts to help us understand the model. \n",
    "\n",
    "![sagemaker experiment metrics](img/sm_experiment_metrics.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c272de3-5775-4b76-9986-9389f1e3e2b1",
   "metadata": {},
   "source": [
    "Here are the visualization that provides insights into validation loss over time, confusion matrix, precision recall and ROC Curve.\n",
    "\n",
    "![sagemaker experiment pr](img/sm-experiment-pr-curve.png)\n",
    "![sagemaker experiment roc](img/sm-experiment-cm-roc-curve.png)\n",
    "![sagemaker experiment logloss](img/sm-experiment-logloss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f9b59-87c9-49a4-8e7e-2d142afae145",
   "metadata": {
    "tags": []
   },
   "source": [
    "For SageMaker Debugger, here's the list of rules and system utilization over the course of training time.\n",
    "![sagemaker experiment debugger rules](img/sm-debugger-rules.png)\n",
    "\n",
    "![sagemaker experiment debugger system](img/sm-debugger-system.png)\n",
    "\n",
    "![sagemaker experiment debugger gpu system](img/sm-debugger-gpu-system.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471764c-ad3a-48f0-8310-1293e506a1af",
   "metadata": {},
   "source": [
    "## Automatic Hyperparameter Tuning\n",
    "\n",
    "Amazon SageMaker automatic model tuning (AMT), also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset. To do this, AMT uses the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that creates a model that performs the best, as measured by a metric that you choose.\n",
    "\n",
    "Here's are the approaches supported by SageMaker Hyperparameter Tuning:\n",
    "\n",
    "## Grid Search\n",
    "Hyperparameter tuning chooses combinations of values from the range of categorical values that you specify when you create the job. Only categorical parameters are supported when using the grid search strategy. \n",
    "\n",
    "## Random Search\n",
    "Hyperparameter tuning chooses a random combination of values from within the ranges that you specify for hyperparameters for each training job it launches. \n",
    "\n",
    "## Bayesian Optimization\n",
    "Bayesian optimization treats hyperparameter tuning like a regression problem. Given a set of input features (the hyperparameters), hyperparameter tuning optimizes a model for the metric that you choose. To solve a regression problem, hyperparameter tuning makes guesses about which hyperparameter combinations are likely to get the best results, and runs training jobs to test these values. After testing a set of hyperparameter values, hyperparameter tuning uses regression to choose the next set of hyperparameter values to test.\n",
    "\n",
    "## Hyperband \n",
    "Multi-fidelity based tuning strategy that dynamically reallocates resources. Hyperband uses both intermediate and final results of training jobs to re-allocate epochs to well-utilized hyperparameter configurations and automatically stops those that underperform. \n",
    "\n",
    "For this experiment, we'll leverage HPO to automatically tune both eta and max_depth parameters. We'll use Hyperband as the optimization technique to train the XGBoost model and observe the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0375e579-d91a-4162-a2f0-3d5392da1566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a122af64-93f4-4bfa-832e-c7a75315a8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.2xlarge.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-xgboost-230202-0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................!\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\":5,\n",
    "    \"eta\":0.2,\n",
    "    \"gamma\":4,\n",
    "    \"min_child_weight\":6,\n",
    "    \"subsample\":0.7,\n",
    "    \"n_estimators\":100,\n",
    "    \"region\" : region,\n",
    "    \"sm_experiment\" : experiment_name,\n",
    "    \"sm_run\" : \"default\"\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:logloss\"\n",
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)    \n",
    "estimator = XGBoost(entry_point = \"pipelines/cust_churn_prediction/train-fs.py\", \n",
    "                framework_version='1.5-1',\n",
    "                hyperparameters=hyperparameters,\n",
    "                role=sagemaker.get_execution_role(),\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.2xlarge',\n",
    "                volume_size =10,\n",
    "                output_path=output_path, \n",
    "                base_job_name=\"kkbox-customer-churn-training\")\n",
    "\n",
    "train_input = TrainingInput(f\"s3://{bucket}/{train_dataset_s3_prefix}\")\n",
    "test_input = TrainingInput(f\"s3://{bucket}/{test_dataset_s3_prefix}\")\n",
    "\n",
    "strategy_config = StrategyConfig(\n",
    "    HyperbandStrategyConfig(\n",
    "        max_resource=10,\n",
    "        min_resource=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# metric_definitions = [ { 'Name': 'validation:logloss', 'Regex': \"validation:logloss=(.*?);\"} ]\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator, \n",
    "    objective_metric_name, \n",
    "    hyperparameter_ranges, \n",
    "    max_jobs=6, \n",
    "    max_parallel_jobs=3,\n",
    "    strategy=\"Hyperband\",\n",
    "    objective_type=\"Minimize\",\n",
    "    strategy_config=strategy_config)\n",
    "    \n",
    "tuner.fit({'train': train_input, 'test': test_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6e970-f909-4ccf-b386-7425bc905290",
   "metadata": {},
   "source": [
    "# HyperParameter Tuner Job Analysis\n",
    "\n",
    "After the HPO jobs complete, we can use SageMaker Experiment to evaluate the metrics for determining the best model. In our example, we defined \n",
    " validation:logloss as our objective metrics. In Sagemaker Experiment, we plot a bar chart to show the metrics for each job triggered by the HPO. \n",
    "    \n",
    "![sagemaker experiment hpo analysis](img/sm-hpo-analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f32c16-645a-4cc5-bac3-6f212b9319d2",
   "metadata": {},
   "source": [
    "We could retrieve the best performant model using the SDK directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad58f0af-f0cb-4a73-9e26-9f7b1e355170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.2xlarge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 03:33:10 Starting - Found matching resource for reuse\n",
      "2023-02-02 03:33:10 Downloading - Downloading input data\n",
      "2023-02-02 03:33:10 Training - Training image download completed. Training in progress.\n",
      "2023-02-02 03:33:10 Uploading - Uploading generated training model\n",
      "2023-02-02 03:33:10 Completed - Resource released due to keep alive period expiry\u001b[34m[2023-02-02 03:31:17.713 ip-10-0-89-11.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:logloss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Module train-fs does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:17:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-fs\n",
      "  Building wheel for train-fs (setup.py): started\n",
      "  Building wheel for train-fs (setup.py): finished with status 'done'\n",
      "  Created wheel for train-fs: filename=train_fs-1.0.0-py2.py3-none-any.whl size=7384 sha256=6c7f742bc6d1debfbb88142ba70cfad88ca6059c276a1728cd6b06577f14213b\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-9rof5yl6/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built train-fs\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-fs\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-fs-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:19:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:logloss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:19:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-02-02:03:31:19:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_class_name\": \"XGBoost\",\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.xgboost.estimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.07798840012205221,\n",
      "        \"gamma\": 4,\n",
      "        \"max_depth\": 8,\n",
      "        \"min_child_weight\": 6,\n",
      "        \"n_estimators\": 100,\n",
      "        \"region\": \"us-east-1\",\n",
      "        \"sm_experiment\": \"kkbox-customer-churn-model-experiment\",\n",
      "        \"sm_run\": \"default\",\n",
      "        \"subsample\": 0.7\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-230202-0327-004-094f7b87\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-03-27-20-265/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-fs\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-fs.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":0.07798840012205221,\"gamma\":4,\"max_depth\":8,\"min_child_weight\":6,\"n_estimators\":100,\"region\":\"us-east-1\",\"sm_experiment\":\"kkbox-customer-churn-model-experiment\",\"sm_run\":\"default\",\"subsample\":0.7}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-fs.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-fs\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-03-27-20-265/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":0.07798840012205221,\"gamma\":4,\"max_depth\":8,\"min_child_weight\":6,\"n_estimators\":100,\"region\":\"us-east-1\",\"sm_experiment\":\"kkbox-customer-churn-model-experiment\",\"sm_run\":\"default\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-230202-0327-004-094f7b87\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-602900100639/kkbox-customer-churn-training-2023-02-02-03-27-20-265/source/sourcedir.tar.gz\",\"module_name\":\"train-fs\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-fs.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.07798840012205221\",\"--gamma\",\"4\",\"--max_depth\",\"8\",\"--min_child_weight\",\"6\",\"--n_estimators\",\"100\",\"--region\",\"us-east-1\",\"--sm_experiment\",\"kkbox-customer-churn-model-experiment\",\"--sm_run\",\"default\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.07798840012205221\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=4\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=8\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_REGION=us-east-1\u001b[0m\n",
      "\u001b[34mSM_HP_SM_EXPERIMENT=kkbox-customer-churn-model-experiment\u001b[0m\n",
      "\u001b[34mSM_HP_SM_RUN=default\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m train-fs --eta 0.07798840012205221 --gamma 4 --max_depth 8 --min_child_weight 6 --n_estimators 100 --region us-east-1 --sm_experiment kkbox-customer-churn-model-experiment --sm_run default --subsample 0.7\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.131.0.tar.gz (665 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 665.5/665.5 kB 53.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug in /miniconda3/lib/python3.8/site-packages (1.0.10)\u001b[0m\n",
      "\u001b[34mCollecting smdebug\n",
      "  Downloading smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 270.1/270.1 kB 49.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting attrs<23,>=20.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 18.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.62-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 33.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 17.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 19.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyinstrument==3.4.2\n",
      "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.3/83.3 kB 22.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyinstrument-cext>=0.2.2\n",
      "  Downloading pyinstrument_cext-0.2.4-cp38-cp38-manylinux2010_x86_64.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 22.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.30.0,>=1.29.62\n",
      "  Downloading botocore-1.29.62-py3-none-any.whl (10.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.4/10.4 MB 56.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.12.0-py3-none-any.whl (6.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /miniconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 15.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 33.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 33.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.62->boto3<2.0,>=1.26.28->sagemaker) (1.26.5)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.131.0-py2.py3-none-any.whl size=902760 sha256=d30d1b539b90c96cd4a38fa9861dc3d3f599493910fe3b38bb0ff1390c7ea547\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/a2/7e/daeaa6ecdd8aa0c3786fabba91ec5f9339f17556a121dfd690\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=416b5e5f5075f3d0a4d519a37a4ae14b9196bf240fc5124c417f6bc69e1e029a\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyinstrument-cext, zipp, smdebug_rulesconfig, pyinstrument, protobuf3-to-dict, ppft, pox, google-pasta, dill, contextlib2, attrs, schema, multiprocess, importlib-metadata, botocore, s3transfer, pathos, boto3, smdebug, sagemaker\n",
      "  Attempting uninstall: pyinstrument\n",
      "    Found existing installation: pyinstrument 4.3.0\n",
      "    Uninstalling pyinstrument-4.3.0:\n",
      "      Successfully uninstalled pyinstrument-4.3.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled botocore-1.20.52\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\u001b[0m\n",
      "\u001b[34m    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\n",
      "  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.10\n",
      "    Uninstalling smdebug-1.0.10:\n",
      "      Successfully uninstalled smdebug-1.0.10\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.26.62 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.29.62 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires smdebug==1.0.10, but you have smdebug 1.0.12 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed attrs-22.2.0 boto3-1.26.62 botocore-1.29.62 contextlib2-21.6.0 dill-0.3.6 google-pasta-0.2.0 importlib-metadata-4.13.0 multiprocess-0.70.14 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyinstrument-3.4.2 pyinstrument-cext-0.2.4 s3transfer-0.6.0 sagemaker-2.131.0 schema-0.7.5 smdebug-1.0.12 smdebug_rulesconfig-1.0.1 zipp-3.12.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[2023-02-02 03:31:27.977 ip-10-0-89-11.ec2.internal:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-02-02 03:31:27.999 ip-10-0-89-11.ec2.internal:39 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34mtrain_dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mval_dir: /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mWARNING:sagemaker.experiments.run:run_name is explicitly supplied in load_run, which will be prioritized to load the Run object. In other words, the run name in the experiment config, fetched from the job environment or the current run context, will be ignored.\u001b[0m\n",
      "\u001b[34m[2023-02-02 03:31:48.576 ip-10-0-89-11.ec2.internal:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-02-02 03:31:48.577 ip-10-0-89-11.ec2.internal:39 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-02-02 03:31:48.577 ip-10-0-89-11.ec2.internal:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mERROR:root:0,3.258096538021482,3.4339872044851463,8.239593454305968,1.0986122886681096,0,4.923841059602649,0.5347682119205298,0.4950331125827814,0.5149006622516556,26.84933774834437,28.97019867549669,8.482085415500888,4.098630136986301,2.0,2.0,1.0,2.0,1.0,0.0\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mERROR:root:0,3.295836866004329,3.4339872044851463,8.262300941787448,0.0,0,25.3960396039604,2.915134370579916,1.654879773691655,2.2701555869872703,14.882602545968885,38.844413012729845,8.100366679331,4.69041095890411,0.0,0.0,0.0,0.0,0.0,0.0\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\u001b[0m\n",
      "\u001b[34m[03:31:49] WARNING: ../src/learner.cc:576: \u001b[0m\n",
      "\u001b[34mParameters: { \"callbacks\" } might not be used.\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\u001b[0m\n",
      "\u001b[34m[03:31:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-logloss:0.62977#011validation_1-logloss:0.63006\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-logloss:0.57577#011validation_1-logloss:0.57596\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-logloss:0.52913#011validation_1-logloss:0.52919\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-logloss:0.48791#011validation_1-logloss:0.48849\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-logloss:0.45195#011validation_1-logloss:0.45250\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-logloss:0.42047#011validation_1-logloss:0.42089\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-logloss:0.39242#011validation_1-logloss:0.39277\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-logloss:0.36708#011validation_1-logloss:0.36778\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-logloss:0.34451#011validation_1-logloss:0.34543\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-logloss:0.32438#011validation_1-logloss:0.32526\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-logloss:0.30630#011validation_1-logloss:0.30720\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-logloss:0.28995#011validation_1-logloss:0.29089\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-logloss:0.27512#011validation_1-logloss:0.27612\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-logloss:0.26169#011validation_1-logloss:0.26283\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-logloss:0.24967#011validation_1-logloss:0.25076\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-logloss:0.23867#011validation_1-logloss:0.23989\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-logloss:0.22860#011validation_1-logloss:0.22992\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-logloss:0.21947#011validation_1-logloss:0.22080\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-logloss:0.21106#011validation_1-logloss:0.21253\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-logloss:0.20360#011validation_1-logloss:0.20508\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-logloss:0.19665#011validation_1-logloss:0.19817\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-logloss:0.19034#011validation_1-logloss:0.19197\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-logloss:0.18462#011validation_1-logloss:0.18618\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-logloss:0.17930#011validation_1-logloss:0.18100\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-logloss:0.17437#011validation_1-logloss:0.17621\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-logloss:0.17004#011validation_1-logloss:0.17184\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-logloss:0.16579#011validation_1-logloss:0.16771\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-logloss:0.16201#011validation_1-logloss:0.16390\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-logloss:0.15858#011validation_1-logloss:0.16056\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-logloss:0.15540#011validation_1-logloss:0.15743\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-logloss:0.15248#011validation_1-logloss:0.15457\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-logloss:0.14982#011validation_1-logloss:0.15188\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-logloss:0.14722#011validation_1-logloss:0.14940\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-logloss:0.14499#011validation_1-logloss:0.14722\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-logloss:0.14299#011validation_1-logloss:0.14520\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-logloss:0.14102#011validation_1-logloss:0.14333\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-logloss:0.13928#011validation_1-logloss:0.14162\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-logloss:0.13769#011validation_1-logloss:0.14006\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-logloss:0.13620#011validation_1-logloss:0.13861\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-logloss:0.13473#011validation_1-logloss:0.13720\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-logloss:0.13330#011validation_1-logloss:0.13585\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-logloss:0.13213#011validation_1-logloss:0.13467\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-logloss:0.13096#011validation_1-logloss:0.13363\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-logloss:0.13006#011validation_1-logloss:0.13273\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-logloss:0.12910#011validation_1-logloss:0.13178\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-logloss:0.12818#011validation_1-logloss:0.13100\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-logloss:0.12738#011validation_1-logloss:0.13024\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-logloss:0.12660#011validation_1-logloss:0.12948\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-logloss:0.12588#011validation_1-logloss:0.12884\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-logloss:0.12528#011validation_1-logloss:0.12826\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-logloss:0.12458#011validation_1-logloss:0.12760\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-logloss:0.12391#011validation_1-logloss:0.12701\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-logloss:0.12337#011validation_1-logloss:0.12652\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-logloss:0.12284#011validation_1-logloss:0.12600\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-logloss:0.12240#011validation_1-logloss:0.12562\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-logloss:0.12191#011validation_1-logloss:0.12514\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-logloss:0.12145#011validation_1-logloss:0.12480\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-logloss:0.12098#011validation_1-logloss:0.12435\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-logloss:0.12054#011validation_1-logloss:0.12401\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-logloss:0.12014#011validation_1-logloss:0.12363\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-logloss:0.11984#011validation_1-logloss:0.12334\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-logloss:0.11954#011validation_1-logloss:0.12312\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-logloss:0.11924#011validation_1-logloss:0.12287\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-logloss:0.11906#011validation_1-logloss:0.12271\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-logloss:0.11879#011validation_1-logloss:0.12246\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-logloss:0.11851#011validation_1-logloss:0.12228\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-logloss:0.11823#011validation_1-logloss:0.12208\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-logloss:0.11800#011validation_1-logloss:0.12186\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-logloss:0.11766#011validation_1-logloss:0.12156\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-logloss:0.11746#011validation_1-logloss:0.12145\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-logloss:0.11734#011validation_1-logloss:0.12133\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-logloss:0.11713#011validation_1-logloss:0.12120\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-logloss:0.11696#011validation_1-logloss:0.12106\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-logloss:0.11686#011validation_1-logloss:0.12097\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-logloss:0.11655#011validation_1-logloss:0.12068\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-logloss:0.11631#011validation_1-logloss:0.12047\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-logloss:0.11610#011validation_1-logloss:0.12030\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-logloss:0.11584#011validation_1-logloss:0.12007\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-logloss:0.11568#011validation_1-logloss:0.11994\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-logloss:0.11550#011validation_1-logloss:0.11983\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-logloss:0.11535#011validation_1-logloss:0.11971\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-logloss:0.11514#011validation_1-logloss:0.11955\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-logloss:0.11489#011validation_1-logloss:0.11934\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-logloss:0.11482#011validation_1-logloss:0.11932\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-logloss:0.11472#011validation_1-logloss:0.11927\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-logloss:0.11456#011validation_1-logloss:0.11916\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-logloss:0.11443#011validation_1-logloss:0.11905\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-logloss:0.11430#011validation_1-logloss:0.11900\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-logloss:0.11422#011validation_1-logloss:0.11895\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-logloss:0.11417#011validation_1-logloss:0.11894\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-logloss:0.11404#011validation_1-logloss:0.11882\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-logloss:0.11393#011validation_1-logloss:0.11877\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-logloss:0.11389#011validation_1-logloss:0.11877\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-logloss:0.11374#011validation_1-logloss:0.11865\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-logloss:0.11367#011validation_1-logloss:0.11859\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-logloss:0.11361#011validation_1-logloss:0.11857\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-logloss:0.11352#011validation_1-logloss:0.11856\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-logloss:0.11344#011validation_1-logloss:0.11852\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-logloss:0.11337#011validation_1-logloss:0.11848\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-logloss:0.11323#011validation_1-logloss:0.11836\u001b[0m\n",
      "\u001b[34m[000]#011train-logloss:0.629768;\u001b[0m\n",
      "\u001b[34m[001]#011train-logloss:0.575773;\u001b[0m\n",
      "\u001b[34m[002]#011train-logloss:0.529129;\u001b[0m\n",
      "\u001b[34m[003]#011train-logloss:0.487914;\u001b[0m\n",
      "\u001b[34m[004]#011train-logloss:0.451954;\u001b[0m\n",
      "\u001b[34m[005]#011train-logloss:0.420467;\u001b[0m\n",
      "\u001b[34m[006]#011train-logloss:0.392417;\u001b[0m\n",
      "\u001b[34m[007]#011train-logloss:0.36708;\u001b[0m\n",
      "\u001b[34m[008]#011train-logloss:0.344513;\u001b[0m\n",
      "\u001b[34m[009]#011train-logloss:0.324385;\u001b[0m\n",
      "\u001b[34m[010]#011train-logloss:0.306305;\u001b[0m\n",
      "\u001b[34m[011]#011train-logloss:0.289953;\u001b[0m\n",
      "\u001b[34m[012]#011train-logloss:0.275118;\u001b[0m\n",
      "\u001b[34m[013]#011train-logloss:0.261685;\u001b[0m\n",
      "\u001b[34m[014]#011train-logloss:0.249671;\u001b[0m\n",
      "\u001b[34m[015]#011train-logloss:0.238667;\u001b[0m\n",
      "\u001b[34m[016]#011train-logloss:0.228598;\u001b[0m\n",
      "\u001b[34m[017]#011train-logloss:0.21947;\u001b[0m\n",
      "\u001b[34m[018]#011train-logloss:0.211059;\u001b[0m\n",
      "\u001b[34m[019]#011train-logloss:0.203598;\u001b[0m\n",
      "\u001b[34m[020]#011train-logloss:0.196651;\u001b[0m\n",
      "\u001b[34m[021]#011train-logloss:0.190339;\u001b[0m\n",
      "\u001b[34m[022]#011train-logloss:0.184623;\u001b[0m\n",
      "\u001b[34m[023]#011train-logloss:0.179299;\u001b[0m\n",
      "\u001b[34m[024]#011train-logloss:0.174366;\u001b[0m\n",
      "\u001b[34m[025]#011train-logloss:0.170042;\u001b[0m\n",
      "\u001b[34m[026]#011train-logloss:0.165789;\u001b[0m\n",
      "\u001b[34m[027]#011train-logloss:0.162014;\u001b[0m\n",
      "\u001b[34m[028]#011train-logloss:0.158577;\u001b[0m\n",
      "\u001b[34m[029]#011train-logloss:0.155402;\u001b[0m\n",
      "\u001b[34m[030]#011train-logloss:0.152481;\u001b[0m\n",
      "\u001b[34m[031]#011train-logloss:0.149817;\u001b[0m\n",
      "\u001b[34m[032]#011train-logloss:0.14722;\u001b[0m\n",
      "\u001b[34m[033]#011train-logloss:0.144988;\u001b[0m\n",
      "\u001b[34m[034]#011train-logloss:0.142985;\u001b[0m\n",
      "\u001b[34m[035]#011train-logloss:0.141019;\u001b[0m\n",
      "\u001b[34m[036]#011train-logloss:0.139282;\u001b[0m\n",
      "\u001b[34m[037]#011train-logloss:0.137688;\u001b[0m\n",
      "\u001b[34m[038]#011train-logloss:0.136197;\u001b[0m\n",
      "\u001b[34m[039]#011train-logloss:0.134733;\u001b[0m\n",
      "\u001b[34m[040]#011train-logloss:0.133304;\u001b[0m\n",
      "\u001b[34m[041]#011train-logloss:0.132129;\u001b[0m\n",
      "\u001b[34m[042]#011train-logloss:0.130956;\u001b[0m\n",
      "\u001b[34m[043]#011train-logloss:0.130059;\u001b[0m\n",
      "\u001b[34m[044]#011train-logloss:0.129098;\u001b[0m\n",
      "\u001b[34m[045]#011train-logloss:0.128182;\u001b[0m\n",
      "\u001b[34m[046]#011train-logloss:0.127385;\u001b[0m\n",
      "\u001b[34m[047]#011train-logloss:0.126603;\u001b[0m\n",
      "\u001b[34m[048]#011train-logloss:0.125885;\u001b[0m\n",
      "\u001b[34m[049]#011train-logloss:0.125279;\u001b[0m\n",
      "\u001b[34m[050]#011train-logloss:0.124583;\u001b[0m\n",
      "\u001b[34m[051]#011train-logloss:0.123909;\u001b[0m\n",
      "\u001b[34m[052]#011train-logloss:0.123365;\u001b[0m\n",
      "\u001b[34m[053]#011train-logloss:0.122839;\u001b[0m\n",
      "\u001b[34m[054]#011train-logloss:0.122405;\u001b[0m\n",
      "\u001b[34m[055]#011train-logloss:0.121914;\u001b[0m\n",
      "\u001b[34m[056]#011train-logloss:0.121451;\u001b[0m\n",
      "\u001b[34m[057]#011train-logloss:0.120985;\u001b[0m\n",
      "\u001b[34m[058]#011train-logloss:0.120541;\u001b[0m\n",
      "\u001b[34m[059]#011train-logloss:0.120143;\u001b[0m\n",
      "\u001b[34m[060]#011train-logloss:0.119839;\u001b[0m\n",
      "\u001b[34m[061]#011train-logloss:0.119539;\u001b[0m\n",
      "\u001b[34m[062]#011train-logloss:0.119236;\u001b[0m\n",
      "\u001b[34m[063]#011train-logloss:0.119056;\u001b[0m\n",
      "\u001b[34m[064]#011train-logloss:0.118795;\u001b[0m\n",
      "\u001b[34m[065]#011train-logloss:0.118512;\u001b[0m\n",
      "\u001b[34m[066]#011train-logloss:0.118227;\u001b[0m\n",
      "\u001b[34m[067]#011train-logloss:0.118003;\u001b[0m\n",
      "\u001b[34m[068]#011train-logloss:0.117658;\u001b[0m\n",
      "\u001b[34m[069]#011train-logloss:0.117465;\u001b[0m\n",
      "\u001b[34m[070]#011train-logloss:0.117337;\u001b[0m\n",
      "\u001b[34m[071]#011train-logloss:0.117128;\u001b[0m\n",
      "\u001b[34m[072]#011train-logloss:0.116961;\u001b[0m\n",
      "\u001b[34m[073]#011train-logloss:0.116857;\u001b[0m\n",
      "\u001b[34m[074]#011train-logloss:0.116547;\u001b[0m\n",
      "\u001b[34m[075]#011train-logloss:0.116306;\u001b[0m\n",
      "\u001b[34m[076]#011train-logloss:0.116103;\u001b[0m\n",
      "\u001b[34m[077]#011train-logloss:0.115836;\u001b[0m\n",
      "\u001b[34m[078]#011train-logloss:0.115681;\u001b[0m\n",
      "\u001b[34m[079]#011train-logloss:0.115503;\u001b[0m\n",
      "\u001b[34m[080]#011train-logloss:0.115349;\u001b[0m\n",
      "\u001b[34m[081]#011train-logloss:0.115136;\u001b[0m\n",
      "\u001b[34m[082]#011train-logloss:0.114894;\u001b[0m\n",
      "\u001b[34m[083]#011train-logloss:0.114822;\u001b[0m\n",
      "\u001b[34m[084]#011train-logloss:0.114717;\u001b[0m\n",
      "\u001b[34m[085]#011train-logloss:0.114556;\u001b[0m\n",
      "\u001b[34m[086]#011train-logloss:0.114432;\u001b[0m\n",
      "\u001b[34m[087]#011train-logloss:0.114296;\u001b[0m\n",
      "\u001b[34m[088]#011train-logloss:0.114217;\u001b[0m\n",
      "\u001b[34m[089]#011train-logloss:0.114169;\u001b[0m\n",
      "\u001b[34m[090]#011train-logloss:0.114039;\u001b[0m\n",
      "\u001b[34m[091]#011train-logloss:0.11393;\u001b[0m\n",
      "\u001b[34m[092]#011train-logloss:0.113894;\u001b[0m\n",
      "\u001b[34m[093]#011train-logloss:0.113743;\u001b[0m\n",
      "\u001b[34m[094]#011train-logloss:0.113669;\u001b[0m\n",
      "\u001b[34m[095]#011train-logloss:0.113612;\u001b[0m\n",
      "\u001b[34m[096]#011train-logloss:0.113517;\u001b[0m\n",
      "\u001b[34m[097]#011train-logloss:0.113439;\u001b[0m\n",
      "\u001b[34m[098]#011train-logloss:0.113367;\u001b[0m\n",
      "\u001b[34m[099]#011train-logloss:0.113231;\u001b[0m\n",
      "\u001b[34m[000]#011validation-logloss:0.630055;\u001b[0m\n",
      "\u001b[34m[001]#011validation-logloss:0.575959;\u001b[0m\n",
      "\u001b[34m[002]#011validation-logloss:0.529189;\u001b[0m\n",
      "\u001b[34m[003]#011validation-logloss:0.488488;\u001b[0m\n",
      "\u001b[34m[004]#011validation-logloss:0.452497;\u001b[0m\n",
      "\u001b[34m[005]#011validation-logloss:0.420891;\u001b[0m\n",
      "\u001b[34m[006]#011validation-logloss:0.392769;\u001b[0m\n",
      "\u001b[34m[007]#011validation-logloss:0.367779;\u001b[0m\n",
      "\u001b[34m[008]#011validation-logloss:0.345431;\u001b[0m\n",
      "\u001b[34m[009]#011validation-logloss:0.325264;\u001b[0m\n",
      "\u001b[34m[010]#011validation-logloss:0.307197;\u001b[0m\n",
      "\u001b[34m[011]#011validation-logloss:0.290894;\u001b[0m\n",
      "\u001b[34m[012]#011validation-logloss:0.276116;\u001b[0m\n",
      "\u001b[34m[013]#011validation-logloss:0.262828;\u001b[0m\n",
      "\u001b[34m[014]#011validation-logloss:0.250759;\u001b[0m\n",
      "\u001b[34m[015]#011validation-logloss:0.239894;\u001b[0m\n",
      "\u001b[34m[016]#011validation-logloss:0.229917;\u001b[0m\n",
      "\u001b[34m[017]#011validation-logloss:0.220803;\u001b[0m\n",
      "\u001b[34m[018]#011validation-logloss:0.21253;\u001b[0m\n",
      "\u001b[34m[019]#011validation-logloss:0.205076;\u001b[0m\n",
      "\u001b[34m[020]#011validation-logloss:0.198175;\u001b[0m\n",
      "\u001b[34m[021]#011validation-logloss:0.191966;\u001b[0m\n",
      "\u001b[34m[022]#011validation-logloss:0.186182;\u001b[0m\n",
      "\u001b[34m[023]#011validation-logloss:0.181002;\u001b[0m\n",
      "\u001b[34m[024]#011validation-logloss:0.176208;\u001b[0m\n",
      "\u001b[34m[025]#011validation-logloss:0.171845;\u001b[0m\n",
      "\u001b[34m[026]#011validation-logloss:0.167713;\u001b[0m\n",
      "\u001b[34m[027]#011validation-logloss:0.163896;\u001b[0m\n",
      "\u001b[34m[028]#011validation-logloss:0.160558;\u001b[0m\n",
      "\u001b[34m[029]#011validation-logloss:0.157434;\u001b[0m\n",
      "\u001b[34m[030]#011validation-logloss:0.154571;\u001b[0m\n",
      "\u001b[34m[031]#011validation-logloss:0.151883;\u001b[0m\n",
      "\u001b[34m[032]#011validation-logloss:0.1494;\u001b[0m\n",
      "\u001b[34m[033]#011validation-logloss:0.14722;\u001b[0m\n",
      "\u001b[34m[034]#011validation-logloss:0.145198;\u001b[0m\n",
      "\u001b[34m[035]#011validation-logloss:0.143327;\u001b[0m\n",
      "\u001b[34m[036]#011validation-logloss:0.141616;\u001b[0m\n",
      "\u001b[34m[037]#011validation-logloss:0.140061;\u001b[0m\n",
      "\u001b[34m[038]#011validation-logloss:0.138606;\u001b[0m\n",
      "\u001b[34m[039]#011validation-logloss:0.137202;\u001b[0m\n",
      "\u001b[34m[040]#011validation-logloss:0.13585;\u001b[0m\n",
      "\u001b[34m[041]#011validation-logloss:0.134674;\u001b[0m\n",
      "\u001b[34m[042]#011validation-logloss:0.133627;\u001b[0m\n",
      "\u001b[34m[043]#011validation-logloss:0.132725;\u001b[0m\n",
      "\u001b[34m[044]#011validation-logloss:0.131784;\u001b[0m\n",
      "\u001b[34m[045]#011validation-logloss:0.131004;\u001b[0m\n",
      "\u001b[34m[046]#011validation-logloss:0.130236;\u001b[0m\n",
      "\u001b[34m[047]#011validation-logloss:0.129485;\u001b[0m\n",
      "\u001b[34m[048]#011validation-logloss:0.128845;\u001b[0m\n",
      "\u001b[34m[049]#011validation-logloss:0.128257;\u001b[0m\n",
      "\u001b[34m[050]#011validation-logloss:0.127597;\u001b[0m\n",
      "\u001b[34m[051]#011validation-logloss:0.127006;\u001b[0m\n",
      "\u001b[34m[052]#011validation-logloss:0.126525;\u001b[0m\n",
      "\u001b[34m[053]#011validation-logloss:0.125999;\u001b[0m\n",
      "\u001b[34m[054]#011validation-logloss:0.125623;\u001b[0m\n",
      "\u001b[34m[055]#011validation-logloss:0.12514;\u001b[0m\n",
      "\u001b[34m[056]#011validation-logloss:0.1248;\u001b[0m\n",
      "\u001b[34m[057]#011validation-logloss:0.124355;\u001b[0m\n",
      "\u001b[34m[058]#011validation-logloss:0.124009;\u001b[0m\n",
      "\u001b[34m[059]#011validation-logloss:0.123627;\u001b[0m\n",
      "\u001b[34m[060]#011validation-logloss:0.12334;\u001b[0m\n",
      "\u001b[34m[061]#011validation-logloss:0.123115;\u001b[0m\n",
      "\u001b[34m[062]#011validation-logloss:0.122871;\u001b[0m\n",
      "\u001b[34m[063]#011validation-logloss:0.122708;\u001b[0m\n",
      "\u001b[34m[064]#011validation-logloss:0.122463;\u001b[0m\n",
      "\u001b[34m[065]#011validation-logloss:0.122276;\u001b[0m\n",
      "\u001b[34m[066]#011validation-logloss:0.122075;\u001b[0m\n",
      "\u001b[34m[067]#011validation-logloss:0.121855;\u001b[0m\n",
      "\u001b[34m[068]#011validation-logloss:0.12156;\u001b[0m\n",
      "\u001b[34m[069]#011validation-logloss:0.12145;\u001b[0m\n",
      "\u001b[34m[070]#011validation-logloss:0.12133;\u001b[0m\n",
      "\u001b[34m[071]#011validation-logloss:0.121203;\u001b[0m\n",
      "\u001b[34m[072]#011validation-logloss:0.121062;\u001b[0m\n",
      "\u001b[34m[073]#011validation-logloss:0.120968;\u001b[0m\n",
      "\u001b[34m[074]#011validation-logloss:0.120678;\u001b[0m\n",
      "\u001b[34m[075]#011validation-logloss:0.120466;\u001b[0m\n",
      "\u001b[34m[076]#011validation-logloss:0.120302;\u001b[0m\n",
      "\u001b[34m[077]#011validation-logloss:0.120074;\u001b[0m\n",
      "\u001b[34m[078]#011validation-logloss:0.119944;\u001b[0m\n",
      "\u001b[34m[079]#011validation-logloss:0.119826;\u001b[0m\n",
      "\u001b[34m[080]#011validation-logloss:0.119705;\u001b[0m\n",
      "\u001b[34m[081]#011validation-logloss:0.119555;\u001b[0m\n",
      "\u001b[34m[082]#011validation-logloss:0.119344;\u001b[0m\n",
      "\u001b[34m[083]#011validation-logloss:0.11932;\u001b[0m\n",
      "\u001b[34m[084]#011validation-logloss:0.119267;\u001b[0m\n",
      "\u001b[34m[085]#011validation-logloss:0.119163;\u001b[0m\n",
      "\u001b[34m[086]#011validation-logloss:0.119053;\u001b[0m\n",
      "\u001b[34m[087]#011validation-logloss:0.119002;\u001b[0m\n",
      "\u001b[34m[088]#011validation-logloss:0.118952;\u001b[0m\n",
      "\u001b[34m[089]#011validation-logloss:0.118937;\u001b[0m\n",
      "\u001b[34m[090]#011validation-logloss:0.118821;\u001b[0m\n",
      "\u001b[34m[091]#011validation-logloss:0.118772;\u001b[0m\n",
      "\u001b[34m[092]#011validation-logloss:0.118766;\u001b[0m\n",
      "\u001b[34m[093]#011validation-logloss:0.118646;\u001b[0m\n",
      "\u001b[34m[094]#011validation-logloss:0.118587;\u001b[0m\n",
      "\u001b[34m[095]#011validation-logloss:0.118573;\u001b[0m\n",
      "\u001b[34m[096]#011validation-logloss:0.118559;\u001b[0m\n",
      "\u001b[34m[097]#011validation-logloss:0.11852;\u001b[0m\n",
      "\u001b[34m[098]#011validation-logloss:0.118482;\u001b[0m\n",
      "\u001b[34m[099]#011validation-logloss:0.118359;\u001b[0m\n",
      "\u001b[34mevaluation results: {'validation_0': OrderedDict([('logloss', [0.629768, 0.575773, 0.529129, 0.487914, 0.451954, 0.420467, 0.392417, 0.36708, 0.344513, 0.324385, 0.306305, 0.289953, 0.275118, 0.261685, 0.249671, 0.238667, 0.228598, 0.21947, 0.211059, 0.203598, 0.196651, 0.190339, 0.184623, 0.179299, 0.174366, 0.170042, 0.165789, 0.162014, 0.158577, 0.155402, 0.152481, 0.149817, 0.14722, 0.144988, 0.142985, 0.141019, 0.139282, 0.137688, 0.136197, 0.134733, 0.133304, 0.132129, 0.130956, 0.130059, 0.129098, 0.128182, 0.127385, 0.126603, 0.125885, 0.125279, 0.124583, 0.123909, 0.123365, 0.122839, 0.122405, 0.121914, 0.121451, 0.120985, 0.120541, 0.120143, 0.119839, 0.119539, 0.119236, 0.119056, 0.118795, 0.118512, 0.118227, 0.118003, 0.117658, 0.117465, 0.117337, 0.117128, 0.116961, 0.116857, 0.116547, 0.116306, 0.116103, 0.115836, 0.115681, 0.115503, 0.115349, 0.115136, 0.114894, 0.114822, 0.114717, 0.114556, 0.114432, 0.114296, 0.114217, 0.114169, 0.114039, 0.11393, 0.113894, 0.113743, 0.113669, 0.113612, 0.113517, 0.113439, 0.113367, 0.113231])]), 'validation_1': OrderedDict([('logloss', [0.630055, 0.575959, 0.529189, 0.488488, 0.452497, 0.420891, 0.392769, 0.367779, 0.345431, 0.325264, 0.307197, 0.290894, 0.276116, 0.262828, 0.250759, 0.239894, 0.229917, 0.220803, 0.21253, 0.205076, 0.198175, 0.191966, 0.186182, 0.181002, 0.176208, 0.171845, 0.167713, 0.163896, 0.160558, 0.157434, 0.154571, 0.151883, 0.1494, 0.14722, 0.145198, 0.143327, 0.141616, 0.140061, 0.138606, 0.137202, 0.13585, 0.134674, 0.133627, 0.132725, 0.131784, 0.131004, 0.130236, 0.129485, 0.128845, 0.128257, 0.127597, 0.127006, 0.126525, 0.125999, 0.125623, 0.12514, 0.1248, 0.124355, 0.124009, 0.123627, 0.12334, 0.123115, 0.122871, 0.122708, 0.122463, 0.122276, 0.122075, 0.121855, 0.12156, 0.12145, 0.12133, 0.121203, 0.121062, 0.120968, 0.120678, 0.120466, 0.120302, 0.120074, 0.119944, 0.119826, 0.119705, 0.119555, 0.119344, 0.11932, 0.119267, 0.119163, 0.119053, 0.119002, 0.118952, 0.118937, 0.118821, 0.118772, 0.118766, 0.118646, 0.118587, 0.118573, 0.118559, 0.11852, 0.118482, 0.118359])])}\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:585: UserWarning: kwargs is not saved in Scikit-Learn meta.\n",
      "  warnings.warn(str(k) + ' is not saved in Scikit-Learn meta.', UserWarning)\u001b[0m\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95a0a2b7-f5c7-40db-979d-16cd6ee557d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-602900100639/data/kkbox-customer-churn-model/output/sagemaker-xgboost-230202-0327-004-094f7b87/output/model.tar.gz'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084adbe-3e9b-4229-a15d-8c335ee9fc67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Performance Evaluation\n",
    "\n",
    "Next, we'll perform one final performance evaluation with the validation test dataset that we held out while splitting the data for training. \n",
    "The metrics to capture in our example are:\n",
    "    \n",
    "* auc score\n",
    "* recall\n",
    "* precision\n",
    "* accuracy\n",
    "* F1 score\n",
    "\n",
    "These metrics are to be used as the performance for the model, and will be recorded when we register the model with SageMaker Model Registry.\n",
    "\n",
    "We'll use a SageMaker Processor job to run the model evaluation step, and upload the metrics to the given S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26ee0dbc-7013-4a8b-8af4-72b9477d6f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating processing-job with name model-evaluation-2023-02-02-04-35-49-688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      ".."
     ]
    }
   ],
   "source": [
    "s3_model_evaluation_prefix = \"data/kkbox-customer-churn-model/evaluation\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# define model evaluation step to evaluate the trained model\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"model-evaluation\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "script_eval.run(\n",
    "    code=\"pipelines/cust_churn_prediction/evaluate.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=best_model.model_data, \n",
    "                           destination=\"/opt/ml/processing/model\"),\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{bucket}/{val_dataset_s3_prefix}\",\n",
    "            destination=\"/opt/ml/processing/validation\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                        destination=f\"s3://{bucket}/{s3_model_evaluation_prefix}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4ac25-f7da-47a6-baa8-2c6777257607",
   "metadata": {},
   "source": [
    "# Bias Detection and Model Explainability\n",
    "\n",
    "Algorithmic bias, discrimination, fairness, and related topics have been studied across disciplines such as law, policy,and computer science. The machine learning models powering these applications learn from data and this datamay reflect disparities or other inherent biases. For example, the training data may not have sufficient representation ofvarious feature groups or may contain biased labels. These biases could end up learning them and then reproduce or even exacerbate those biases in their predictions. Thefield of machine learning provides an opportunity to address biases by detecting them and measuring them at eachstage of the ML lifecycle.\n",
    "\n",
    "Amazon SageMaker Clarify can detect potential bias during data preparation, after model training, and in your deployed model. For instance, you can check for bias related to gender in your dataset or in your trained model and receive a detailed report that quantifies different types of potential bias. \n",
    "\n",
    "SageMaker Clarify also includes feature importance scores that help you explain how your model make predictions and produces explainability reports in bulk or real time via online explainability. You can use these reports to support customer or internal presentations, or to identify potential issues with your model.\n",
    "\n",
    "Here's a diagram that outlines how SageMaker Clarify can be integrated into the ML development lifecycle:\n",
    "\n",
    "![sagemaker clarify](img/sm-clarify.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf59c6-e96a-403c-91b7-51cbadd6b048",
   "metadata": {},
   "source": [
    "In the following section, we'll explore SageMaker Clarify capability to provide bias and explainability for our XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6db24e5e-ac75-42f0-aae7-c295fa70d206",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.0.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "# First we'll instantiate a Clarify Processor.\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\", \n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09c3aa40-a417-4905-abf9-0c2697767ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.experiments.run:run_name is explicitly supplied in load_run, which will be prioritized to load the Run object. In other words, the run name in the experiment config, fetched from the job environment or the current run context, will be ignored.\n",
      "INFO:sagemaker.clarify:Analysis Config: {'dataset_type': 'text/csv', 'headers': ['msno', 'is_churn', 'regist_trans', 'mst_frq_plan_days', 'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew'], 'label': 'is_churn', 'label_values_or_threshold': [1], 'facet': [{'name_or_index': 'gender', 'value_or_threshold': [1]}], 'group_variable': 'bd', 'methods': {'report': {'name': 'report', 'title': 'Analysis Report'}, 'pre_training_bias': {'methods': 'all'}}}\n",
      "INFO:sagemaker:Creating processing-job with name clarify-pretrain-bias-1675314395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m2023-02-02 05:11:35,789 logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 This host is algo-1.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 This host is the leader.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,790 Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,792 Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,792 Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:35,803 Loading dataset...\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/analyzer/data_loading/csv_data_loader.py:323: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_tmp, ignore_index=True)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,620 Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 582105 entries, 0 to 582104\u001b[0m\n",
      "\u001b[34mData columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \u001b[0m\n",
      "\u001b[34m---  ------             --------------   -----  \n",
      " 0   msno               582105 non-null  object \n",
      " 1   regist_trans       582105 non-null  float64\n",
      " 2   mst_frq_plan_days  582105 non-null  float64\n",
      " 3   revenue            582105 non-null  float64\n",
      " 4   regist_cancels     582105 non-null  float64\n",
      " 5   bd                 582105 non-null  int64  \n",
      " 6   tenure             582105 non-null  float64\n",
      " 7   num_25             582105 non-null  float64\n",
      " 8   num_50             582105 non-null  float64\n",
      " 9   num_75             582105 non-null  float64\n",
      " 10  num_985            582105 non-null  float64\n",
      " 11  num_100            582105 non-null  float64\n",
      " 12  num_unq            582105 non-null  float64\n",
      " 13  total_secs         582105 non-null  float64\n",
      " 14  city               582105 non-null  float64\n",
      " 15  gender             582105 non-null  float64\n",
      " 16  registered_via     582105 non-null  float64\n",
      " 17  qtr_trans          582105 non-null  float64\n",
      " 18  mst_frq_pay_met    582105 non-null  float64\n",
      " 19  is_auto_renew      582105 non-null  float64\u001b[0m\n",
      "\u001b[34mdtypes: float64(18), int64(1), object(1)\u001b[0m\n",
      "\u001b[34mmemory usage: 88.8+ MB\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,708 Calculated global analysis with predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,708 =====================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,708 Calculating pre-training bias metrics\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,708 =====================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,712 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,728 Column gender with data uniqueness fraction 5.15370938232793e-06 is classifed as a CONTINUOUS column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:469: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,821 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:11:37,830 Threshold Interval indices: IntervalIndex([(1.0, 2.0]], dtype='interval[float64, right]')\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,053 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,053 Calculating bias statistics for report\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,053 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,056 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,070 Column gender with data uniqueness fraction 5.15370938232793e-06 is classifed as a CONTINUOUS column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:469: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,109 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:05,120 Threshold Interval indices: IntervalIndex([(1.0, 2.0]], dtype='interval[float64, right]')\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:08,297 Model performance computations failed.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/analyzer/bias/bias_stats_analyzer.py\", line 118, in generate_model_performance_report\n",
      "    metrics_result: Dict[str, Any] = bias.model_performance_report(\u001b[0m\n",
      "\u001b[34mAttributeError: module 'smclarify.bias' has no attribute 'model_performance_report'\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:08,299 Converting Pandas DataFrame to SparkDataFrame for computing report metadata\u001b[0m\n",
      "\u001b[34m05:12:09.718 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m05:12:26.394 [dispatcher-event-loop-10] WARN  o.a.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:28.289 [dispatcher-event-loop-1] WARN  o.a.spark.scheduler.TaskSetManager - Stage 3 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:29.516 [dispatcher-event-loop-13] WARN  o.a.spark.scheduler.TaskSetManager - Stage 9 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:30.113 [dispatcher-event-loop-12] WARN  o.a.spark.scheduler.TaskSetManager - Stage 12 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:30.821 [dispatcher-event-loop-13] WARN  o.a.spark.scheduler.TaskSetManager - Stage 13 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:31.395 [dispatcher-event-loop-14] WARN  o.a.spark.scheduler.TaskSetManager - Stage 19 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:32.097 [dispatcher-event-loop-1] WARN  o.a.spark.scheduler.TaskSetManager - Stage 22 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:32.699 [dispatcher-event-loop-0] WARN  o.a.spark.scheduler.TaskSetManager - Stage 23 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:33.301 [dispatcher-event-loop-6] WARN  o.a.spark.scheduler.TaskSetManager - Stage 29 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:12:33.753 [dispatcher-event-loop-13] WARN  o.a.spark.scheduler.TaskSetManager - Stage 32 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m#015[Stage 0:>                                                        (0 + 16) / 16]#015#015                                                                                #015#015[Stage 3:>                                                        (0 + 16) / 16]#015#015[Stage 3:=========================>                                (7 + 9) / 16]#015#015                                                                                #015#015[Stage 12:====================================================>   (15 + 1) / 16]#015#015                                                                                #015#015[Stage 19:===================================>                    (10 + 6) / 16]#015#015                                                                                #0152023-02-02 05:12:34,310 Calculated global analysis without predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:34,941 ['jupyter', 'nbconvert', '--to', 'html', '--output', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.ipynb', '--template', 'sagemaker-xai']\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 516874 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:35,924 ['wkhtmltopdf', '-q', '--enable-local-file-access', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.pdf']\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:36,636 Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"pre_training_bias_metrics\": {\n",
      "        \"label\": \"is_churn\",\n",
      "        \"facets\": {\n",
      "            \"gender\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"(1.0, 2.0]\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"CDDL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Labels (CDDL)\",\n",
      "                            \"value\": -0.07153165204777884\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CI\",\n",
      "                            \"description\": \"Class Imbalance (CI)\",\n",
      "                            \"value\": 0.626026232380756\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Labels (DPL)\",\n",
      "                            \"value\": -0.027953510386670585\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"JS\",\n",
      "                            \"description\": \"Jensen-Shannon Divergence (JS)\",\n",
      "                            \"value\": 0.001467043743315321\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KL\",\n",
      "                            \"description\": \"Kullback-Liebler Divergence (KL)\",\n",
      "                            \"value\": 0.005547738890645193\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KS\",\n",
      "                            \"description\": \"Kolmogorov-Smirnov Distance (KS)\",\n",
      "                            \"value\": 0.027953510386670585\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"LP\",\n",
      "                            \"description\": \"L-p Norm (LP)\",\n",
      "                            \"value\": 0.03953223350476665\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TVD\",\n",
      "                            \"description\": \"Total Variation Distance (TVD)\",\n",
      "                            \"value\": 0.027953510386670537\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-02-02 05:12:36,660 exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bias_report_output_path = f\"s3://{bucket}/{prefix}/clarify-bias\"\n",
    "\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=f\"s3://{bucket}/{train_dataset_s3_prefix}/train.csv\",\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"is_churn\",\n",
    "    headers=feature_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"gender\", facet_values_or_threshold=[1], group_name=\"bd\")\n",
    "\n",
    "job_name = f\"clarify-pretrain-bias-{int(time.time())}\"\n",
    "run_name = \"clarify-pretrain-bias\"\n",
    "with load_run(experiment_name=experiment_name, \n",
    "              run_name=run_name,\n",
    "              sagemaker_session=sagemaker_session) as run:    \n",
    "    clarify_processor.run_pre_training_bias(data_config=bias_data_config, \n",
    "                          data_bias_config=bias_config, \n",
    "                          methods='all', \n",
    "                          wait=True, \n",
    "                          logs=True, \n",
    "                          job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d90839-d3d4-4390-8813-1f9e0e4e0cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pretrain Bias Analysis\n",
    "Once the Clarify job is complete, we can view the Pretrain Bias Evaluation analysis report in SageMaker Experiment.\n",
    "\n",
    "![sagemaker clarify pretrain bias](img/sm-clarify-pretrain-bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b145e-df11-402f-9090-227a4ef4bb05",
   "metadata": {},
   "source": [
    "## Model Bias Analysis\n",
    "\n",
    "Similar to the bias analysis for the training dataset, we are also interested in evaluating the bias that the model might exhibit given the signal learn from the training data.\n",
    "\n",
    "Amazon SageMaker Clarify provides eleven posttraining data and model bias metrics to help quantify various conceptions of fairness. These concepts cannot all be satisfied simultaneously and the selection depends on specifics of the cases involving potential bias being analyzed. Most of these metrics are a combination of the numbers taken from the binary classification confusion matrices for the different demographic groups. Because fairness and bias can be defined by a wide range of metrics, human judgment is required to understand and choose which metrics are relevant to the individual use case, and customers should consult with appropriate stakeholders to determine the appropriate measure of fairness for their application.\n",
    "\n",
    "In the following section, we'll launch a SageMaker Clarify processor job to conduct the model bias analysis on the best XGBoost model trained in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9561e74f-e2cd-451c-b860-5dca8b7fef4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n",
      "INFO:sagemaker:Creating model with name: kkbox-customer-churn-model-20230202053205\n"
     ]
    }
   ],
   "source": [
    "model_name=f\"kkbox-customer-churn-model-{strftime('%Y%m%d%H%M%S', gmtime())}\"\n",
    "model = XGBoostModel(\n",
    "    name = model_name,\n",
    "    model_data=best_model.model_data,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    entry_point=\"pipelines/cust_churn_prediction/inference.py\",\n",
    "    framework_version=\"1.5-1\"\n",
    ")\n",
    "model.create(instance_type=inference_serving_instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8aa0ac00-7564-4bca-8874-09ec5b8b5ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=inference_serving_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)\n",
    "bias_report_output_path = f\"s3://{bucket}/{prefix}/clarify-bias\"\n",
    "\n",
    "post_train_bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=f\"s3://{bucket}/{train_dataset_s3_prefix}/train.csv\",\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    headers=feature_cols,\n",
    "    label=\"is_churn\",\n",
    "    dataset_type=\"text/csv\",\n",
    "    excluded_columns=[\"msno\"]\n",
    ")\n",
    "post_train_bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"gender\", facet_values_or_threshold=[1], group_name=\"bd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0da2ac1d-d9ba-4f8b-b46f-facd413f8d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.experiments.run:run_name is explicitly supplied in load_run, which will be prioritized to load the Run object. In other words, the run name in the experiment config, fetched from the job environment or the current run context, will be ignored.\n",
      "INFO:sagemaker.clarify:Analysis Config: {'dataset_type': 'text/csv', 'headers': ['msno', 'is_churn', 'regist_trans', 'mst_frq_plan_days', 'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew'], 'label': 'is_churn', 'excluded_columns': ['msno'], 'label_values_or_threshold': [1], 'facet': [{'name_or_index': 'gender', 'value_or_threshold': [1]}], 'group_variable': 'bd', 'methods': {'report': {'name': 'report', 'title': 'Analysis Report'}, 'post_training_bias': {'methods': 'all'}}, 'predictor': {'model_name': 'kkbox-customer-churn-model-20230202053205', 'instance_type': 'ml.m5.xlarge', 'initial_instance_count': 1, 'accept_type': 'text/csv', 'content_type': 'text/csv'}, 'probability_threshold': 0.8}\n",
      "INFO:sagemaker:Creating processing-job with name Clarify-Posttraining-Bias-2023-02-02-05-39-45-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34m2023-02-02 05:44:52,549 logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 This host is algo-1.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 This host is the leader.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,550 Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,764 Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,764 Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:52,774 Loading dataset...\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/analyzer/data_loading/csv_data_loader.py:323: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_tmp, ignore_index=True)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:54,649 Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 582105 entries, 0 to 582104\u001b[0m\n",
      "\u001b[34mData columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \u001b[0m\n",
      "\u001b[34m---  ------             --------------   -----  \n",
      " 0   msno               582105 non-null  object \n",
      " 1   regist_trans       582105 non-null  float64\n",
      " 2   mst_frq_plan_days  582105 non-null  float64\n",
      " 3   revenue            582105 non-null  float64\n",
      " 4   regist_cancels     582105 non-null  float64\n",
      " 5   bd                 582105 non-null  int64  \n",
      " 6   tenure             582105 non-null  float64\n",
      " 7   num_25             582105 non-null  float64\n",
      " 8   num_50             582105 non-null  float64\n",
      " 9   num_75             582105 non-null  float64\n",
      " 10  num_985            582105 non-null  float64\n",
      " 11  num_100            582105 non-null  float64\n",
      " 12  num_unq            582105 non-null  float64\n",
      " 13  total_secs         582105 non-null  float64\n",
      " 14  city               582105 non-null  float64\n",
      " 15  gender             582105 non-null  float64\n",
      " 16  registered_via     582105 non-null  float64\n",
      " 17  qtr_trans          582105 non-null  float64\n",
      " 18  mst_frq_pay_met    582105 non-null  float64\n",
      " 19  is_auto_renew      582105 non-null  float64\u001b[0m\n",
      "\u001b[34mdtypes: float64(18), int64(1), object(1)\u001b[0m\n",
      "\u001b[34mmemory usage: 88.8+ MB\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:54,823 Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:54,823 Creating endpoint-config with name sm-clarify-config-1675316694-dedc\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:54,980 Creating endpoint: 'sm-clarify-kkbox-customer-churn-model-202302020-1675316694-1e8b'\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:55,343 Using endpoint name: sm-clarify-kkbox-customer-churn-model-202302020-1675316694-1e8b\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:55,343 Waiting for endpoint ...\u001b[0m\n",
      "\u001b[34m2023-02-02 05:44:55,343 Checking endpoint status:\u001b[0m\n",
      "\u001b[34mLegend:\u001b[0m\n",
      "\u001b[34m(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,811 Endpoint is in service after 180 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,812 Endpoint ready.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,812 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,812 Calculating post-training bias metrics\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,812 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:47:55,812 Getting predictions from the endpoint\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:00,130 Prediction batch size is reduced to 13687 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:01,416 Prediction batch size is reduced to 13687 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:02,809 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:04,082 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:07,188 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:08,484 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:09,808 Prediction batch size is reduced to 13685 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:12,916 Prediction batch size is reduced to 13687 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:14,191 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:15,469 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:20,139 Prediction batch size is reduced to 13686 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:21,552 Prediction batch size is reduced to 13685 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:22,813 Prediction batch size is reduced to 13685 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:24,092 Prediction batch size is reduced to 13684 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:25,409 Prediction batch size is reduced to 13684 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:26,708 Prediction batch size is reduced to 13684 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:27,987 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:29,402 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:30,671 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:33,647 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:34,958 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:39,686 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:40,973 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:42,245 Prediction batch size is reduced to 13683 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,151 We assume a prediction above 0.800 indicates 1 and below or equal indicates 0.\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,155 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,169 Column gender with data uniqueness fraction 5.15370938232793e-06 is classifed as a CONTINUOUS column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:469: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,261 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,270 Column None with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:48:45,278 Threshold Interval indices: IntervalIndex([(1.0, 2.0]], dtype='interval[float64, right]')\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:14,296 FT metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py\", line 336, in _continuous_metric_call_wrapper\n",
      "    metric_value = smclarify.bias.metrics.call_metric(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/smclarify/bias/metrics/__init__.py\", line 27, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.9/site-packages/smclarify/bias/metrics/posttraining.py\", line 359, in FT\n",
      "    raise ValueError(\"FlipTest does not support non-numeric columns\")\u001b[0m\n",
      "\u001b[34mValueError: FlipTest does not support non-numeric columns\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,089 Calculated global analysis with predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,089 Stop using endpoint: sm-clarify-kkbox-customer-churn-model-202302020-1675316694-1e8b\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,089 Deleting endpoint configuration with name: sm-clarify-config-1675316694-dedc\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,248 Deleting endpoint with name: sm-clarify-kkbox-customer-churn-model-202302020-1675316694-1e8b\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,392 Model endpoint delivered 0.02191 requests per second and a total of 2 requests over 91 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,392 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,392 Calculating bias statistics for report\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,392 ======================================\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,396 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,410 Column gender with data uniqueness fraction 5.15370938232793e-06 is classifed as a CONTINUOUS column\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/smclarify/bias/report.py:469: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop(facet_column.name, 1)\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,450 Column is_churn with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,461 Column None with data uniqueness fraction 3.435806254885287e-06 is classifed as a CATEGORICAL column\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:27,470 Threshold Interval indices: IntervalIndex([(1.0, 2.0]], dtype='interval[float64, right]')\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:33,916 Model performance computations failed.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/analyzer/bias/bias_stats_analyzer.py\", line 118, in generate_model_performance_report\n",
      "    metrics_result: Dict[str, Any] = bias.model_performance_report(\u001b[0m\n",
      "\u001b[34mAttributeError: module 'smclarify.bias' has no attribute 'model_performance_report'\u001b[0m\n",
      "\u001b[34m2023-02-02 05:49:33,918 Converting Pandas DataFrame to SparkDataFrame for computing report metadata\u001b[0m\n",
      "\u001b[34m---!05:49:35.409 [main] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m05:49:52.718 [dispatcher-event-loop-10] WARN  o.a.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:54.689 [dispatcher-event-loop-4] WARN  o.a.spark.scheduler.TaskSetManager - Stage 3 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:56.029 [dispatcher-event-loop-7] WARN  o.a.spark.scheduler.TaskSetManager - Stage 9 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:56.589 [dispatcher-event-loop-5] WARN  o.a.spark.scheduler.TaskSetManager - Stage 12 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:57.340 [dispatcher-event-loop-15] WARN  o.a.spark.scheduler.TaskSetManager - Stage 13 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:57.908 [dispatcher-event-loop-5] WARN  o.a.spark.scheduler.TaskSetManager - Stage 19 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:58.483 [dispatcher-event-loop-4] WARN  o.a.spark.scheduler.TaskSetManager - Stage 22 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:59.156 [dispatcher-event-loop-13] WARN  o.a.spark.scheduler.TaskSetManager - Stage 23 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:49:59.950 [dispatcher-event-loop-1] WARN  o.a.spark.scheduler.TaskSetManager - Stage 29 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m05:50:00.437 [dispatcher-event-loop-11] WARN  o.a.spark.scheduler.TaskSetManager - Stage 32 contains a task of very large size (7566 KiB). The maximum recommended task size is 1000 KiB.\u001b[0m\n",
      "\u001b[34m#015[Stage 0:>                                                        (0 + 16) / 16]#015#015                                                                                #015#015[Stage 3:>                                                        (0 + 16) / 16]#015#015                                                                                #015#015[Stage 12:=================>                                      (5 + 11) / 16]#015#015                                                                                #015#015[Stage 22:>                                                       (0 + 16) / 16]#015#015                                                                                #015#015[Stage 23:>                                                       (0 + 16) / 16]#015#015                                                                                #0152023-02-02 05:50:00,940 Calculated global analysis without predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 05:50:00,950 Stop using endpoint: None\u001b[0m\n",
      "\u001b[34m2023-02-02 05:50:01,510 ['jupyter', 'nbconvert', '--to', 'html', '--output', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.ipynb', '--template', 'sagemaker-xai']\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 553915 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34m2023-02-02 05:50:02,601 ['wkhtmltopdf', '-q', '--enable-local-file-access', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.pdf']\u001b[0m\n",
      "\u001b[34m2023-02-02 05:50:03,370 Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"post_training_bias_metrics\": {\n",
      "        \"label\": \"is_churn\",\n",
      "        \"facets\": {\n",
      "            \"gender\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"(1.0, 2.0]\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"AD\",\n",
      "                            \"description\": \"Accuracy Difference (AD)\",\n",
      "                            \"value\": 0.03139382320579298\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CDDPL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Predicted Labels (CDDPL)\",\n",
      "                            \"value\": -0.024805277785913016\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DAR\",\n",
      "                            \"description\": \"Difference in Acceptance Rates (DAR)\",\n",
      "                            \"value\": 0.08905767097627348\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCA\",\n",
      "                            \"description\": \"Difference in Conditional Acceptance (DCA)\",\n",
      "                            \"value\": -0.5114537061773696\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCR\",\n",
      "                            \"description\": \"Difference in Conditional Rejection (DCR)\",\n",
      "                            \"value\": -0.023901140269775634\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DI\",\n",
      "                            \"description\": \"Disparate Impact (DI)\",\n",
      "                            \"value\": 1.1627497692679076\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Predicted Labels (DPPL)\",\n",
      "                            \"value\": -0.005057612970113867\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DRR\",\n",
      "                            \"description\": \"Difference in Rejection Rates (DRR)\",\n",
      "                            \"value\": -0.028343695289689053\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"FT\",\n",
      "                            \"description\": \"Flip Test (FT)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"FlipTest does not support non-numeric columns\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"GE\",\n",
      "                            \"description\": \"Generalized Entropy (GE)\",\n",
      "                            \"value\": 0.02381354940136561\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"RD\",\n",
      "                            \"description\": \"Recall Difference (RD)\",\n",
      "                            \"value\": 0.1285256851111935\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"SD\",\n",
      "                            \"description\": \"Specificity Difference (SD)\",\n",
      "                            \"value\": -0.0048553127334026724\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TE\",\n",
      "                            \"description\": \"Treatment Equality (TE)\",\n",
      "                            \"value\": 0.4440408188792526\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-02-02 05:50:03,370 exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_train_bias_run_name = \"clarify-post-train-bias\"\n",
    "with load_run(experiment_name=experiment_name, \n",
    "              run_name=post_train_bias_run_name,\n",
    "              sagemaker_session=sagemaker_session) as run:\n",
    "    clarify_processor.run_post_training_bias(\n",
    "        data_config=post_train_bias_data_config,\n",
    "        data_bias_config=post_train_bias_config,\n",
    "        model_config=model_config,\n",
    "        model_predicted_label_config=predictions_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9f00c-33b8-4766-9126-b085df22d165",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Post Training Bias Analysis\n",
    "Once the Clarify job is complete, we can view the Post Train Bias Evaluation analysis report in SageMaker Experiment.\n",
    "\n",
    "![sagemaker clarify post train bias](img/sm-clarify-post-train-bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0351-1e97-4405-8c48-99b569f0384b",
   "metadata": {},
   "source": [
    "# Model Explainability\n",
    "\n",
    "So far we've seen how SageMaker Clarify can be used to analyze Bias in both Data and the Model. \n",
    "In addition to bias analysis, Clarify can also be used to explain how machine learning (ML) models make predictions.  These tools can help ML modelers and developers and other internal stakeholders understand model characteristics as a whole prior to deployment and to debug predictions provided by the model after it's deployed. SageMaker Clarify uses a model-agnostic **feature attribution** approach to explain why a model made a prediction after training, and to provide per-instance explanation during inference. The implementation includes a scalable and efficient implementation of SHAP, based on the concept of a Shapley value, from the field of cooperative game theory, that assigns each feature an importance value for a particular prediction.\n",
    "\n",
    "Explanations are typically contrastive (that is, they account for deviations from a baseline). As a result, for the same model prediction, you can expect to get different explanations with respect to different baselines. Therefore, your choice of a baseline is crucial. In an ML context, the baseline corresponds to a hypothetical instance that can be either uninformative or informative. During the computation of Shapley values, SageMaker Clarify generates several new instances between the baseline and the given instance, in which the absence of a feature, is modeled by setting the feature value to that of the baseline and the presence of a feature is modeled by setting the feature value to that of the given instance. Thus, the absence of all features corresponds to the baseline and the presence of all features corresponds to the given instance.\n",
    "\n",
    "## Choosing a Baseline For Explainability\n",
    "How can you choose good baselines? Often it is desirable to select a baseline with very low information content. For example, you can construct an average instance from the training dataset by taking either the median or average for numerical features and the mode for categorical features. For the college admissions example, you might be interested in explaining why a particular applicant was accepted as compared to a baseline acceptances based on an average applicant. If not provided, a baseline is calculated automatically by SageMaker Clarify using K-means or K-prototypes in the input dataset.\n",
    "\n",
    "\n",
    "In the following section, we'll use Clarify to analyze the Model and provide Explainability in the form of SHAP values for each feature. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb127bd-d7e9-4ca7-a9fa-f3b264c25ecc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since our dataset contains both categorical and numerical columns, we'll use the following technique to construct our baseline dataset for SHAP analysis.\n",
    "\n",
    "* For numeric features, we'll use the mean value for the feature in the training dataset.\n",
    "* For categorical features, we'll use the mode for each features in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3e9e46ae-5c0f-4558-a422-32f0e5bb79c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>regist_trans</th>\n",
       "      <th>mst_frq_plan_days</th>\n",
       "      <th>revenue</th>\n",
       "      <th>regist_cancels</th>\n",
       "      <th>bd</th>\n",
       "      <th>tenure</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>...</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>qtr_trans</th>\n",
       "      <th>mst_frq_pay_met</th>\n",
       "      <th>is_auto_renew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452844</th>\n",
       "      <td>x7jIfnVqYQJQ/rUpXQ6a9qD3o3op5BOprCBV2AFOoX4=</td>\n",
       "      <td>0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.273592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.734242</td>\n",
       "      <td>1.357751</td>\n",
       "      <td>0.727428</td>\n",
       "      <td>...</td>\n",
       "      <td>15.051107</td>\n",
       "      <td>16.144804</td>\n",
       "      <td>7.850090</td>\n",
       "      <td>5.876712</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840421</th>\n",
       "      <td>/qcOoQQtPFBQHIoa/be/3672SArOmNqfzH+Z16l07ng=</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.158768</td>\n",
       "      <td>1.187204</td>\n",
       "      <td>0.881517</td>\n",
       "      <td>...</td>\n",
       "      <td>18.751185</td>\n",
       "      <td>45.950237</td>\n",
       "      <td>8.079880</td>\n",
       "      <td>3.246575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716023</th>\n",
       "      <td>NXlC99Lxpo4RNFIa+dHhSSXhYDi8K9T19cuT4nPFSEs=</td>\n",
       "      <td>0</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>7.423568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.538835</td>\n",
       "      <td>1.315534</td>\n",
       "      <td>1.019417</td>\n",
       "      <td>...</td>\n",
       "      <td>21.172330</td>\n",
       "      <td>19.155340</td>\n",
       "      <td>8.178232</td>\n",
       "      <td>8.758904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966444</th>\n",
       "      <td>xRZdxjljVoblzXnN3lASe+bbYdkYUH1GRt60MMxzo/s=</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>7.540090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.146853</td>\n",
       "      <td>2.538462</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>12.489510</td>\n",
       "      <td>23.482517</td>\n",
       "      <td>7.650415</td>\n",
       "      <td>1.715068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469497</th>\n",
       "      <td>1wbBkYB1AOyJrfitu2KuJC9+klX6PGreWmHgMj7vXbI=</td>\n",
       "      <td>0</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>8.262301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.020833</td>\n",
       "      <td>1.106771</td>\n",
       "      <td>0.440104</td>\n",
       "      <td>...</td>\n",
       "      <td>18.140625</td>\n",
       "      <td>13.997396</td>\n",
       "      <td>7.802782</td>\n",
       "      <td>3.558904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                msno  is_churn  regist_trans  \\\n",
       "452844  x7jIfnVqYQJQ/rUpXQ6a9qD3o3op5BOprCBV2AFOoX4=         0      2.639057   \n",
       "840421  /qcOoQQtPFBQHIoa/be/3672SArOmNqfzH+Z16l07ng=         0      1.386294   \n",
       "716023  NXlC99Lxpo4RNFIa+dHhSSXhYDi8K9T19cuT4nPFSEs=         0      2.564949   \n",
       "966444  xRZdxjljVoblzXnN3lASe+bbYdkYUH1GRt60MMxzo/s=         0      2.995732   \n",
       "469497  1wbBkYB1AOyJrfitu2KuJC9+klX6PGreWmHgMj7vXbI=         0      3.295837   \n",
       "\n",
       "        mst_frq_plan_days   revenue  regist_cancels  bd     tenure    num_25  \\\n",
       "452844           3.433987  8.273592             0.0   0   3.734242  1.357751   \n",
       "840421           3.433987  6.293419             0.0   0  28.158768  1.187204   \n",
       "716023           3.433987  7.423568             0.0   0   6.538835  1.315534   \n",
       "966444           3.433987  7.540090             0.0   0  10.146853  2.538462   \n",
       "469497           3.433987  8.262301             0.0   0   2.020833  1.106771   \n",
       "\n",
       "          num_50  ...    num_985    num_100   num_unq  total_secs  city  \\\n",
       "452844  0.727428  ...  15.051107  16.144804  7.850090    5.876712   6.0   \n",
       "840421  0.881517  ...  18.751185  45.950237  8.079880    3.246575   2.0   \n",
       "716023  1.019417  ...  21.172330  19.155340  8.178232    8.758904   2.0   \n",
       "966444  1.153846  ...  12.489510  23.482517  7.650415    1.715068   0.0   \n",
       "469497  0.440104  ...  18.140625  13.997396  7.802782    3.558904   0.0   \n",
       "\n",
       "        gender  registered_via  qtr_trans  mst_frq_pay_met  is_auto_renew  \n",
       "452844     0.0             1.0        0.0              4.0            0.0  \n",
       "840421     2.0             1.0        0.0              4.0            0.0  \n",
       "716023     1.0             1.0        0.0              3.0            0.0  \n",
       "966444     0.0             0.0        2.0              0.0            0.0  \n",
       "469497     0.0             0.0        0.0              0.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "89be04fb-ac51-4b99-bb1d-3f29541fa36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_feature_names = [ 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "006127ef-c8c4-477f-962a-04d1d4d255e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_feature_names = [ x for x in feature_cols if x not in category_feature_names and x not in [ \"msno\", \"is_churn\" ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "caddeefe-6878-40e8-9dc3-18c3390081b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_df = pd.DataFrame(columns= ['regist_trans', 'mst_frq_plan_days', 'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', \n",
    "    'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', \n",
    "    'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b15dae8-6c31-4463-b751-b71f0e463bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in category_feature_names:\n",
    "     baseline_df[f] = train[f].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "895a2f5d-72d7-48d6-9ba1-d50a8b92ec86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in numeric_feature_names:\n",
    "    baseline_df[f] = train[f].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7eff695a-52bf-456f-8012-d81759618c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = baseline_df.loc[0,:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c5e9f766-52d7-41ed-ad50-463cf3df4315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=[baseline],\n",
    "    agg_method=\"mean_abs\",\n",
    "    num_samples=59,\n",
    "    save_local_shap_values=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e96c69b9-ea28-476e-adc3-1ac432f625f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainability_output_path = f\"s3://{bucket}/{prefix}/clarify-explainability\"\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=f\"s3://{bucket}/{val_dataset_s3_prefix}/val.csv\",\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label=\"is_churn\",\n",
    "    headers=feature_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    "    excluded_columns=[\"msno\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f6756000-2cdd-4734-b0c3-47ce2c5674a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.experiments.run:run_name is explicitly supplied in load_run, which will be prioritized to load the Run object. In other words, the run name in the experiment config, fetched from the job environment or the current run context, will be ignored.\n",
      "INFO:sagemaker.clarify:Analysis Config: {'dataset_type': 'text/csv', 'headers': ['msno', 'is_churn', 'regist_trans', 'mst_frq_plan_days', 'revenue', 'regist_cancels', 'bd', 'tenure', 'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs', 'city', 'gender', 'registered_via', 'qtr_trans', 'mst_frq_pay_met', 'is_auto_renew'], 'label': 'is_churn', 'excluded_columns': ['msno'], 'predictor': {'model_name': 'kkbox-customer-churn-model-20230202053205', 'instance_type': 'ml.m5.xlarge', 'initial_instance_count': 1, 'accept_type': 'text/csv', 'content_type': 'text/csv'}, 'methods': {'report': {'name': 'report', 'title': 'Analysis Report'}, 'shap': {'use_logit': False, 'save_local_shap_values': True, 'baseline': [[2.663893229857712, 3.465653240347559, 7.443359819138155, 0.17611774303500843, 0.0, 5.922386381609899, 1.4932106804795426, 0.8961970300898964, 0.9524666352497243, 24.61423117387386, 25.068232366720203, 7.977549570168414, 3.5766200219489708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], 'num_samples': 59, 'agg_method': 'mean_abs'}}}\n",
      "INFO:sagemaker:Creating processing-job with name Clarify-Explainability-2023-02-02-06-30-48-887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m2023-02-02 06:35:26,864 logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 This host is algo-1.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 This host is the leader.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:26,865 Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,093 Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,093 Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,103 Loading dataset...\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/analyzer/data_loading/csv_data_loader.py:323: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_tmp, ignore_index=True)\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,408 Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 83158 entries, 0 to 83157\u001b[0m\n",
      "\u001b[34mData columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \u001b[0m\n",
      "\u001b[34m---  ------             --------------  -----  \n",
      " 0   msno               83158 non-null  object \n",
      " 1   regist_trans       83158 non-null  float64\n",
      " 2   mst_frq_plan_days  83158 non-null  float64\n",
      " 3   revenue            83158 non-null  float64\n",
      " 4   regist_cancels     83158 non-null  float64\n",
      " 5   bd                 83158 non-null  int64  \n",
      " 6   tenure             83158 non-null  float64\n",
      " 7   num_25             83158 non-null  float64\n",
      " 8   num_50             83158 non-null  float64\n",
      " 9   num_75             83158 non-null  float64\n",
      " 10  num_985            83158 non-null  float64\n",
      " 11  num_100            83158 non-null  float64\n",
      " 12  num_unq            83158 non-null  float64\n",
      " 13  total_secs         83158 non-null  float64\n",
      " 14  city               83158 non-null  float64\n",
      " 15  gender             83158 non-null  float64\n",
      " 16  registered_via     83158 non-null  float64\n",
      " 17  qtr_trans          83158 non-null  float64\n",
      " 18  mst_frq_pay_met    83158 non-null  float64\n",
      " 19  is_auto_renew      83158 non-null  float64\u001b[0m\n",
      "\u001b[34mdtypes: float64(18), int64(1), object(1)\u001b[0m\n",
      "\u001b[34mmemory usage: 12.7+ MB\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,477 Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,477 Creating endpoint-config with name sm-clarify-config-1675319727-9c09\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:27,670 Creating endpoint: 'sm-clarify-kkbox-customer-churn-model-202302020-1675319727-9e09'\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:28,100 Using endpoint name: sm-clarify-kkbox-customer-churn-model-202302020-1675319727-9e09\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:28,100 Waiting for endpoint ...\u001b[0m\n",
      "\u001b[34m2023-02-02 06:35:28,100 Checking endpoint status:\u001b[0m\n",
      "\u001b[34mLegend:\u001b[0m\n",
      "\u001b[34m(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,489 Endpoint is in service after 180 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,489 Endpoint ready.\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,496 SHAP n_samples 59\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,633 =====================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,633 Shap analyzer: explaining 83158 rows, 19 columns...\u001b[0m\n",
      "\u001b[34m2023-02-02 06:38:28,633 =====================================================\n",
      "  0% (0 of 83158) |                      | Elapsed Time: 0:00:00 ETA:  --:--:--\u001b[0m\n",
      "\u001b[34m  1% (1274 of 83158) |                   | Elapsed Time: 0:00:30 ETA:   0:32:09\u001b[0m\n",
      "\u001b[34m  3% (2630 of 83158) |                   | Elapsed Time: 0:01:00 ETA:   0:29:42\u001b[0m\n",
      "\u001b[34m  4% (3987 of 83158) |                   | Elapsed Time: 0:01:30 ETA:   0:29:10\u001b[0m\n",
      "\u001b[34m  6% (5384 of 83158) |#                  | Elapsed Time: 0:02:00 ETA:   0:27:50\u001b[0m\n",
      "\u001b[34m  8% (6737 of 83158) |#                  | Elapsed Time: 0:02:30 ETA:   0:28:15\u001b[0m\n",
      "\u001b[34m  9% (8138 of 83158) |#                  | Elapsed Time: 0:03:00 ETA:   0:26:47\u001b[0m\n",
      "\u001b[34m 11% (9544 of 83158) |##                 | Elapsed Time: 0:03:30 ETA:   0:26:11\u001b[0m\n",
      "\u001b[34m 13% (10964 of 83158) |##                | Elapsed Time: 0:04:00 ETA:   0:25:26\u001b[0m\n",
      "\u001b[34m 14% (12394 of 83158) |##                | Elapsed Time: 0:04:30 ETA:   0:24:44\u001b[0m\n",
      "\u001b[34m 16% (13790 of 83158) |##                | Elapsed Time: 0:05:00 ETA:   0:24:51\u001b[0m\n",
      "\u001b[34m 18% (15217 of 83158) |###               | Elapsed Time: 0:05:30 ETA:   0:23:48\u001b[0m\n",
      "\u001b[34m 20% (16647 of 83158) |###               | Elapsed Time: 0:06:00 ETA:   0:23:16\u001b[0m\n",
      "\u001b[34m 21% (18079 of 83158) |###               | Elapsed Time: 0:06:30 ETA:   0:22:44\u001b[0m\n",
      "\u001b[34m 23% (19491 of 83158) |####              | Elapsed Time: 0:07:00 ETA:   0:22:32\u001b[0m\n",
      "\u001b[34m 25% (20859 of 83158) |####              | Elapsed Time: 0:07:30 ETA:   0:22:46\u001b[0m\n",
      "\u001b[34m 26% (22151 of 83158) |####              | Elapsed Time: 0:08:00 ETA:   0:23:37\u001b[0m\n",
      "\u001b[34m 28% (23585 of 83158) |#####             | Elapsed Time: 0:08:30 ETA:   0:20:46\u001b[0m\n",
      "\u001b[34m 30% (25015 of 83158) |#####             | Elapsed Time: 0:09:00 ETA:   0:20:20\u001b[0m\n",
      "\u001b[34m 31% (26452 of 83158) |#####             | Elapsed Time: 0:09:30 ETA:   0:19:44\u001b[0m\n",
      "\u001b[34m 33% (27880 of 83158) |######            | Elapsed Time: 0:10:00 ETA:   0:19:21\u001b[0m\n",
      "\u001b[34m 35% (29304 of 83158) |######            | Elapsed Time: 0:10:30 ETA:   0:18:55\u001b[0m\n",
      "\u001b[34m 36% (30745 of 83158) |######            | Elapsed Time: 0:11:00 ETA:   0:18:11\u001b[0m\n",
      "\u001b[34m 38% (32198 of 83158) |######            | Elapsed Time: 0:11:30 ETA:   0:17:32\u001b[0m\n",
      "\u001b[34m 40% (33630 of 83158) |#######           | Elapsed Time: 0:12:00 ETA:   0:17:17\u001b[0m\n",
      "\u001b[34m 42% (35079 of 83158) |#######           | Elapsed Time: 0:12:30 ETA:   0:16:35\u001b[0m\n",
      "\u001b[34m 43% (36522 of 83158) |#######           | Elapsed Time: 0:13:00 ETA:   0:16:09\u001b[0m\n",
      "\u001b[34m 45% (37964 of 83158) |########          | Elapsed Time: 0:13:30 ETA:   0:15:40\u001b[0m\n",
      "\u001b[34m 47% (39415 of 83158) |########          | Elapsed Time: 0:14:00 ETA:   0:15:04\u001b[0m\n",
      "\u001b[34m 49% (40848 of 83158) |########          | Elapsed Time: 0:14:30 ETA:   0:14:46\u001b[0m\n",
      "\u001b[34m 50% (42275 of 83158) |#########         | Elapsed Time: 0:15:00 ETA:   0:14:19\u001b[0m\n",
      "\u001b[34m 52% (43701 of 83158) |#########         | Elapsed Time: 0:15:30 ETA:   0:13:50\u001b[0m\n",
      "\u001b[34m 54% (45123 of 83158) |#########         | Elapsed Time: 0:16:00 ETA:   0:13:22\u001b[0m\n",
      "\u001b[34m 55% (46540 of 83158) |##########        | Elapsed Time: 0:16:30 ETA:   0:12:55\u001b[0m\n",
      "\u001b[34m 57% (47962 of 83158) |##########        | Elapsed Time: 0:17:00 ETA:   0:12:22\u001b[0m\n",
      "\u001b[34m 59% (49382 of 83158) |##########        | Elapsed Time: 0:17:30 ETA:   0:11:53\u001b[0m\n",
      "\u001b[34m 61% (50787 of 83158) |##########        | Elapsed Time: 0:18:00 ETA:   0:11:31\u001b[0m\n",
      "\u001b[34m 62% (52200 of 83158) |###########       | Elapsed Time: 0:18:30 ETA:   0:10:57\u001b[0m\n",
      "\u001b[34m 64% (53608 of 83158) |###########       | Elapsed Time: 0:19:00 ETA:   0:10:29\u001b[0m\n",
      "\u001b[34m 66% (55022 of 83158) |###########       | Elapsed Time: 0:19:30 ETA:   0:09:57\u001b[0m\n",
      "\u001b[34m 67% (56427 of 83158) |############      | Elapsed Time: 0:20:00 ETA:   0:09:31\u001b[0m\n",
      "\u001b[34m 69% (57829 of 83158) |############      | Elapsed Time: 0:20:30 ETA:   0:09:02\u001b[0m\n",
      "\u001b[34m 71% (59236 of 83158) |############      | Elapsed Time: 0:21:00 ETA:   0:08:30\u001b[0m\n",
      "\u001b[34m 72% (60642 of 83158) |#############     | Elapsed Time: 0:21:30 ETA:   0:08:00\u001b[0m\n",
      "\u001b[34m 74% (62042 of 83158) |#############     | Elapsed Time: 0:22:00 ETA:   0:07:32\u001b[0m\n",
      "\u001b[34m 76% (63461 of 83158) |#############     | Elapsed Time: 0:22:30 ETA:   0:06:56\u001b[0m\n",
      "\u001b[34m 77% (64552 of 83158) |#############     | Elapsed Time: 0:23:00 ETA:   0:08:31\u001b[0m\n",
      "\u001b[34m 79% (65959 of 83158) |##############    | Elapsed Time: 0:23:30 ETA:   0:06:06\u001b[0m\n",
      "\u001b[34m 81% (67374 of 83158) |##############    | Elapsed Time: 0:24:00 ETA:   0:05:34\u001b[0m\n",
      "\u001b[34m 82% (68795 of 83158) |##############    | Elapsed Time: 0:24:30 ETA:   0:05:03\u001b[0m\n",
      "\u001b[34m 84% (70203 of 83158) |###############   | Elapsed Time: 0:25:00 ETA:   0:04:36\u001b[0m\n",
      "\u001b[34m 86% (71638 of 83158) |###############   | Elapsed Time: 0:25:30 ETA:   0:04:00\u001b[0m\n",
      "\u001b[34m 87% (73077 of 83158) |###############   | Elapsed Time: 0:26:00 ETA:   0:03:30\u001b[0m\n",
      "\u001b[34m 89% (74516 of 83158) |################  | Elapsed Time: 0:26:30 ETA:   0:03:00\u001b[0m\n",
      "\u001b[34m 91% (75950 of 83158) |################  | Elapsed Time: 0:27:00 ETA:   0:02:30\u001b[0m\n",
      "\u001b[34m 93% (77383 of 83158) |################  | Elapsed Time: 0:27:30 ETA:   0:02:00\u001b[0m\n",
      "\u001b[34m 94% (78800 of 83158) |################# | Elapsed Time: 0:28:00 ETA:   0:01:32\u001b[0m\n",
      "\u001b[34m 96% (80213 of 83158) |################# | Elapsed Time: 0:28:30 ETA:   0:01:02\u001b[0m\n",
      "\u001b[34m 98% (81617 of 83158) |################# | Elapsed Time: 0:29:00 ETA:   0:00:32\u001b[0m\n",
      "\u001b[34m 99% (83041 of 83158) |################# | Elapsed Time: 0:29:30 ETA:   0:00:02\u001b[0m\n",
      "\u001b[34m100% (83158 of 83158) |##################| Elapsed Time: 0:29:33 Time:  0:29:33\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:02,113 getting explanations took 1773.48 seconds.\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:02,113 ===================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:02,116 Falling back to generic labels: label0, label1, ...\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,024 converting explanations to tabular took 5.91 seconds.\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,024 ===================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,028 Wrote baseline used to compute explanations to: /opt/ml/processing/output/explanations_shap/baseline.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,875 Wrote 83158 local explanations to: /opt/ml/processing/output/explanations_shap/out.csv\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,875 writing local explanations took 0.85 seconds.\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,875 ===================================================\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,883 aggregating local explanations took 0.01 seconds.\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,883 ===================================================\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,883 Shap analysis finished.\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,884 Calculated global analysis with predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,884 Stop using endpoint: sm-clarify-kkbox-customer-churn-model-202302020-1675319727-9e09\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:08,884 Deleting endpoint configuration with name: sm-clarify-config-1675319727-9c09\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:09,068 Deleting endpoint with name: sm-clarify-kkbox-customer-churn-model-202302020-1675319727-9e09\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:09,176 Model endpoint delivered 46.70874 requests per second and a total of 83160 requests over 1780 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:09,176 Calculated global analysis without predictor\u001b[0m\n",
      "\u001b[34m2023-02-02 07:08:09,604 Stop using endpoint: None\u001b[0m\n",
      "\u001b[34m2023-02-02 07:09:17,516 ['jupyter', 'nbconvert', '--to', 'html', '--output', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.ipynb', '--template', 'sagemaker-xai']\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 457707 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34m2023-02-02 07:09:18,524 ['wkhtmltopdf', '-q', '--enable-local-file-access', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.pdf']\u001b[0m\n",
      "\u001b[34m2023-02-02 07:09:19,173 Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"explanations\": {\n",
      "        \"kernel_shap\": {\n",
      "            \"label0\": {\n",
      "                \"global_shap_values\": {\n",
      "                    \"regist_trans\": 0.02227088074191561,\n",
      "                    \"mst_frq_plan_days\": 0.007057866418414953,\n",
      "                    \"revenue\": 0.011543538176133527,\n",
      "                    \"regist_cancels\": 0.026462594542818334,\n",
      "                    \"bd\": 0.0066366406157635375,\n",
      "                    \"tenure\": 0.006745774612699141,\n",
      "                    \"num_25\": 0.006678202102954884,\n",
      "                    \"num_50\": 0.006645087277022444,\n",
      "                    \"num_75\": 0.006691784110512422,\n",
      "                    \"num_985\": 0.0070193999437046205,\n",
      "                    \"num_100\": 0.006725535292371128,\n",
      "                    \"num_unq\": 0.007881377437301324,\n",
      "                    \"total_secs\": 0.008030126938854363,\n",
      "                    \"city\": 0.00682032288317857,\n",
      "                    \"gender\": 0.00671167689058702,\n",
      "                    \"registered_via\": 0.007032036006063607,\n",
      "                    \"qtr_trans\": 0.008132085333655113,\n",
      "                    \"mst_frq_pay_met\": 0.012394053533674782,\n",
      "                    \"is_auto_renew\": 0.011896440007737348\n",
      "                },\n",
      "                \"expected_value\": 0.0\n",
      "            }\n",
      "        }\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-02-02 07:09:19,174 exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34m---!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explainability_run_name = \"clarify-explainability\"\n",
    "with load_run(experiment_name=experiment_name, \n",
    "              run_name=explainability_run_name,\n",
    "              sagemaker_session=sagemaker_session) as run:    \n",
    "\n",
    "    clarify_processor.run_explainability(\n",
    "        data_config=explainability_data_config,\n",
    "        model_config=model_config,\n",
    "        explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825e5fe-9192-47d5-b6b4-3385f14366c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Explainability Analysis\n",
    "Once the Clarify job is complete, we can view the Model Explainability analysis report in SageMaker Experiment.\n",
    "\n",
    "![sagemaker clarify model explainability](img/sm-clarify-explainability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4a05f-28ad-4274-a027-46784bbe8d12",
   "metadata": {},
   "source": [
    "# Model Registry\n",
    "\n",
    "From MLOps perspective, Model Registry is a mechanism that provides a central repository that allows model developers to publish production-ready models for ease of access. With the registry, developers can also work together with other teams and stakeholders, collaboratively manage the lifecycle of all models in the organization. \n",
    "\n",
    "A data scientist can push trained models to the model registry. Once in the registry, your models are ready to be tested, validated, and deployed to production.\n",
    "\n",
    "SageMaker provides a Model Registry for any models. Here are some key features of SageMaker Model Registry:\n",
    "\n",
    "* Catalog models for production\n",
    "\n",
    "* Manage model versions\n",
    "\n",
    "* Associate metadata, such as training metrics, with a model\n",
    "\n",
    "* Manage the approval status of a model\n",
    "\n",
    "* Deploy models to production.\n",
    "\n",
    "* Automate model deployment with CI/CD.\n",
    "\n",
    "* Associate metadata, such as training metrics, with a model.\n",
    "\n",
    "* Manage the approval status of a model.\n",
    "\n",
    "* Deploy models to production.\n",
    "\n",
    "Automate model deployment with CI/CD.\n",
    "\n",
    "## Model Registry Structure\n",
    "\n",
    "The SageMaker Model Registry is structured as several model groups with model packages in each group. Each model package in a model group corresponds to a trained model. The version of each model package is a numerical value that starts at 1 and is incremented with each new model package added to a model group. For example, if 5 model packages are added to a model group, the model package versions will be 1, 2, 3, 4, and 5. The example Model Registry shown in the following image contains 3 model groups, where each group contains the model packages related to a particular ML problem.\n",
    "\n",
    "The following diagram shows how a model registry is organized in SageMaker:\n",
    "\n",
    "![sagemaker model registry](img/sm-model-registry.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45078138-4ecd-4581-b398-1df83f87422f",
   "metadata": {},
   "source": [
    "In the following section, we'll register our best model trained using SageMaker HPO into a new model group. \n",
    "We'll also provide the model metrics generated from the model evaluation processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a2521ff9-ef02-47ab-9b92-560675eebef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_approval_status = \"PendingManualApproval\"\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"s3://{bucket}/{s3_model_evaluation_prefix}/evaluation.json\",\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "537363eb-ceae-46a6-bc12-fc3106a3273c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.model.ModelPackage at 0x7efcc2ac5450>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_package_group_name = \"demo-kkbox-customer-churn-model-group\"\n",
    "model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf5efc-fe8c-44f6-92d1-7651f0d53752",
   "metadata": {},
   "source": [
    "Here's a screenshot of a model version registered with Model Registry\n",
    "\n",
    "![sm model registry version](img/sm-model-registry-version.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb713a-0424-44da-8424-f6c4fae7434f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Deployment\n",
    "\n",
    "There are many options available to optimally serve your model inference with SageMaker. Here are the common types of inference modes supported:\n",
    "\n",
    "![sagemaker inference](img/sm-deployment-modes.png)\n",
    "\n",
    "In this example, we'll deploy a realtime endpoint and run some inference on it to validate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0126170f-2500-4312-8fe3-35738fd5a175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "985f1c52-0cee-450a-9121-4fa6dbf7eb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: kkbox-customer-churn-model-20230202053205\n",
      "WARNING:sagemaker:Using already existing model: kkbox-customer-churn-model-20230202053205\n",
      "INFO:sagemaker:Creating endpoint-config with name kkbox-customer-churn-model-202302020532-2023-02-02-16-26-14-949\n",
      "INFO:sagemaker:Creating endpoint with name kkbox-customer-churn-model-202302020532-2023-02-02-16-26-14-949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serializer = CSVSerializer(),\n",
    "    deserializer = CSVDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3695c6-ca02-4183-a2de-4ad12578881d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Test the endpoint by sending traffics to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "73cb49ec-0842-4bea-bd14-523248208547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test.iloc[:10, 2:].to_csv(header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "78316db9-13a6-43df-ba18-df23bbc48649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "82eda8c3-e234-417b-8b89-6f720ec88c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0'], ['1'], ['0'], ['0'], ['0'], ['0'], ['0'], ['0'], ['0'], ['0']]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85b2d0-9d60-4535-ae46-6b2cb1db5cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
